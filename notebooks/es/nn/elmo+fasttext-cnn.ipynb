{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancias de entrenamiento: 4500\n",
      "Instancias de desarrollo: 500\n",
      "Instancias de test: 1600\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def \n",
    "\n",
    "torch.manual_seed(2019)\n",
    "np.random.seed(2019)\n",
    "tf.random.set_random_seed(2019)\n",
    "random.seed(2019)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "df_dev = pd.read_table(\"../../../data/es/dev_es.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "df_train = pd.read_table(\"../../../data/es/train_es.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "df_test = pd.read_table(\"../../../data/es/reference_es.tsv\", header=None, \n",
    "                        names=[\"text\", \"HS\", \"TR\", \"AG\"], quoting=csv.QUOTE_NONE)\n",
    "\n",
    "\n",
    "text_train, y_train = df_train[\"text\"], df_train[\"HS\"]\n",
    "text_dev, y_dev = df_dev[\"text\"], df_dev[\"HS\"]\n",
    "text_test, y_test = df_test[\"text\"], df_test[\"HS\"]\n",
    "\n",
    "print(\"Instancias de entrenamiento: {}\".format(len(df_train)))\n",
    "print(\"Instancias de desarrollo: {}\".format(len(df_dev)))\n",
    "print(\"Instancias de test: {}\".format(len(df_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elmo + Embeddings\n",
    "\n",
    "Probemos si usando también los embeddings de fastText obtenemos algo razonable...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fastText\n",
    "import os\n",
    "\n",
    "\n",
    "model = fastText.load_model(os.path.expanduser(\"../../../WordVectors/UBA_w3_300.bin\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tengo que hacer dos cosas:\n",
    "\n",
    "- Primero, convertir los tweets a secuencias de texto\n",
    "- Luego, paddear las secuencias a cierta longitud (Keras necesita esto para poder paralelizar cálculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "max_length = 40\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    if len(tokens) >= max_length:\n",
    "        tokens = tokens[:max_length]\n",
    "    else:\n",
    "        tokens = tokens + [''] * (max_length - len(tokens))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "tokens_train = [preprocess_tweet(tweet) for tweet in df_train[\"text\"].values]\n",
    "tokens_dev = [preprocess_tweet(tweet) for tweet in df_dev[\"text\"].values]\n",
    "tokens_test = [preprocess_tweet(tweet) for tweet in df_test[\"text\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from elmoformanylangs import Embedder\n",
    "\n",
    "e = Embedder(\"../../../models/elmo/es/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "X_train = np.array(e.sents2elmo(tokens_train))\n",
    "X_dev = np.array(e.sents2elmo(tokens_dev))\n",
    "X_test = np.array(e.sents2elmo(tokens_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 40, 300), (500, 40, 300), (1600, 40, 300))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_embeddings(toks):\n",
    "    ret = []\n",
    "    \n",
    "    for tok in toks:\n",
    "        vec = model.get_word_vector(tok)\n",
    "        ret.append(vec)\n",
    "    return ret\n",
    "\n",
    "X_emb_train = np.array([get_embeddings(toks) for toks in tokens_train])\n",
    "X_emb_dev = np.array([get_embeddings(toks) for toks in tokens_dev])\n",
    "X_emb_test = np.array([get_embeddings(toks) for toks in tokens_test])\n",
    "\n",
    "X_emb_train.shape, X_emb_dev.shape, X_emb_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con Global Max Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 40, 1024)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 40, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 40, 1324)     0           input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 38, 40)       158920      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 38, 40)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 40)           0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            41          global_max_pooling1d_1[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 158,961\n",
      "Trainable params: 158,961\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Dropout, Conv1D, CuDNNGRU, Input, Concatenate, Bidirectional, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "optimizer_args = {\n",
    "    \"lr\": 0.00075,\n",
    "    \"decay\": 0.005,\n",
    "}\n",
    "\n",
    "elmo_input = Input(shape=X_train[0].shape)\n",
    "emb_input = Input(shape=X_emb_train[0].shape)\n",
    "\n",
    "x = Concatenate()([elmo_input, emb_input])\n",
    "x = Conv1D(filters=40, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.60)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=[elmo_input, emb_input], outputs=[output])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/250\n",
      "4500/4500 [==============================] - 4s 795us/step - loss: 0.7989 - acc: 0.6651 - val_loss: 0.5510 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.72400, saving model to /tmp/cnn_model.h5\n",
      "Epoch 2/250\n",
      "4500/4500 [==============================] - 1s 282us/step - loss: 0.5261 - acc: 0.7622 - val_loss: 0.4812 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.72400 to 0.77600, saving model to /tmp/cnn_model.h5\n",
      "Epoch 3/250\n",
      "4500/4500 [==============================] - 1s 285us/step - loss: 0.4337 - acc: 0.8020 - val_loss: 0.4560 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.77600 to 0.80000, saving model to /tmp/cnn_model.h5\n",
      "Epoch 4/250\n",
      "4500/4500 [==============================] - 1s 273us/step - loss: 0.4055 - acc: 0.8138 - val_loss: 0.4505 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.80000 to 0.82200, saving model to /tmp/cnn_model.h5\n",
      "Epoch 5/250\n",
      "4500/4500 [==============================] - 1s 275us/step - loss: 0.3634 - acc: 0.8453 - val_loss: 0.4471 - val_acc: 0.8260\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.82200 to 0.82600, saving model to /tmp/cnn_model.h5\n",
      "Epoch 6/250\n",
      "4500/4500 [==============================] - 1s 272us/step - loss: 0.3329 - acc: 0.8560 - val_loss: 0.4398 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.82600\n",
      "Epoch 7/250\n",
      "4500/4500 [==============================] - 1s 271us/step - loss: 0.3143 - acc: 0.8649 - val_loss: 0.4400 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.82600\n",
      "Epoch 8/250\n",
      "4500/4500 [==============================] - 1s 272us/step - loss: 0.3200 - acc: 0.8629 - val_loss: 0.4297 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.82600\n",
      "Epoch 9/250\n",
      "4500/4500 [==============================] - 1s 284us/step - loss: 0.2878 - acc: 0.8800 - val_loss: 0.4343 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.82600\n",
      "Epoch 10/250\n",
      "4500/4500 [==============================] - 1s 267us/step - loss: 0.2745 - acc: 0.8900 - val_loss: 0.4322 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.82600\n",
      "Epoch 11/250\n",
      "4500/4500 [==============================] - 1s 265us/step - loss: 0.2694 - acc: 0.8918 - val_loss: 0.4306 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.82600\n",
      "Epoch 12/250\n",
      "4500/4500 [==============================] - 1s 271us/step - loss: 0.2636 - acc: 0.8953 - val_loss: 0.4291 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.82600\n",
      "Epoch 13/250\n",
      "4500/4500 [==============================] - 1s 273us/step - loss: 0.2573 - acc: 0.8991 - val_loss: 0.4333 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.82600\n",
      "Epoch 14/250\n",
      "4500/4500 [==============================] - 1s 275us/step - loss: 0.2485 - acc: 0.8978 - val_loss: 0.4394 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.82600\n",
      "Epoch 15/250\n",
      "4500/4500 [==============================] - 1s 274us/step - loss: 0.2378 - acc: 0.9087 - val_loss: 0.4254 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.82600\n",
      "Epoch 16/250\n",
      "4500/4500 [==============================] - 1s 276us/step - loss: 0.2318 - acc: 0.9111 - val_loss: 0.4301 - val_acc: 0.7840\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.82600\n",
      "Epoch 17/250\n",
      "4500/4500 [==============================] - 1s 270us/step - loss: 0.2321 - acc: 0.9118 - val_loss: 0.4264 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.82600\n",
      "Epoch 18/250\n",
      "4500/4500 [==============================] - 1s 283us/step - loss: 0.2211 - acc: 0.9204 - val_loss: 0.4212 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.82600\n",
      "Epoch 19/250\n",
      "4500/4500 [==============================] - 1s 271us/step - loss: 0.2179 - acc: 0.9142 - val_loss: 0.4263 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.82600\n",
      "Epoch 20/250\n",
      "4500/4500 [==============================] - 1s 295us/step - loss: 0.2117 - acc: 0.9220 - val_loss: 0.4235 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.82600\n",
      "Epoch 21/250\n",
      "4500/4500 [==============================] - 1s 273us/step - loss: 0.2169 - acc: 0.9164 - val_loss: 0.4192 - val_acc: 0.8080\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.82600\n",
      "Epoch 22/250\n",
      "4500/4500 [==============================] - 1s 289us/step - loss: 0.1959 - acc: 0.9322 - val_loss: 0.4317 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.82600\n",
      "Epoch 23/250\n",
      "4500/4500 [==============================] - 1s 272us/step - loss: 0.2089 - acc: 0.9247 - val_loss: 0.4195 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.82600\n",
      "Epoch 24/250\n",
      "4500/4500 [==============================] - 1s 280us/step - loss: 0.2050 - acc: 0.9258 - val_loss: 0.4201 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.82600\n",
      "Epoch 25/250\n",
      "4500/4500 [==============================] - 1s 272us/step - loss: 0.1946 - acc: 0.9309 - val_loss: 0.4182 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.82600\n",
      "Epoch 26/250\n",
      "4500/4500 [==============================] - 1s 290us/step - loss: 0.1946 - acc: 0.9253 - val_loss: 0.4192 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.82600\n",
      "Epoch 27/250\n",
      "4500/4500 [==============================] - 1s 274us/step - loss: 0.1911 - acc: 0.9260 - val_loss: 0.4200 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.82600\n",
      "Epoch 28/250\n",
      "4500/4500 [==============================] - 1s 270us/step - loss: 0.1917 - acc: 0.9267 - val_loss: 0.4215 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.82600\n",
      "Epoch 29/250\n",
      "4500/4500 [==============================] - 1s 273us/step - loss: 0.1845 - acc: 0.9342 - val_loss: 0.4224 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.82600\n",
      "Epoch 30/250\n",
      "4500/4500 [==============================] - 1s 268us/step - loss: 0.1876 - acc: 0.9327 - val_loss: 0.4154 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.82600\n",
      "Epoch 31/250\n",
      "4500/4500 [==============================] - 1s 283us/step - loss: 0.1729 - acc: 0.9398 - val_loss: 0.4188 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.82600\n",
      "Epoch 32/250\n",
      "4500/4500 [==============================] - 1s 283us/step - loss: 0.1757 - acc: 0.9387 - val_loss: 0.4209 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.82600\n",
      "Epoch 33/250\n",
      "4500/4500 [==============================] - 1s 273us/step - loss: 0.1728 - acc: 0.9398 - val_loss: 0.4180 - val_acc: 0.8080\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.82600\n",
      "Epoch 34/250\n",
      "4500/4500 [==============================] - 1s 273us/step - loss: 0.1654 - acc: 0.9440 - val_loss: 0.4168 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.82600\n",
      "Epoch 35/250\n",
      "4500/4500 [==============================] - 1s 274us/step - loss: 0.1692 - acc: 0.9411 - val_loss: 0.4196 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.82600\n",
      "Epoch 36/250\n",
      "4500/4500 [==============================] - 1s 274us/step - loss: 0.1637 - acc: 0.9451 - val_loss: 0.4173 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.82600\n",
      "Epoch 37/250\n",
      "4500/4500 [==============================] - 1s 275us/step - loss: 0.1662 - acc: 0.9444 - val_loss: 0.4203 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.82600\n",
      "Epoch 38/250\n",
      "4500/4500 [==============================] - 1s 273us/step - loss: 0.1626 - acc: 0.9436 - val_loss: 0.4216 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.82600\n",
      "Epoch 39/250\n",
      "4500/4500 [==============================] - 1s 270us/step - loss: 0.1623 - acc: 0.9460 - val_loss: 0.4200 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.82600\n",
      "Epoch 40/250\n",
      "4500/4500 [==============================] - 1s 271us/step - loss: 0.1636 - acc: 0.9491 - val_loss: 0.4180 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.82600\n",
      "Epoch 41/250\n",
      "4500/4500 [==============================] - 1s 272us/step - loss: 0.1615 - acc: 0.9464 - val_loss: 0.4184 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.82600\n",
      "Epoch 42/250\n",
      "4500/4500 [==============================] - 1s 278us/step - loss: 0.1622 - acc: 0.9460 - val_loss: 0.4190 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.82600\n",
      "Epoch 43/250\n",
      "4500/4500 [==============================] - 1s 270us/step - loss: 0.1525 - acc: 0.9529 - val_loss: 0.4223 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.82600\n",
      "Epoch 44/250\n",
      "4500/4500 [==============================] - 1s 277us/step - loss: 0.1546 - acc: 0.9487 - val_loss: 0.4177 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.82600\n",
      "Epoch 45/250\n",
      "4500/4500 [==============================] - 1s 278us/step - loss: 0.1563 - acc: 0.9498 - val_loss: 0.4170 - val_acc: 0.8080\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.82600\n",
      "Epoch 46/250\n",
      "4500/4500 [==============================] - 1s 278us/step - loss: 0.1536 - acc: 0.9491 - val_loss: 0.4165 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.82600\n",
      "Epoch 47/250\n",
      "4500/4500 [==============================] - 1s 271us/step - loss: 0.1535 - acc: 0.9520 - val_loss: 0.4201 - val_acc: 0.8080\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.82600\n",
      "Epoch 48/250\n",
      "4500/4500 [==============================] - 1s 271us/step - loss: 0.1451 - acc: 0.9553 - val_loss: 0.4224 - val_acc: 0.8180\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.82600\n",
      "Epoch 49/250\n",
      "4500/4500 [==============================] - 1s 269us/step - loss: 0.1460 - acc: 0.9531 - val_loss: 0.4175 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.82600\n",
      "Epoch 50/250\n",
      "4500/4500 [==============================] - 1s 270us/step - loss: 0.1524 - acc: 0.9513 - val_loss: 0.4170 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.82600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efc47ea09b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint('/tmp/cnn_elmo+fasttext_model.h5', save_best_only=True, monitor='val_acc', verbose=1)\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "\n",
    "model.fit([X_train, X_emb_train], y_train, \n",
    "          callbacks=[checkpointer, early_stopper],\n",
    "          validation_data=([X_dev, X_emb_dev], y_dev), epochs=250, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN + Elmo+Embeddings -- \n",
      "\n",
      "\n",
      "Evaluación sobre dev\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b58b94360c89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluación sobre dev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_emb_dev\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "print(\"CNN + Elmo+Embeddings -- \\n\\n\")\n",
    "print(\"Evaluación sobre dev\")\n",
    "\n",
    "model.load_weights(checkpointer.filepath)\n",
    "\n",
    "print_evaluation(model, [X_dev, X_emb_dev], y_dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without ELMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 40, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 38, 40)            36040     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 38, 40)            0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 36,081\n",
      "Trainable params: 36,081\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Dropout, Conv1D, CuDNNGRU, Input, Concatenate, Bidirectional, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "optimizer_args = {\n",
    "    \"lr\": 0.0015,\n",
    "    \"decay\": 0.005,\n",
    "}\n",
    "\n",
    "\n",
    "emb_input = Input(shape=X_emb_train[0].shape)\n",
    "\n",
    "x = emb_input\n",
    "x = Conv1D(filters=40, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.60)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=emb_input, outputs=[output])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/250\n",
      "4500/4500 [==============================] - 1s 246us/step - loss: 0.6211 - acc: 0.6658 - val_loss: 0.5560 - val_acc: 0.7540\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.75400, saving model to /tmp/cnn_model.h5\n",
      "Epoch 2/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.4992 - acc: 0.7591 - val_loss: 0.5264 - val_acc: 0.7260\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.75400\n",
      "Epoch 3/250\n",
      "4500/4500 [==============================] - 1s 157us/step - loss: 0.4658 - acc: 0.7778 - val_loss: 0.5043 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.75400 to 0.76400, saving model to /tmp/cnn_model.h5\n",
      "Epoch 4/250\n",
      "4500/4500 [==============================] - 1s 156us/step - loss: 0.4312 - acc: 0.8042 - val_loss: 0.4944 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.76400 to 0.76600, saving model to /tmp/cnn_model.h5\n",
      "Epoch 5/250\n",
      "4500/4500 [==============================] - 1s 169us/step - loss: 0.4034 - acc: 0.8187 - val_loss: 0.4894 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.76600 to 0.78200, saving model to /tmp/cnn_model.h5\n",
      "Epoch 6/250\n",
      "4500/4500 [==============================] - 1s 155us/step - loss: 0.3896 - acc: 0.8313 - val_loss: 0.4830 - val_acc: 0.7660\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.78200\n",
      "Epoch 7/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.3844 - acc: 0.8278 - val_loss: 0.4793 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.78200 to 0.78800, saving model to /tmp/cnn_model.h5\n",
      "Epoch 8/250\n",
      "4500/4500 [==============================] - 1s 170us/step - loss: 0.3682 - acc: 0.8384 - val_loss: 0.4793 - val_acc: 0.7600\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.78800\n",
      "Epoch 9/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.3565 - acc: 0.8484 - val_loss: 0.4748 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.78800\n",
      "Epoch 10/250\n",
      "4500/4500 [==============================] - 1s 163us/step - loss: 0.3518 - acc: 0.8524 - val_loss: 0.4691 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.78800\n",
      "Epoch 11/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.3374 - acc: 0.8602 - val_loss: 0.4668 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.78800\n",
      "Epoch 12/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.3304 - acc: 0.8691 - val_loss: 0.4705 - val_acc: 0.7620\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.78800\n",
      "Epoch 13/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.3300 - acc: 0.8596 - val_loss: 0.4602 - val_acc: 0.7800\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.78800\n",
      "Epoch 14/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.3170 - acc: 0.8716 - val_loss: 0.4577 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.78800 to 0.79000, saving model to /tmp/cnn_model.h5\n",
      "Epoch 15/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.3142 - acc: 0.8733 - val_loss: 0.4567 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.79000\n",
      "Epoch 16/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.3115 - acc: 0.8731 - val_loss: 0.4557 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.79000\n",
      "Epoch 17/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.3042 - acc: 0.8773 - val_loss: 0.4546 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.79000\n",
      "Epoch 18/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.3076 - acc: 0.8780 - val_loss: 0.4553 - val_acc: 0.7720\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.79000\n",
      "Epoch 19/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.3064 - acc: 0.8764 - val_loss: 0.4520 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.79000 to 0.79200, saving model to /tmp/cnn_model.h5\n",
      "Epoch 20/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.3020 - acc: 0.8791 - val_loss: 0.4504 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.79200 to 0.79800, saving model to /tmp/cnn_model.h5\n",
      "Epoch 21/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.2930 - acc: 0.8849 - val_loss: 0.4491 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.79800\n",
      "Epoch 22/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.2889 - acc: 0.8851 - val_loss: 0.4503 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.79800\n",
      "Epoch 23/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.2941 - acc: 0.8900 - val_loss: 0.4478 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.79800\n",
      "Epoch 24/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2852 - acc: 0.8884 - val_loss: 0.4471 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.79800\n",
      "Epoch 25/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2816 - acc: 0.8913 - val_loss: 0.4461 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.79800\n",
      "Epoch 26/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.2856 - acc: 0.8880 - val_loss: 0.4454 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.79800\n",
      "Epoch 27/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.2746 - acc: 0.8909 - val_loss: 0.4456 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.79800\n",
      "Epoch 28/250\n",
      "4500/4500 [==============================] - 1s 156us/step - loss: 0.2716 - acc: 0.8967 - val_loss: 0.4443 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00028: val_acc improved from 0.79800 to 0.80600, saving model to /tmp/cnn_model.h5\n",
      "Epoch 29/250\n",
      "4500/4500 [==============================] - 1s 163us/step - loss: 0.2752 - acc: 0.8942 - val_loss: 0.4445 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.80600\n",
      "Epoch 30/250\n",
      "4500/4500 [==============================] - 1s 173us/step - loss: 0.2697 - acc: 0.8982 - val_loss: 0.4418 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.80600\n",
      "Epoch 31/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.2645 - acc: 0.9000 - val_loss: 0.4411 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.80600\n",
      "Epoch 32/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2681 - acc: 0.9029 - val_loss: 0.4414 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.80600\n",
      "Epoch 33/250\n",
      "4500/4500 [==============================] - 1s 156us/step - loss: 0.2688 - acc: 0.8989 - val_loss: 0.4427 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.80600\n",
      "Epoch 34/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.2630 - acc: 0.9049 - val_loss: 0.4402 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.80600\n",
      "Epoch 35/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2659 - acc: 0.8953 - val_loss: 0.4390 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.80600\n",
      "Epoch 36/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.2662 - acc: 0.8996 - val_loss: 0.4400 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.80600\n",
      "Epoch 37/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2603 - acc: 0.8991 - val_loss: 0.4380 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.80600\n",
      "Epoch 38/250\n",
      "4500/4500 [==============================] - 1s 154us/step - loss: 0.2577 - acc: 0.9018 - val_loss: 0.4397 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.80600\n",
      "Epoch 39/250\n",
      "4500/4500 [==============================] - 1s 157us/step - loss: 0.2633 - acc: 0.9011 - val_loss: 0.4387 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.80600\n",
      "Epoch 40/250\n",
      "4500/4500 [==============================] - 1s 157us/step - loss: 0.2520 - acc: 0.9060 - val_loss: 0.4394 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.80600\n",
      "Epoch 41/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.2559 - acc: 0.9022 - val_loss: 0.4371 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.80600\n",
      "Epoch 42/250\n",
      "4500/4500 [==============================] - 1s 154us/step - loss: 0.2547 - acc: 0.9029 - val_loss: 0.4368 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.80600\n",
      "Epoch 43/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.2526 - acc: 0.9031 - val_loss: 0.4395 - val_acc: 0.7860\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.80600\n",
      "Epoch 44/250\n",
      "4500/4500 [==============================] - 1s 156us/step - loss: 0.2542 - acc: 0.9018 - val_loss: 0.4378 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.80600\n",
      "Epoch 45/250\n",
      "4500/4500 [==============================] - 1s 163us/step - loss: 0.2528 - acc: 0.9064 - val_loss: 0.4361 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.80600\n",
      "Epoch 46/250\n",
      "4500/4500 [==============================] - 1s 165us/step - loss: 0.2497 - acc: 0.9076 - val_loss: 0.4356 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.80600\n",
      "Epoch 47/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2476 - acc: 0.9053 - val_loss: 0.4359 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.80600\n",
      "Epoch 48/250\n",
      "4500/4500 [==============================] - 1s 156us/step - loss: 0.2390 - acc: 0.9100 - val_loss: 0.4344 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.80600\n",
      "Epoch 49/250\n",
      "4500/4500 [==============================] - 1s 155us/step - loss: 0.2406 - acc: 0.9133 - val_loss: 0.4348 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.80600\n",
      "Epoch 50/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.2417 - acc: 0.9156 - val_loss: 0.4339 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.80600\n",
      "Epoch 51/250\n",
      "4500/4500 [==============================] - 1s 168us/step - loss: 0.2431 - acc: 0.9140 - val_loss: 0.4332 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.80600\n",
      "Epoch 52/250\n",
      "4500/4500 [==============================] - 1s 172us/step - loss: 0.2432 - acc: 0.9107 - val_loss: 0.4332 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.80600\n",
      "Epoch 53/250\n",
      "4500/4500 [==============================] - 1s 166us/step - loss: 0.2357 - acc: 0.9158 - val_loss: 0.4335 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.80600\n",
      "Epoch 54/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.2377 - acc: 0.9111 - val_loss: 0.4335 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.80600\n",
      "Epoch 55/250\n",
      "4500/4500 [==============================] - 1s 163us/step - loss: 0.2322 - acc: 0.9158 - val_loss: 0.4340 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.80600\n",
      "Epoch 56/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2312 - acc: 0.9162 - val_loss: 0.4342 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.80600\n",
      "Epoch 57/250\n",
      "4500/4500 [==============================] - 1s 153us/step - loss: 0.2308 - acc: 0.9169 - val_loss: 0.4330 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.80600\n",
      "Epoch 58/250\n",
      "4500/4500 [==============================] - 1s 154us/step - loss: 0.2320 - acc: 0.9180 - val_loss: 0.4332 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.80600\n",
      "Epoch 59/250\n",
      "4500/4500 [==============================] - 1s 163us/step - loss: 0.2339 - acc: 0.9131 - val_loss: 0.4327 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.80600\n",
      "Epoch 60/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.2326 - acc: 0.9162 - val_loss: 0.4354 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.80600\n",
      "Epoch 61/250\n",
      "4500/4500 [==============================] - 1s 164us/step - loss: 0.2297 - acc: 0.9140 - val_loss: 0.4318 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.80600\n",
      "Epoch 62/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2297 - acc: 0.9136 - val_loss: 0.4321 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.80600\n",
      "Epoch 63/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.2364 - acc: 0.9162 - val_loss: 0.4321 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.80600\n",
      "Epoch 64/250\n",
      "4500/4500 [==============================] - 1s 170us/step - loss: 0.2273 - acc: 0.9144 - val_loss: 0.4316 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.80600\n",
      "Epoch 65/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.2270 - acc: 0.9187 - val_loss: 0.4304 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.80600\n",
      "Epoch 66/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2271 - acc: 0.9187 - val_loss: 0.4313 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.80600\n",
      "Epoch 67/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2303 - acc: 0.9171 - val_loss: 0.4318 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.80600\n",
      "Epoch 68/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.2263 - acc: 0.9187 - val_loss: 0.4309 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.80600\n",
      "Epoch 69/250\n",
      "4500/4500 [==============================] - 1s 169us/step - loss: 0.2253 - acc: 0.9218 - val_loss: 0.4311 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.80600\n",
      "Epoch 70/250\n",
      "4500/4500 [==============================] - 1s 165us/step - loss: 0.2238 - acc: 0.9213 - val_loss: 0.4313 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.80600\n",
      "Epoch 71/250\n",
      "4500/4500 [==============================] - 1s 163us/step - loss: 0.2293 - acc: 0.9171 - val_loss: 0.4310 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.80600\n",
      "Epoch 72/250\n",
      "4500/4500 [==============================] - 1s 166us/step - loss: 0.2198 - acc: 0.9236 - val_loss: 0.4310 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.80600\n",
      "Epoch 73/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2263 - acc: 0.9176 - val_loss: 0.4309 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.80600\n",
      "Epoch 74/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.2201 - acc: 0.9216 - val_loss: 0.4314 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.80600\n",
      "Epoch 75/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.2181 - acc: 0.9280 - val_loss: 0.4305 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.80600\n",
      "Epoch 76/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2190 - acc: 0.9178 - val_loss: 0.4322 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.80600\n",
      "Epoch 77/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2189 - acc: 0.9216 - val_loss: 0.4302 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.80600\n",
      "Epoch 78/250\n",
      "4500/4500 [==============================] - 1s 163us/step - loss: 0.2245 - acc: 0.9164 - val_loss: 0.4300 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.80600\n",
      "Epoch 79/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2179 - acc: 0.9240 - val_loss: 0.4316 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.80600\n",
      "Epoch 80/250\n",
      "4500/4500 [==============================] - 1s 163us/step - loss: 0.2164 - acc: 0.9193 - val_loss: 0.4296 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.80600\n",
      "Epoch 81/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.2187 - acc: 0.9209 - val_loss: 0.4306 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.80600\n",
      "Epoch 82/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2188 - acc: 0.9191 - val_loss: 0.4297 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.80600\n",
      "Epoch 83/250\n",
      "4500/4500 [==============================] - 1s 157us/step - loss: 0.2157 - acc: 0.9207 - val_loss: 0.4302 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.80600\n",
      "Epoch 84/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2164 - acc: 0.9276 - val_loss: 0.4294 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.80600\n",
      "Epoch 85/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2177 - acc: 0.9218 - val_loss: 0.4299 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.80600\n",
      "Epoch 86/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2121 - acc: 0.9269 - val_loss: 0.4302 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.80600\n",
      "Epoch 87/250\n",
      "4500/4500 [==============================] - 1s 155us/step - loss: 0.2135 - acc: 0.9256 - val_loss: 0.4299 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.80600\n",
      "Epoch 88/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2084 - acc: 0.9284 - val_loss: 0.4290 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.80600\n",
      "Epoch 89/250\n",
      "4500/4500 [==============================] - 1s 165us/step - loss: 0.2152 - acc: 0.9220 - val_loss: 0.4279 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.80600\n",
      "Epoch 90/250\n",
      "4500/4500 [==============================] - 1s 164us/step - loss: 0.2068 - acc: 0.9289 - val_loss: 0.4286 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.80600\n",
      "Epoch 91/250\n",
      "4500/4500 [==============================] - 1s 172us/step - loss: 0.2119 - acc: 0.9251 - val_loss: 0.4297 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.80600\n",
      "Epoch 92/250\n",
      "4500/4500 [==============================] - 1s 170us/step - loss: 0.2116 - acc: 0.9216 - val_loss: 0.4287 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.80600\n",
      "Epoch 93/250\n",
      "4500/4500 [==============================] - 1s 163us/step - loss: 0.2041 - acc: 0.9291 - val_loss: 0.4274 - val_acc: 0.8120\n",
      "\n",
      "Epoch 00093: val_acc improved from 0.80600 to 0.81200, saving model to /tmp/cnn_model.h5\n",
      "Epoch 94/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.2089 - acc: 0.9267 - val_loss: 0.4286 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.81200\n",
      "Epoch 95/250\n",
      "4500/4500 [==============================] - 1s 166us/step - loss: 0.2137 - acc: 0.9213 - val_loss: 0.4302 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.81200\n",
      "Epoch 96/250\n",
      "4500/4500 [==============================] - 1s 164us/step - loss: 0.2097 - acc: 0.9298 - val_loss: 0.4286 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.81200\n",
      "Epoch 97/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2031 - acc: 0.9289 - val_loss: 0.4277 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.81200\n",
      "Epoch 98/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.2039 - acc: 0.9280 - val_loss: 0.4277 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.81200\n",
      "Epoch 99/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.2134 - acc: 0.9216 - val_loss: 0.4270 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.81200\n",
      "Epoch 100/250\n",
      "4500/4500 [==============================] - 1s 163us/step - loss: 0.2064 - acc: 0.9313 - val_loss: 0.4288 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.81200\n",
      "Epoch 101/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2044 - acc: 0.9289 - val_loss: 0.4301 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.81200\n",
      "Epoch 102/250\n",
      "4500/4500 [==============================] - 1s 157us/step - loss: 0.2033 - acc: 0.9320 - val_loss: 0.4285 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.81200\n",
      "Epoch 103/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2036 - acc: 0.9307 - val_loss: 0.4289 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.81200\n",
      "Epoch 104/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.2034 - acc: 0.9269 - val_loss: 0.4282 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.81200\n",
      "Epoch 105/250\n",
      "4500/4500 [==============================] - 1s 168us/step - loss: 0.2099 - acc: 0.9218 - val_loss: 0.4277 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.81200\n",
      "Epoch 106/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2074 - acc: 0.9253 - val_loss: 0.4272 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.81200\n",
      "Epoch 107/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.2074 - acc: 0.9291 - val_loss: 0.4283 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.81200\n",
      "Epoch 108/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.2014 - acc: 0.9316 - val_loss: 0.4275 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.81200\n",
      "Epoch 109/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.1979 - acc: 0.9298 - val_loss: 0.4282 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.81200\n",
      "Epoch 110/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2007 - acc: 0.9289 - val_loss: 0.4287 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.81200\n",
      "Epoch 111/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.2057 - acc: 0.9240 - val_loss: 0.4281 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.81200\n",
      "Epoch 112/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.2051 - acc: 0.9260 - val_loss: 0.4281 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.81200\n",
      "Epoch 113/250\n",
      "4500/4500 [==============================] - 1s 175us/step - loss: 0.2080 - acc: 0.9240 - val_loss: 0.4286 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.81200\n",
      "Epoch 114/250\n",
      "4500/4500 [==============================] - 1s 169us/step - loss: 0.2053 - acc: 0.9271 - val_loss: 0.4293 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.81200\n",
      "Epoch 115/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.1991 - acc: 0.9282 - val_loss: 0.4302 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.81200\n",
      "Epoch 116/250\n",
      "4500/4500 [==============================] - 1s 159us/step - loss: 0.2022 - acc: 0.9342 - val_loss: 0.4265 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.81200\n",
      "Epoch 117/250\n",
      "4500/4500 [==============================] - 1s 153us/step - loss: 0.1984 - acc: 0.9329 - val_loss: 0.4276 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00117: val_acc did not improve from 0.81200\n",
      "Epoch 118/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.2047 - acc: 0.9262 - val_loss: 0.4270 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.81200\n",
      "Epoch 119/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.1976 - acc: 0.9267 - val_loss: 0.4256 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.81200\n",
      "Epoch 120/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.2030 - acc: 0.9296 - val_loss: 0.4274 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.81200\n",
      "Epoch 121/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.1963 - acc: 0.9349 - val_loss: 0.4281 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.81200\n",
      "Epoch 122/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.1941 - acc: 0.9327 - val_loss: 0.4258 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.81200\n",
      "Epoch 123/250\n",
      "4500/4500 [==============================] - 1s 168us/step - loss: 0.2010 - acc: 0.9331 - val_loss: 0.4267 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.81200\n",
      "Epoch 124/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.1992 - acc: 0.9331 - val_loss: 0.4262 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.81200\n",
      "Epoch 125/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.1993 - acc: 0.9324 - val_loss: 0.4272 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.81200\n",
      "Epoch 126/250\n",
      "4500/4500 [==============================] - 1s 157us/step - loss: 0.1949 - acc: 0.9389 - val_loss: 0.4279 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.81200\n",
      "Epoch 127/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.1950 - acc: 0.9344 - val_loss: 0.4282 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.81200\n",
      "Epoch 128/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.2005 - acc: 0.9333 - val_loss: 0.4278 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.81200\n",
      "Epoch 129/250\n",
      "4500/4500 [==============================] - 1s 165us/step - loss: 0.1960 - acc: 0.9338 - val_loss: 0.4289 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.81200\n",
      "Epoch 130/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.1961 - acc: 0.9304 - val_loss: 0.4273 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.81200\n",
      "Epoch 131/250\n",
      "4500/4500 [==============================] - 1s 161us/step - loss: 0.1943 - acc: 0.9338 - val_loss: 0.4262 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.81200\n",
      "Epoch 132/250\n",
      "4500/4500 [==============================] - 1s 162us/step - loss: 0.1960 - acc: 0.9342 - val_loss: 0.4264 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.81200\n",
      "Epoch 133/250\n",
      "4500/4500 [==============================] - 1s 157us/step - loss: 0.1949 - acc: 0.9329 - val_loss: 0.4257 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.81200\n",
      "Epoch 134/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.1930 - acc: 0.9313 - val_loss: 0.4280 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.81200\n",
      "Epoch 135/250\n",
      "4500/4500 [==============================] - 1s 160us/step - loss: 0.1919 - acc: 0.9376 - val_loss: 0.4265 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.81200\n",
      "Epoch 136/250\n",
      "4500/4500 [==============================] - 1s 158us/step - loss: 0.1949 - acc: 0.9324 - val_loss: 0.4271 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.81200\n",
      "Epoch 137/250\n",
      "4500/4500 [==============================] - 1s 164us/step - loss: 0.1895 - acc: 0.9362 - val_loss: 0.4271 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.81200\n",
      "Epoch 138/250\n",
      "4500/4500 [==============================] - 1s 166us/step - loss: 0.1917 - acc: 0.9364 - val_loss: 0.4272 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.81200\n",
      "Epoch 139/250\n",
      "4500/4500 [==============================] - 1s 157us/step - loss: 0.1853 - acc: 0.9382 - val_loss: 0.4267 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.81200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efc6c566550>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint('/tmp/cnn_only_fasttext_model.h5', save_best_only=True, monitor='val_acc', verbose=1)\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=20)\n",
    "\n",
    "\n",
    "model.fit(X_emb_train, y_train, \n",
    "          callbacks=[checkpointer, early_stopper],\n",
    "          validation_data=(X_emb_dev, y_dev), epochs=250, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN + Embeddings -- \n",
      "\n",
      "\n",
      "Evaluación sobre dev\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-22f124b62140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluación sobre dev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_emb_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "print(\"CNN + Embeddings -- \\n\\n\")\n",
    "print(\"Evaluación sobre dev\")\n",
    "\n",
    "model.load_weights(checkpointer.filepath)\n",
    "\n",
    "print_evaluation(model, X_emb_dev, y_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
