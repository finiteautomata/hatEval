{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM  + ElMO\n",
    "\n",
    "En esta, rehacemos todo lo de ElMO pero usando nuestra nueva clase: ElMOModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancias de entrenamiento: 4500\n",
      "Instancias de desarrollo: 500\n",
      "Instancias de test: 1600\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "df_dev = pd.read_table(\"../../../data/es/dev_es.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "df_train = pd.read_table(\"../../../data/es/train_es.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "df_test = pd.read_table(\"../../../data/es/test_es.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "\n",
    "print(\"Instancias de entrenamiento: {}\".format(len(df_train)))\n",
    "print(\"Instancias de desarrollo: {}\".format(len(df_dev)))\n",
    "print(\"Instancias de test: {}\".format(len(df_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tengo que hacer dos cosas:\n",
    "\n",
    "- Primero, convertir los tweets a secuencias de texto\n",
    "- Luego, paddear las secuencias a cierta longitud (Keras necesita esto para poder paralelizar c√°lculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hate.nn.preprocessing import Tokenizer\n",
    "\n",
    "tokenize_args = {\n",
    "    \"preserve_case\": False, \n",
    "    \"deaccent\": False,\n",
    "    \"reduce_len\": True, \n",
    "    \"strip_handles\": False,\n",
    "    \"alpha_only\": True,\n",
    "    \"stem\": False\n",
    "}\n",
    "\n",
    "tokenizer = Tokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "\n",
    "tokens_train = [tokenizer.tokenize(tweet) for tweet in df_train[\"text\"].values]\n",
    "tokens_dev = [tokenizer.tokenize(tweet) for tweet in df_dev[\"text\"].values]\n",
    "tokens_test = [tokenizer.tokenize(tweet) for tweet in df_test[\"text\"].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las distribuciones de las longitudes de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de longitud: train 22.91 dev 23.33 test 23.33\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmAAAADFCAYAAADzJU6kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGNZJREFUeJzt3X+s3XWd5/Hna0Bx/LHyq2lqabfdtaNhTARyAxgnExb8RTFTJ1GCa7S6TTrJ4gyObobi/oEzalITRwbjhqROGcE4AiKzNEh0sWKMyVhtkVWgsnSwSJtCqxZ0hqhTfe8f53PxUC/cH+ee7zn33ucjubnn+/l+zznve9p37vt+P79SVUiSJKk7vzfqACRJkpYaCzBJkqSOWYBJkiR1zAJMkiSpYxZgkiRJHbMAkyRJ6pgFmCRJUscswCRJkjpmASZJktSxE0cdwHM5/fTTa82aNaMOQwJgz549P66qZaOMwZzQODEnpGeaTU6MdQG2Zs0adu/ePeowJACSPDLqGMwJjRNzQnqm2eSEXZCSJEkdswCTJEnqmAWYJElSxyzAJElDkeQFSb6d5P8muT/JX7f2tUl2JdmX5OYkz2/tJ7Xjfe38mlHGLw2TBZgkaVh+CVxYVa8GzgLelOR84GPANVX1cuAosKldvwk42tqvaddJi9JYz4IcpjVbvjTn5+7fesk8RiKNB3NC862qCvjXdvi89lXAhcB/be03AB8CrgM2tMcAtwKfSpL2OgvKXPPJXFo6vAMmSRqaJCckuRc4DNwF/AvwRFUda5ccAFa2xyuBRwHa+SeB07qNWOqGBZgkaWiq6tdVdRZwBnAu8MpBXzPJ5iS7k+w+cuTIwDFKo2ABJkkauqp6ArgbeA1wcpLJITBnAAfb44PAKoB2/qXAT6Z4rW1VNVFVE8uWjXQhfmnOLMAkSUORZFmSk9vj3wdeD+ylV4i9tV22Ebi9Pd7Rjmnnv7YQx39JM7FkB+FLkoZuBXBDkhPo/cF/S1XdkeQB4KYkHwG+C2xv128HPptkH/BT4LJRBC11wQJMkjQUVfU94Owp2h+mNx7s+PZfAG/rIDRp5OyClCRJ6pgFmDSPklyf5HCS+/raTk1yV5KH2vdTWnuSfLKt+v29JOeMLnJJUpcswKT59RngTce1bQF2VtU6YGc7BrgYWNe+NtNbiFKStARYgEnzqKq+QW/wcL8N9Fb7pn1/S1/7jdXzLXpT81d0E6kkaZQswKThW15Vh9rjx4Dl7fHTq343/SuCP81FJyVp8bEAkzrU1jSa1bpGLjopSYuPBZg0fI9Pdi2274db+9Orfjf9K4JLkhYx1wGThm9yde+t/O6q3+9NchNwHvBkX1flgrJmy5fm9Lz9Wy+Z50gkaWGY9g7YfE2rT7KxXf9Qko1TvZe00CX5PPDPwCuSHEiyiV7h9fokDwGva8cAdwIPA/uATwP/fQQhS5JGYCZ3wD4DfAq4sa9tclr91iRb2vGVPHNa/Xn0ptWfl+RU4Gpggt74lz1JdlTV0fn6QaRxUFVvf5ZTF01xbQGXDzciSdI4mvYO2DxNq38jcFdV/bQVXXfxu2slSZIkLQlzHQM222n1M5puD70p9/QWpWT16tVzDE+SpIVnruMpwTGVC83Ag/CrqpLMalr9NK+3DdgGMDExMW+vO59MEEmSNIi5FmCPJ1lRVYdmOK3+IHDBce1fn+N7S5I0dIP8sS1NZ67rgE1Oq4ffnVb/rjYb8nx+O63+K8AbkpzSZky+obVJkiQtOdPeAWvT6i8ATk9ygN5sxq3ALW2K/SPApe3yO4H19KbVPwW8B6Cqfprkw8B32nV/U1XHD+yXJElaEqYtwOZrWn1VXQ9cP6voJEmSFiG3IpIkDUWSVUnuTvJAkvuTXNHaP5TkYJJ729f6vudc1RbzfjDJG0cXvTRcbkUkSRqWY8AHquqeJC+htwj3Xe3cNVX18f6Lk5wJXAb8IfAy4KtJ/qCqft1p1FIHvAMmSRqKqjpUVfe0xz8H9vIsa0A2G4CbquqXVfVDeuOJzx1+pFL3LMAkSUOXZA1wNrCrNb237Rl8/eR+wsxw0e4km5PsTrL7yJEjQ4xaGh4LMEnSUCV5MfBF4H1V9TN6+wT/Z+As4BDwt7N5varaVlUTVTWxbNmyeY9X6oIFmCRpaJI8j17x9bmqug2gqh6vql9X1W+AT/PbbsZnW8xbWnQswCRJQ5EkwHZgb1V9oq99Rd9lfwrc1x7vAC5LclKStcA64NtdxSt1yVmQkqRheS3wTuD7Se5tbR8E3p7kLKCA/cCfAVTV/UluAR6gN4PycmdAarGyAJM0Mm5sv7hV1TeBTHHqzud4zkeBjw4tKGlM2AUpSZLUMQswSZKkjlmASZIkdcwCTJIkqWMWYFIHkvxl24z4viSfT/KCJGuT7GobD9+c5PmjjlOS1A0LMGnIkqwE/gKYqKpXASfQ23D4Y/Q2JH45cBTYNLooJUldsgCTunEi8PtJTgReSG/7lQuBW9v5G4C3jCg2SVLHLMCkIauqg8DHgR/RK7yeBPYAT1TVsXbZlJsOgxsPS9Ji5EKs0pAlOQXYAKwFngC+ALxpps+vqm3ANoCJiYkaRozSYjXIYr/SMHkHTBq+1wE/rKojVfXvwG30tmg5uXVJgpsOS9KSMlABNpuZXW1z1Ztb+64ka+bjB5AWgB8B5yd5Yduc+CJ6e93dDby1XbMRuH1E8UmSOjbnAmwOM7s2AUdb+zXtOmnRq6pd9Abb3wN8n17ebQOuBN6fZB9wGrB9ZEFKkjo1aBfkbGZ2bWjHtPMXtbsB0qJXVVdX1Sur6lVV9c6q+mVVPVxV51bVy6vqbVX1y1HHKUnqxpwLsDnM7FoJPNqee6xdf9rxr+uML0mStNgN0gXZP7PrZcCLmMXMrmdTVduqaqKqJpYtWzboy0mSJI2dQbogZzuz6yCwCqCdfynwkwHeX5IkaUEapACb7cyuHe2Ydv5rVeWaRpIkacmZ80KsVbUryeTMrmPAd+nN7PoScFOSj7S2yZld24HPthlfP6U3Y3IgLrAnSeMrySrgRmA5UMC2qro2yanAzcAaYD9waVUdbX/MXwusB54C3l1V94widmnYBloJv6quBq4+rvlh4Nwprv0F8LZB3k+StKAcAz5QVfckeQmwJ8ldwLuBnVW1NckWYAu9ZVkuBta1r/OA69p3adFxJXxJ0lBU1aHJO1hV9XNgL70Z8f3LEh2/XNGN1fMtemOKV3QcttQJCzBJ0tC13U/OBnYBy6vqUDv1GL0uSuhbrqiZcpN6lyvSYmABJkkaqiQvBr4IvK+qftZ/rk3GmtWELJcr0mJgASZJGpokz6NXfH2uqm5rzY9Pdi2274db+9PLFTVuUq9FywJMkjQUbVbjdmBvVX2i71T/skTHL1f0rvScDzzZ11UpLSoDzYKUJOk5vBZ4J/D9JPe2tg8CW4FbkmwCHgEubefupLcExT56y1C8p9twpe5YgEmShqKqvgnkWU5fNMX1BVw+1KCkMWEXpCRJUscswCRJkjpmASZJktQxCzBJkqSOWYBJkiR1zAJMkiSpYxZgkiRJHbMAkzqQ5OQktyb5QZK9SV6T5NQkdyV5qH0/ZdRxSpK6YQEmdeNa4MtV9Urg1cBeYAuws6rWATvbsSRpCbAAk4YsyUuBP6a3Jx5V9auqegLYANzQLrsBeMtoIpQkdc2tiDq2ZsuX5vS8/VsvmedI1KG1wBHgH5K8GtgDXAEs79to+DFg+VRPTrIZ2AywevXq4UcrSRq6ge6AzWZcS9vd/pNJ9iX5XpJz5udHkMbeicA5wHVVdTbwbxzX3dj2wKupnlxV26pqoqomli1bNvRgJUnDN+gdsMlxLW9N8nzghfR2ut9ZVVuTbKH3i+ZK4GJgXfs6D7iufZcWuwPAgara1Y5vpZcXjydZUVWHkqwADo8sQkkL3lx7WMBellGY8x2wOYxr2QDcWD3fAk5uv3SkRa2qHgMeTfKK1nQR8ACwA9jY2jYCt48gPEnSCAxyB2y241pWAo/2Pf9AazvU1+Z4Fy1Wfw58rt0pfhh4D70/gG5Jsgl4BLh0hPFJkjo0SAE2Oa7lz6tqV5JrmWJcS5Ipx7U8m6raBmwDmJiYmNVzpXFVVfcCE1OcuqjrWCRJozfIIPypxrWcQxvXAnDcuJaDwKq+55/R2iRJkpaUORdgcxjXsgN4V5sNeT7wZF9XpSRpkUlyfZLDSe7ra/tQkoNJ7m1f6/vOXdVmyj+Y5I2jiVrqxqCzIGczruVOYD2wD3iqXStJWrw+A3wKuPG49muq6uP9DUnOBC4D/hB4GfDVJH9QVb/uIlCpawMVYLMZ19LWObp8kPeTJC0cVfWNJGtmePkG4Kaq+iXwwyT7gHOBfx5SeNJIuRWRJKlr720Lcl/ftwn9s82U/x1JNifZnWT3kSNHhh2rNBRuRSQtIoMsxCh15Drgw/R2fvgw8LfAf5vNCzhbXouBd8AkSZ2pqser6tdV9Rvg0/S6GcGZ8lpiLMAkSZ05bgeUPwUmZ0juAC5LclKStfS2rft21/FJXbELUpI0FEk+D1wAnJ7kAHA1cEGSs+h1Qe4H/gygqu5Pcgu95YyOAZc7A1KLmQWYJGkoqurtUzRvf47rPwp8dHgRSePDLkhJkqSOeQdM0oI0yIzP/VsvmcdIJGn2vAMmSZLUMQswSZKkjlmASZIkdcwCTJIkqWMWYJIkSR2zAJMkSeqYBZgkSVLHLMAkSZI65kKsUkeSnADsBg5W1ZvbhsM3AacBe4B3VtWvRhmjJM2WiyLPjXfApO5cAeztO/4YcE1VvRw4CmwaSVSSpM5ZgEkdSHIGcAnw9+04wIXAre2SG4C3jCY6SVLXBi7AkpyQ5LtJ7mjHa5PsSrIvyc1Jnt/aT2rH+9r5NYO+t7SA/B3wV8Bv2vFpwBNVdawdHwBWTvXEJJuT7E6y+8iRI8OPVJI0dPNxB2ym3SqbgKOt/Zp2nbToJXkzcLiq9szl+VW1raomqmpi2bJl8xydJGkUBirAZtmtsqEd085f1K6XFrvXAn+SZD+9QfcXAtcCJyeZnAhzBnBwNOFJkro26CzIyW6Vl7Tj5+pWWQk8ClBVx5I82a7/cf8LJtkMbAZYvXr1gOEtHs4yWbiq6irgKoAkFwD/o6rekeQLwFvpFWUbgdtHFqQ0BEmuBybvAL+qtZ0K3AysAfYDl1bV0fYH+bXAeuAp4N1Vdc8o4pa6MOcCrL9bpf1SmRdVtQ3YBjAxMVHz9brSGLoSuCnJR4DvAttHHI+GbAn+IfUZ4FPAjX1tW4CdVbU1yZZ2fCVwMbCufZ0HXNe+S4vSIHfAJrtV1gMvAP4Dfd0q7S5Yf7fKQWAVcKB1u7wU+MkA7y8tOFX1deDr7fHDwLmjjEcapqr6xhQTrjYAF7THN9DLhytb+41VVcC3kpycZEVVHeomWqlbcx4DVlVXVdUZVbUGuAz4WlW9A7ibXrcKPLNbZUc7pp3/Wks0SdLSsbyvqHoMWN4ePz1MpXFmsBa1YawDdiXw/iT76I3xmuxW2Q6c1trfT++2syRpiWp/hM/6D3FnBmsxmJetiGbSrVJVvwDeNh/vJ0mDWIJjscbJ45Ndi0lWAIdb++QwlUnODNai5l6QkqQuTQ5H2crvDlN5b5Kb6A2+f9LxX90Z5I8SzY0FmCRpKJJ8nt6A+9OTHACupld43ZJkE/AIcGm7/E56S1Dso7cMxXs6D1jqkAWYJGkoqurtz3LqoimuLeDy4UYkjQ8345YkSeqYBZgkSVLH7IKUJEkjsZRnJFuALQFL+T+4JEnjyC5ISZKkjlmASZIkdcwCTJIkqWMWYJIkSR1zEL4kzYJbtkiaD94BkyRJ6pgFmCRJUscswCRJkjpmASZJktQxCzBJkqSOOQtSGrIkq4AbgeVAAduq6tokpwI3A2uA/cClVXV0VHFK0kKy0LfZm/MdsCSrktyd5IEk9ye5orWfmuSuJA+176e09iT5ZJJ9Sb6X5Jz5+iGkMXcM+EBVnQmcD1ye5ExgC7CzqtYBO9uxJGkJGKQLcra/VC4G1rWvzcB1A7y3tGBU1aGquqc9/jmwF1gJbABuaJfdALxlNBFKkro25wJsDr9UNgA3Vs+3gJOTrJhz5NIClGQNcDawC1heVYfaqcfodVFO9ZzNSXYn2X3kyJFO4pSGLcn+JN9Pcm+S3a1tyh4UaTGalzFgM/ylshJ4tO9pB1rbob42kmymd4eM1atXz0d4GsBC72MfJ0leDHwReF9V/SzJ0+eqqpLUVM+rqm3ANoCJiYkpr5EWqP9SVT/uO57sQdmaZEs7vnI0oUnDNfAsyON/qfSfq6qiN+h4xqpqW1VNVNXEsmXLBg1PGgtJnkcvTz5XVbe15scn7wK374dHFZ80JuyW15IxUAE2y18qB4FVfU8/o7VJi1p6t7q2A3ur6hN9p3YAG9vjjcDtXccmjVAB/yfJntbzAXbLawkZZBbkbH+p7ADe1WZDng882Zdo0mL2WuCdwIVtvMu9SdYDW4HXJ3kIeF07lpaKP6qqc+hN0Lo8yR/3n3yuHhR7SrQYDDIGbPKXyveT3NvaPkjvl8gtSTYBjwCXtnN3AuuBfcBTwHsGeG9pwaiqbwJ5ltMXdRmLNC6q6mD7fjjJPwHn0npQquqQ3fJa7OZcgM32l0r7a+byub6fJGlxSPIi4Peq6uft8RuAv+G3PShbsVtei5wr4UuSurYc+Kc2E/hE4B+r6stJvsPUPSjSomMBJknqVFU9DLx6ivafYLe8lgg345YkSeqYBZgkSVLHLMAkSZI6ZgEmSZLUMQswSZKkjlmASZIkdcwCTJIkqWOuAyZJC8CaLV+a83P3b71kHiORNB+8AyZJktQxCzBJkqSO2QUpSZKWlHHo0vcOmCRJUscswCRJkjpmF6SGZhxu8UqSNI4swCRpkfOPIWn82AUpSZLUMQswSZKkjnVegCV5U5IHk+xLsqXr95fGjTkhPZM5oaWg0zFgSU4A/hfweuAA8J0kO6rqgS7j0PhbKmNWzAnpmcwJLRVd3wE7F9hXVQ9X1a+Am4ANHccgjRNzQnomc0JLQtezIFcCj/YdHwDO678gyWZgczv81yQPTvE6pwM/HkqEc2dM0+sknnxsVpfPJqb/OOtgpjcfOTFu/84ztRDjXnIxT5NP5sT8Mu5uzSnu+cqJsVuGoqq2Adue65oku6tqoqOQZsSYpjdu8cB4xnS86XJiIfwMU1mIcRvzeDAnxotxz03XXZAHgVV9x2e0NmmpMiekZzIntCR0XYB9B1iXZG2S5wOXATs6jkEaJ+aE9EzmhJaETrsgq+pYkvcCXwFOAK6vqvvn8FLP2UU5IsY0vXGLB0Yc0zzlxDh+rjOxEOM25iEzJxYk456DVNUo31+SJGnJcSV8SZKkjlmASZIkdWxBFWDjsD1FklVJ7k7yQJL7k1zR2k9NcleSh9r3U0YQ2wlJvpvkjna8Nsmu9nnd3Aa0dhnPyUluTfKDJHuTvGbUn1OSv2z/bvcl+XySF4z6cxrEOOTEdMY5Z6Yzbjk1E+OYd11aCDkB5sUojFtuLJgCLL/dnuJi4Ezg7UnOHEEox4APVNWZwPnA5S2OLcDOqloH7GzHXbsC2Nt3/DHgmqp6OXAU2NRxPNcCX66qVwKvbrGN7HNKshL4C2Ciql5Fb4DvZYz+c5qTMcqJ6Yxzzkxn3HJqJsYq77q0gHICzItRGK/cqKoF8QW8BvhK3/FVwFVjENft9PYsexBY0dpWAA92HMcZ7T/PhcAdQOit8HviVJ9fB/G8FPghbaJHX/vIPid+u8L2qfRmAN8BvHGUn9OAP89Y5sQM4h6LnJlBnGOVUzOMeezyruOff0HmRIvVvBhu3GOXGwvmDhhTb0+xckSxAJBkDXA2sAtYXlWH2qnHgOUdh/N3wF8Bv2nHpwFPVNWxdtz157UWOAL8Q7tV/fdJXsQIP6eqOgh8HPgRcAh4EtjDaD+nQYxdTkxnzHJmOuOWUzMxdnnXsQWXE2BedGTscmMhFWBjJcmLgS8C76uqn/Wfq14p3dn6HkneDByuqj1dvecMnAicA1xXVWcD/8Zxt3ZH8DmdQm9T37XAy4AXAW/q6v2XunHKmemMaU7NxNjlnZ6bedGZscuNhVSAjc32FEmeRy9hPldVt7Xmx5OsaOdXAIc7DOm1wJ8k2Q/cRO/W8LXAyUkmF9vt+vM6AByoql3t+FZ6//lH+Tm9DvhhVR2pqn8HbqP32Y3ycxrE2OTEdMYwZ6Yzjjk1E+OYd11aMDkB5kXHxi43FlIBNhbbUyQJsB3YW1Wf6Du1A9jYHm+k15/fiaq6qqrOqKo19D6Xr1XVO4C7gbeOKKbHgEeTvKI1XQQ8wAg/J3pdj+cneWH7d5yMaWSf04DGIiemM445M51xzKmZGNO869KCyAkwL7o2lrkx6oFxs/kC1gP/D/gX4H+OKIY/oneL8nvAve1rPb1+8J3AQ8BXgVNHFN8FwB3t8X8Cvg3sA74AnNRxLGcBu9tn9b+BU0b9OQF/DfwAuA/4LHDSqD+nAX+ekefEDGIc65yZQfxjk1MzjHfs8q7jn3/sc6LFaV50H/NY5YZbEUmSJHVsIXVBSpIkLQoWYJIkSR2zAJMkSeqYBZgkSVLHLMAkSZI6ZgEmSZLUMQswSZKkjv1/BtUC+3HmWI4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
    "\n",
    "train_lens = np.array([len(t) for t in tokens_train]) \n",
    "dev_lens = np.array([len(t) for t in tokens_dev])\n",
    "test_lens = np.array([len(t) for t in tokens_test])\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "\n",
    "plt.hist(train_lens)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(dev_lens)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(test_lens)\n",
    "\n",
    "print(\"Media de longitud: train {:.2f} dev {:.2f} test {:.2f}\".format(train_lens.mean(), dev_lens.mean(), test_lens.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 52., 107.,  98.,  85.,  48.,  34.,  26.,  37.,   9.,   4.]),\n",
       " array([ 1. ,  7.6, 14.2, 20.8, 27.4, 34. , 40.6, 47.2, 53.8, 60.4, 67. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(t) for t in tokens_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-19 23:15:30,432 INFO: char embedding size: 2637\n",
      "2019-01-19 23:15:32,608 INFO: word embedding size: 185214\n",
      "2019-01-19 23:15:43,247 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(185214, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2637, 50, padding_idx=2634)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from elmoformanylangs import Embedder\n",
    "\n",
    "e = Embedder(\"../../../models/elmo/es/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Elmo_Input (InputLayer)      (None, 60, 1024)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 256)               1180672   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_elmo (Dense)           (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,213,697\n",
      "Trainable params: 1,213,697\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-19 23:20:09,402 INFO: 71 batches, avg len: 62.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-6950d43664ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/projects/hatEval/hate/nn/base_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/hatEval/hate/nn/elmo_model.py\u001b[0m in \u001b[0;36mpreprocess_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mlist_of_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mpadded_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist_of_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/hateval/lib/python3.6/site-packages/elmoformanylangs/elmo.py\u001b[0m in \u001b[0;36msents2elmo\u001b[0;34m(self, sents, output_layer)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mafter_elmo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_lens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/hateval/lib/python3.6/site-packages/elmoformanylangs/frontend.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_inp, chars_package, mask_package)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mtoken_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_embedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchars_package\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask_package\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_package\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoder'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'elmo'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_package\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_package\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/hateval/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/hateval/lib/python3.6/site-packages/elmoformanylangs/modules/token_embedder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, word_inp, chars_inp, shape)\u001b[0m\n\u001b[1;32m    112\u001b[0m       \u001b[0mconvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mconvolved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcharacter_embedding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0;31m# (batch_size * sequence_length, n_filters for this width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mconvolved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvolved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/hateval/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/hateval/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 187\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hate.nn import ElmoModel\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "optimizer_args = {\n",
    "    \"lr\": 0.0005,\n",
    "    \"decay\": 0.01\n",
    "}\n",
    "\n",
    "tokenize_args = {\n",
    "    \"preserve_case\": False, \n",
    "    \"deaccent\": False,\n",
    "    \"reduce_len\": True, \n",
    "    \"strip_handles\": False,\n",
    "    \"alpha_only\": True,\n",
    "    \"stem\": False\n",
    "}\n",
    "\n",
    "max_len = 60\n",
    "\n",
    "X_train, y_train = df_train[\"text\"], df_train[\"HS\"]\n",
    "X_dev, y_dev = df_dev[\"text\"], df_dev[\"HS\"]\n",
    "\n",
    "model = ElmoModel(max_len=60, embedder=e, tokenize_args=tokenize_args)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 679us/step\n",
      "Loss        : 0.4876\n",
      "Accuracy    : 0.7740\n",
      "Precision   : 0.7401\n",
      "Recall      : 0.7568\n",
      "F1          : 0.7483\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "4500/4500 [==============================] - 12s 3ms/step - loss: 0.8192 - acc: 0.5482 - val_loss: 0.6684 - val_acc: 0.5880\n",
      "Epoch 2/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.7269 - acc: 0.5836 - val_loss: 0.6510 - val_acc: 0.6400\n",
      "Epoch 3/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.6674 - acc: 0.6291 - val_loss: 0.6370 - val_acc: 0.6720\n",
      "Epoch 4/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.6506 - acc: 0.6471 - val_loss: 0.6305 - val_acc: 0.6680\n",
      "Epoch 5/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.6311 - acc: 0.6547 - val_loss: 0.6102 - val_acc: 0.7020\n",
      "Epoch 6/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.6005 - acc: 0.6802 - val_loss: 0.5947 - val_acc: 0.7100\n",
      "Epoch 7/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.5812 - acc: 0.6976 - val_loss: 0.5789 - val_acc: 0.7260\n",
      "Epoch 8/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.5641 - acc: 0.7184 - val_loss: 0.5631 - val_acc: 0.7400\n",
      "Epoch 9/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.5369 - acc: 0.7380 - val_loss: 0.5470 - val_acc: 0.7500\n",
      "Epoch 10/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.5170 - acc: 0.7476 - val_loss: 0.5257 - val_acc: 0.7720\n",
      "Epoch 11/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.5003 - acc: 0.7582 - val_loss: 0.5154 - val_acc: 0.7700\n",
      "Epoch 12/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.4840 - acc: 0.7660 - val_loss: 0.5019 - val_acc: 0.7680\n",
      "Epoch 13/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.4759 - acc: 0.7764 - val_loss: 0.5050 - val_acc: 0.7700\n",
      "Epoch 14/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.4628 - acc: 0.7882 - val_loss: 0.4976 - val_acc: 0.7740\n",
      "Epoch 15/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.4636 - acc: 0.7911 - val_loss: 0.4862 - val_acc: 0.7800\n",
      "Epoch 16/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.4507 - acc: 0.7887 - val_loss: 0.4740 - val_acc: 0.7880\n",
      "Epoch 17/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.4403 - acc: 0.7976 - val_loss: 0.4746 - val_acc: 0.7820\n",
      "Epoch 18/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.4237 - acc: 0.8047 - val_loss: 0.4651 - val_acc: 0.7920\n",
      "Epoch 19/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.4231 - acc: 0.8127 - val_loss: 0.4616 - val_acc: 0.7920\n",
      "Epoch 20/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.4075 - acc: 0.8160 - val_loss: 0.4555 - val_acc: 0.7920\n",
      "Epoch 21/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.4121 - acc: 0.8147 - val_loss: 0.4589 - val_acc: 0.7940\n",
      "Epoch 22/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3997 - acc: 0.8233 - val_loss: 0.4475 - val_acc: 0.8020\n",
      "Epoch 23/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3992 - acc: 0.8251 - val_loss: 0.4576 - val_acc: 0.7940\n",
      "Epoch 24/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3985 - acc: 0.8191 - val_loss: 0.4523 - val_acc: 0.7960\n",
      "Epoch 25/25\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3881 - acc: 0.8320 - val_loss: 0.4481 - val_acc: 0.7980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f72a411d128>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU, Dropout, LSTM, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "optimizer_args = {\n",
    "    \"lr\": 0.0005,\n",
    "    \"decay\": 0.01\n",
    "}\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(256, input_shape=(max_length, embedding_dim))))\n",
    "model.add(Dropout(0.80))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.55))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train.values, validation_data=(X_dev, y_dev), epochs=25, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/2\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3734 - acc: 0.8387 - val_loss: 0.4570 - val_acc: 0.7960\n",
      "Epoch 2/2\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3666 - acc: 0.8333 - val_loss: 0.4473 - val_acc: 0.7960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74f623eeb8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values, validation_data=(X_dev, y_dev), epochs=2, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3636 - acc: 0.8418 - val_loss: 0.4557 - val_acc: 0.7900\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3614 - acc: 0.8422 - val_loss: 0.4525 - val_acc: 0.7920\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3607 - acc: 0.8436 - val_loss: 0.4424 - val_acc: 0.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74f623e4a8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values, validation_data=(X_dev, y_dev), epochs=3, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3524 - acc: 0.8413 - val_loss: 0.4523 - val_acc: 0.7980\n",
      "Epoch 2/3\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3431 - acc: 0.8556 - val_loss: 0.4505 - val_acc: 0.7980\n",
      "Epoch 3/3\n",
      "4500/4500 [==============================] - 10s 2ms/step - loss: 0.3403 - acc: 0.8538 - val_loss: 0.4456 - val_acc: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f74f623efd0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values, validation_data=(X_dev, y_dev), epochs=3, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 1ms/step\n",
      "Loss        : 0.4456\n",
      "Accuracy    : 0.8000\n",
      "Precision   : 0.7675\n",
      "Recall      : 0.7883\n",
      "F1          : 0.7778\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Vamos a ver los tweets con mayores errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_true</th>\n",
       "      <th>pred_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hs=1</th>\n",
       "      <td>175</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs=0</th>\n",
       "      <td>53</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_true  pred_false\n",
       "real                       \n",
       "hs=1        175          47\n",
       "hs=0         53         225"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev[\"proba\"] = model.predict_proba(X_dev)\n",
    "\n",
    "\n",
    "true_positives = df_dev[(df_dev[\"HS\"] == 1) & (df_dev[\"proba\"] >= 0.5)].copy()\n",
    "true_negatives = df_dev[(df_dev[\"HS\"] == 0) & (df_dev[\"proba\"] < 0.5)].copy()\n",
    "\n",
    "false_positives = df_dev[(df_dev[\"HS\"] == 0) & (df_dev[\"proba\"] > 0.5)].copy()\n",
    "false_positives.sort_values(\"proba\", ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "false_negatives = df_dev[(df_dev[\"HS\"] == 1) & (df_dev[\"proba\"] < 0.5)].copy()\n",
    "false_negatives.sort_values(\"proba\", ascending=True, inplace=True)\n",
    "\n",
    "conf_matrix = pd.DataFrame([\n",
    "    {\"real\":\"hs=1\", \"pred_true\": len(true_positives), \"pred_false\": len(false_negatives)},\n",
    "    {\"real\":\"hs=0\", \"pred_true\": len(false_positives), \"pred_false\": len(true_negatives)}\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "conf_matrix.set_index(\"real\", inplace=True)\n",
    "\n",
    "conf_matrix[[\"pred_true\", \"pred_false\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Falsos Negativos\n",
    "\n",
    "Veamos los 20 falsos negativos en los cuales nuestro modelo se equivoca m√°s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21535</th>\n",
       "      <td>#VOX critica duramente a ‚Å¶@pablocasado_‚Å© ‚ÄúLes da la bienvenida como si fuera un cartel del welcome de #Carmena ‚Äú ¬°Expulsi√≥n inmediata de moromierdas!  https://t.co/HaySDibj2l</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.043542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21152</th>\n",
       "      <td>@NatyBurgos15 @Horaciogenta @PaolaPa05 C√°llate vos Black and bitch como la puta falsa abogada. Espero se pudra en la c√°rcel y devuelva todo. Ded√≠cate a estudiar en serio. La droga es mala. Cristin...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22560</th>\n",
       "      <td>@CarlaEUrena @FelipeCalderon Callateeeee !! Puta gallina cacarea !! Ni idea tienes de nada .</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.080199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23415</th>\n",
       "      <td>Exacto! #puralata #feminazis #HombreAbusado https://t.co/zTEvaftxcd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21215</th>\n",
       "      <td>Que tal otro aporte an√≥nimo son de la puta de mi esposa, as√≠ los dej√≥ en navidad ense√±ando le los calzones al vecino rt y siguenos @TANGASUCIA @Tangasrobadas https://t.co/70ioUjveqY</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24925</th>\n",
       "      <td>La verdad que si, no veia la hora de llegar a los 5 mil amigosüòÇ ahora de a poco voy borrando esos indios indocumentadosüòÇ https://t.co/Xw8q4GLM8v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24401</th>\n",
       "      <td>No habr√° que darles de lo 'nuestro'. Ellos se apropiar√°n de lo 'suyo'.  @Manuj_Hidalgo les dice ‚òùÔ∏è a quienes piensan q hay q jubilar a los mayores para q trabajen los j√≥venes o q los q vienen d fu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.151047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21072</th>\n",
       "      <td>Voy andando por la calle y me han dicho cosas en √°rabe ya que me estas acosando dime lo en espa√±ol para que te entienda, asique como yo no les entiendo me he cagado en su puta madre en √°rabe para ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.152465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24590</th>\n",
       "      <td>SOMOS MUCHO M√ÅS DE LO QUE SUE√ëAS SER PINCH√â SUDACA CAGADO, y si no te gusta dime donde nos topamos pa reventarnos el hocico 1:1 @amarchesin1 https://t.co/vHHPBKS1AK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22008</th>\n",
       "      <td>@Namurii @medicaster_xz @Yorha2d @KeloKlau_ Se merec√≠a de puta y no quiere que le metan la verga, jajaja no mamen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24488</th>\n",
       "      <td>Un indocumentado...habla y habla y no para y acaba hablando su ignorancia.Empezamos bien. https://t.co/SMRsqjtEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22168</th>\n",
       "      <td>Mi novia es como mi polla. S√© que est√° ah√≠ porque de vez en cuando se levanta. Una de mis pantalones y la otra de la cama.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24864</th>\n",
       "      <td>rosalia me podr√≠a decir sudaca i wouldn't give a fuck</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.186539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>En que se parece superman a una mujer lista: En que los dos son personajes de ciencia-ficci√≥n.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.193847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24431</th>\n",
       "      <td>Yo nunca le he dicho puta a una mujer pero socia t√∫ eres senda petardo üòÇüòÇ estas navidades no voy a comprar pirotecnias ya contigo vasta üòÇüòÇüòÇ</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.194956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24746</th>\n",
       "      <td>@rU_1970 muestra como teni esa vagina de puta caliente llena de moco wacha culia hija de la perra traga semen 146:146</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.199260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21887</th>\n",
       "      <td>@A3Noticias Esta tiene que ser una 'fake new' porque las mujeres son siempre las v√≠ctimas, no las hijas de puta maltratadoras. Eso o el chaval es un machista que se lo ha merecido (machete al mach...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.222684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21727</th>\n",
       "      <td>Espa√±a crea su primer 'campo de refugiados' en la bah√≠a de Algeciras https://t.co/l7Zmh2kvPN v√≠a @elmundoes Gran noticia para el contribuyente espa√±ol. Espa√±oles a pagar, a pagar. Las pensiones pe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.224704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20337</th>\n",
       "      <td>Ni armar un complot para matar un presidente saben... #Sudacas..</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21339</th>\n",
       "      <td>La #Inmigraci√≥n, como sabemos, es mala, se ha demostrado en media #Europa. Pero no debemos caer en la tentaci√≥n de salpicar nuestra #soberan√≠a con extremismos, tenemos que defender lo nuestro, si,...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.236573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                          text  \\\n",
       "id                                                                                                                                                                                                               \n",
       "21535                           #VOX critica duramente a ‚Å¶@pablocasado_‚Å© ‚ÄúLes da la bienvenida como si fuera un cartel del welcome de #Carmena ‚Äú ¬°Expulsi√≥n inmediata de moromierdas!  https://t.co/HaySDibj2l   \n",
       "21152  @NatyBurgos15 @Horaciogenta @PaolaPa05 C√°llate vos Black and bitch como la puta falsa abogada. Espero se pudra en la c√°rcel y devuelva todo. Ded√≠cate a estudiar en serio. La droga es mala. Cristin...   \n",
       "22560                                                                                                             @CarlaEUrena @FelipeCalderon Callateeeee !! Puta gallina cacarea !! Ni idea tienes de nada .   \n",
       "23415                                                                                                                                      Exacto! #puralata #feminazis #HombreAbusado https://t.co/zTEvaftxcd   \n",
       "21215                    Que tal otro aporte an√≥nimo son de la puta de mi esposa, as√≠ los dej√≥ en navidad ense√±ando le los calzones al vecino rt y siguenos @TANGASUCIA @Tangasrobadas https://t.co/70ioUjveqY   \n",
       "24925                                                         La verdad que si, no veia la hora de llegar a los 5 mil amigosüòÇ ahora de a poco voy borrando esos indios indocumentadosüòÇ https://t.co/Xw8q4GLM8v   \n",
       "24401  No habr√° que darles de lo 'nuestro'. Ellos se apropiar√°n de lo 'suyo'.  @Manuj_Hidalgo les dice ‚òùÔ∏è a quienes piensan q hay q jubilar a los mayores para q trabajen los j√≥venes o q los q vienen d fu...   \n",
       "21072  Voy andando por la calle y me han dicho cosas en √°rabe ya que me estas acosando dime lo en espa√±ol para que te entienda, asique como yo no les entiendo me he cagado en su puta madre en √°rabe para ...   \n",
       "24590                                     SOMOS MUCHO M√ÅS DE LO QUE SUE√ëAS SER PINCH√â SUDACA CAGADO, y si no te gusta dime donde nos topamos pa reventarnos el hocico 1:1 @amarchesin1 https://t.co/vHHPBKS1AK   \n",
       "22008                                                                                        @Namurii @medicaster_xz @Yorha2d @KeloKlau_ Se merec√≠a de puta y no quiere que le metan la verga, jajaja no mamen   \n",
       "24488                                                                                        Un indocumentado...habla y habla y no para y acaba hablando su ignorancia.Empezamos bien. https://t.co/SMRsqjtEBT   \n",
       "22168                                                                               Mi novia es como mi polla. S√© que est√° ah√≠ porque de vez en cuando se levanta. Una de mis pantalones y la otra de la cama.   \n",
       "24864                                                                                                                                                    rosalia me podr√≠a decir sudaca i wouldn't give a fuck   \n",
       "24481                                                                                                           En que se parece superman a una mujer lista: En que los dos son personajes de ciencia-ficci√≥n.   \n",
       "24431                                                              Yo nunca le he dicho puta a una mujer pero socia t√∫ eres senda petardo üòÇüòÇ estas navidades no voy a comprar pirotecnias ya contigo vasta üòÇüòÇüòÇ   \n",
       "24746                                                                                    @rU_1970 muestra como teni esa vagina de puta caliente llena de moco wacha culia hija de la perra traga semen 146:146   \n",
       "21887  @A3Noticias Esta tiene que ser una 'fake new' porque las mujeres son siempre las v√≠ctimas, no las hijas de puta maltratadoras. Eso o el chaval es un machista que se lo ha merecido (machete al mach...   \n",
       "21727  Espa√±a crea su primer 'campo de refugiados' en la bah√≠a de Algeciras https://t.co/l7Zmh2kvPN v√≠a @elmundoes Gran noticia para el contribuyente espa√±ol. Espa√±oles a pagar, a pagar. Las pensiones pe...   \n",
       "20337                                                                                                                                         Ni armar un complot para matar un presidente saben... #Sudacas..   \n",
       "21339  La #Inmigraci√≥n, como sabemos, es mala, se ha demostrado en media #Europa. Pero no debemos caer en la tentaci√≥n de salpicar nuestra #soberan√≠a con extremismos, tenemos que defender lo nuestro, si,...   \n",
       "\n",
       "       HS  TR  AG     proba  \n",
       "id                           \n",
       "21535   1   0   1  0.043542  \n",
       "21152   1   1   1  0.053808  \n",
       "22560   1   1   1  0.080199  \n",
       "23415   1   0   1  0.084722  \n",
       "21215   1   1   1  0.092792  \n",
       "24925   1   0   0  0.144993  \n",
       "24401   1   0   1  0.151047  \n",
       "21072   1   0   1  0.152465  \n",
       "24590   1   1   1  0.157015  \n",
       "22008   1   1   0  0.168723  \n",
       "24488   1   0   0  0.183900  \n",
       "22168   1   1   0  0.185569  \n",
       "24864   1   1   1  0.186539  \n",
       "24481   1   0   0  0.193847  \n",
       "24431   1   1   0  0.194956  \n",
       "24746   1   1   1  0.199260  \n",
       "21887   1   0   1  0.222684  \n",
       "21727   1   0   0  0.224704  \n",
       "20337   1   0   1  0.236325  \n",
       "21339   1   0   1  0.236573  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives.iloc[:20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Qu√© onda la longitud de la secuencia?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 734., 1109., 1019.,  655.,  386.,  315.,  210.,   57.,   13.,\n",
       "           2.]),\n",
       " array([ 2., 10., 18., 26., 34., 42., 50., 58., 66., 74., 82.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tokens_dev = df_dev[\"text\"].apply(lambda t: len(tokenizer.tokenize(t)))\n",
    "tokens_train = df_train[\"text\"].apply(lambda t: len(tokenizer.tokenize(t)))\n",
    "\n",
    "plt.hist(tokens_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22517</th>\n",
       "      <td>-¬øeres poblana? -soy colombiana -¬øy por qu√© eres g√ºera? en Colombia TODAS son morenas, fui a Colombia 3 veces. -ok, ment√≠ üôÑ solo me pinto el cabello</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22416</th>\n",
       "      <td>@Pepe_ElEzequiel Puta!? Puta con las que vos te metes Esa mujer es un √°ngel enviado por Jesucristo nuestro se√±or para darnos esa paz que buscamos s√≥lo con verla</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.967200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21892</th>\n",
       "      <td>@saancisco Callate puta tu eres el traidor.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.963039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21497</th>\n",
       "      <td>Talvez quede como zorra pero te lo mereces Sociaüòé</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24172</th>\n",
       "      <td>Y los que no se denuncian... hagamos n√∫meros. El acoso a las mujeres es diario. No todos los hombres son acosadores, pero todas las mujeres han sido acosadas. https://t.co/jza9llhqWA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.945128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21255</th>\n",
       "      <td>Y t√∫ eres una maldita escoria con una repugnante inclinaci√≥n por los hombres.. ¬°Seres como t√∫ me producen n√°useas! https://t.co/TaHDcpZdnm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.943286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24159</th>\n",
       "      <td>@LeonDeJapon Jajajajajaja tu eres uno, diego jajajajajaja mentira perra perra perrraaaaaaaaaa de mierda jajaja ‚ô°</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.931898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24402</th>\n",
       "      <td>zorra eres tu que no te sientes hombre y no entiendes que toda mujer es bella</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.925799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21671</th>\n",
       "      <td>@danlntifada @fatinascidi @manolivizoso @Zurine3 @Jvillaver2 https://t.co/HG4ljNlwR3, co√±o entonces tu eres de lo que te guias por el antes de cristo y despues de cristo,cuando llegamos los Espa√±o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.921038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22115</th>\n",
       "      <td>Una chica no es una guarra, una zorra, una puta, una buscan por su manera de vestir.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.915731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22014</th>\n",
       "      <td>Ni t√∫ eres una zorra hambrienta ni yo un incorregible depredador.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.910154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20376</th>\n",
       "      <td>Zorra tu abuela, imb√©cil.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.890432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21050</th>\n",
       "      <td>@GvyMC @Wismichu Callate puta rataüòÇüòÇ ya estas llorando??</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.877848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22848</th>\n",
       "      <td>Pinche beb√© pendejo c√°llate el hocico, nom√°s te est√°n cortando el pelo. Puta chillona</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.856129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22938</th>\n",
       "      <td>Masculinidad fr√°gil es mi crush franc√©s ech√°ndose un clavado al cenote solo porque un grupo de √°rabes le dijo pussy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.855542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23320</th>\n",
       "      <td>@HenriFalconLara No digas nada que t√∫ eres c√≥mplice de lo que est√° pasando... y recuerda seguir√°s siendo la perra m√°s perra de Venezuela</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21966</th>\n",
       "      <td>esc√∫chame ya me joder√≠a jajajajajajajajajajajajajaja si pa ti ense√±ar es ser una guarra yo soy biennnn guarra, menos mal que no me respeto que si no... https://t.co/yt5fHp99b7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.848084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24209</th>\n",
       "      <td>¬øYa les he contado que si fuera rica/millonaria ser√≠a toda una PERRA?, Yisus me est√° ense√±ando humildad... Y no he aprendido mucho ldvdd.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.813778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22846</th>\n",
       "      <td>Si a mi se me ocurre ense√±ar por twitter una conversaci√≥n de whatsap con mi madre me manda a dormir a la caseta de mi perra.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.808360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22457</th>\n",
       "      <td>De Colombia tocar√° emigrar en pateras, como hacen los africanos subsaharianos.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.795402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                          text  \\\n",
       "id                                                                                                                                                                                                               \n",
       "22517                                                     -¬øeres poblana? -soy colombiana -¬øy por qu√© eres g√ºera? en Colombia TODAS son morenas, fui a Colombia 3 veces. -ok, ment√≠ üôÑ solo me pinto el cabello   \n",
       "22416                                         @Pepe_ElEzequiel Puta!? Puta con las que vos te metes Esa mujer es un √°ngel enviado por Jesucristo nuestro se√±or para darnos esa paz que buscamos s√≥lo con verla   \n",
       "21892                                                                                                                                                              @saancisco Callate puta tu eres el traidor.   \n",
       "21497                                                                                                                                                        Talvez quede como zorra pero te lo mereces Sociaüòé   \n",
       "24172                   Y los que no se denuncian... hagamos n√∫meros. El acoso a las mujeres es diario. No todos los hombres son acosadores, pero todas las mujeres han sido acosadas. https://t.co/jza9llhqWA   \n",
       "21255                                                               Y t√∫ eres una maldita escoria con una repugnante inclinaci√≥n por los hombres.. ¬°Seres como t√∫ me producen n√°useas! https://t.co/TaHDcpZdnm   \n",
       "24159                                                                                         @LeonDeJapon Jajajajajaja tu eres uno, diego jajajajajaja mentira perra perra perrraaaaaaaaaa de mierda jajaja ‚ô°   \n",
       "24402                                                                                                                            zorra eres tu que no te sientes hombre y no entiendes que toda mujer es bella   \n",
       "21671  @danlntifada @fatinascidi @manolivizoso @Zurine3 @Jvillaver2 https://t.co/HG4ljNlwR3, co√±o entonces tu eres de lo que te guias por el antes de cristo y despues de cristo,cuando llegamos los Espa√±o...   \n",
       "22115                                                                                                                     Una chica no es una guarra, una zorra, una puta, una buscan por su manera de vestir.   \n",
       "22014                                                                                                                                        Ni t√∫ eres una zorra hambrienta ni yo un incorregible depredador.   \n",
       "20376                                                                                                                                                                                Zorra tu abuela, imb√©cil.   \n",
       "21050                                                                                                                                                 @GvyMC @Wismichu Callate puta rataüòÇüòÇ ya estas llorando??   \n",
       "22848                                                                                                                    Pinche beb√© pendejo c√°llate el hocico, nom√°s te est√°n cortando el pelo. Puta chillona   \n",
       "22938                                                                                      Masculinidad fr√°gil es mi crush franc√©s ech√°ndose un clavado al cenote solo porque un grupo de √°rabes le dijo pussy   \n",
       "23320                                                                 @HenriFalconLara No digas nada que t√∫ eres c√≥mplice de lo que est√° pasando... y recuerda seguir√°s siendo la perra m√°s perra de Venezuela   \n",
       "21966                          esc√∫chame ya me joder√≠a jajajajajajajajajajajajajaja si pa ti ense√±ar es ser una guarra yo soy biennnn guarra, menos mal que no me respeto que si no... https://t.co/yt5fHp99b7   \n",
       "24209                                                                ¬øYa les he contado que si fuera rica/millonaria ser√≠a toda una PERRA?, Yisus me est√° ense√±ando humildad... Y no he aprendido mucho ldvdd.   \n",
       "22846                                                                             Si a mi se me ocurre ense√±ar por twitter una conversaci√≥n de whatsap con mi madre me manda a dormir a la caseta de mi perra.   \n",
       "22457                                                                                                                           De Colombia tocar√° emigrar en pateras, como hacen los africanos subsaharianos.   \n",
       "\n",
       "       HS  TR  AG     proba  \n",
       "id                           \n",
       "22517   0   0   0  0.971048  \n",
       "22416   0   0   0  0.967200  \n",
       "21892   0   0   0  0.963039  \n",
       "21497   0   0   0  0.947185  \n",
       "24172   0   0   0  0.945128  \n",
       "21255   0   0   0  0.943286  \n",
       "24159   0   0   0  0.931898  \n",
       "24402   0   0   0  0.925799  \n",
       "21671   0   0   0  0.921038  \n",
       "22115   0   0   0  0.915731  \n",
       "22014   0   0   0  0.910154  \n",
       "20376   0   0   0  0.890432  \n",
       "21050   0   0   0  0.877848  \n",
       "22848   0   0   0  0.856129  \n",
       "22938   0   0   0  0.855542  \n",
       "23320   0   0   0  0.854512  \n",
       "21966   0   0   0  0.848084  \n",
       "24209   0   0   0  0.813778  \n",
       "22846   0   0   0  0.808360  \n",
       "22457   0   0   0  0.795402  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 200)\n",
    "false_positives.iloc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['easyjet',\n",
       " 'quiere',\n",
       " 'duplicar',\n",
       " 'el',\n",
       " 'n√∫mero',\n",
       " 'de',\n",
       " 'mujeres',\n",
       " 'piloto',\n",
       " \"'\",\n",
       " 'ver√°s',\n",
       " 't√∫',\n",
       " 'para',\n",
       " 'aparcar',\n",
       " 'el',\n",
       " 'avi√≥n',\n",
       " '..',\n",
       " 'http://t.co/46NuLkm09x',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
