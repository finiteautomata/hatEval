{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM  + ElMO\n",
    "\n",
    "En esta, rehacemos todo lo de ElMO pero usando nuestra nueva clase: ElMOModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancias de entrenamiento: 4500\n",
      "Instancias de desarrollo: 500\n",
      "Instancias de test: 1600\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "df_dev = pd.read_table(\"../../../data/es/dev_es.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "df_train = pd.read_table(\"../../../data/es/train_es.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "df_test = pd.read_table(\"../../../data/es/test_es.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "\n",
    "print(\"Instancias de entrenamiento: {}\".format(len(df_train)))\n",
    "print(\"Instancias de desarrollo: {}\".format(len(df_dev)))\n",
    "print(\"Instancias de test: {}\".format(len(df_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tengo que hacer dos cosas:\n",
    "\n",
    "- Primero, convertir los tweets a secuencias de texto\n",
    "- Luego, paddear las secuencias a cierta longitud (Keras necesita esto para poder paralelizar c√°lculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hate.nn.preprocessing import Tokenizer\n",
    "\n",
    "tokenize_args = {\n",
    "    \"preserve_case\": False, \n",
    "    \"deaccent\": False,\n",
    "    \"reduce_len\": True, \n",
    "    \"strip_handles\": False,\n",
    "    \"alpha_only\": True,\n",
    "    \"stem\": False\n",
    "}\n",
    "\n",
    "tokenizer = Tokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "\n",
    "tokens_train = [tokenizer.tokenize(tweet) for tweet in df_train[\"text\"].values]\n",
    "tokens_dev = [tokenizer.tokenize(tweet) for tweet in df_dev[\"text\"].values]\n",
    "tokens_test = [tokenizer.tokenize(tweet) for tweet in df_test[\"text\"].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos las distribuciones de las longitudes de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de longitud: train 22.91 dev 23.33 test 23.33\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,3)\n",
    "\n",
    "train_lens = np.array([len(t) for t in tokens_train]) \n",
    "dev_lens = np.array([len(t) for t in tokens_dev])\n",
    "test_lens = np.array([len(t) for t in tokens_test])\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "\n",
    "plt.hist(train_lens)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(dev_lens)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(test_lens)\n",
    "\n",
    "print(\"Media de longitud: train {:.2f} dev {:.2f} test {:.2f}\".format(train_lens.mean(), dev_lens.mean(), test_lens.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 16:29:06,430 INFO: char embedding size: 2637\n",
      "2019-01-20 16:29:07,386 INFO: word embedding size: 185214\n",
      "2019-01-20 16:29:16,407 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(185214, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2637, 50, padding_idx=2634)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from elmoformanylangs import Embedder\n",
    "\n",
    "e = Embedder(\"../../../models/elmo/es/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Elmo_Input (InputLayer)      (None, 60, 1024)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               1181696   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_elmo (Dense)           (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,214,721\n",
      "Trainable params: 1,214,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from hate.nn import ElmoModel\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import CuDNNLSTM, CuDNNGRU\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "optimizer_args = {\n",
    "    \"lr\": 0.0005,\n",
    "    \"decay\": 0.01\n",
    "}\n",
    "\n",
    "tokenize_args = {\n",
    "    \"preserve_case\": False, \n",
    "    \"deaccent\": False,\n",
    "    \"reduce_len\": True, \n",
    "    \"strip_handles\": False,\n",
    "    \"alpha_only\": True,\n",
    "    \"stem\": False\n",
    "}\n",
    "\n",
    "max_len = 60\n",
    "\n",
    "X_train, y_train = df_train[\"text\"], df_train[\"HS\"]\n",
    "X_dev, y_dev = df_dev[\"text\"], df_dev[\"HS\"]\n",
    "\n",
    "model = ElmoModel(\n",
    "    max_len=60, embedder=e, tokenize_args=tokenize_args,\n",
    "    recursive_class=CuDNNLSTM,\n",
    ")\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 16:29:35,009 INFO: 71 batches, avg len: 62.0\n",
      "2019-01-20 16:29:39,928 INFO: Finished 1000 sentences.\n",
      "2019-01-20 16:29:43,723 INFO: Finished 2000 sentences.\n",
      "2019-01-20 16:29:47,318 INFO: Finished 3000 sentences.\n",
      "2019-01-20 16:29:51,115 INFO: Finished 4000 sentences.\n",
      "2019-01-20 16:29:54,826 INFO: 8 batches, avg len: 62.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 16:29:57,067 WARNING: Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/40\n",
      "4500/4500 [==============================] - 5s 1ms/step - loss: 0.7059 - acc: 0.5662 - val_loss: 0.6664 - val_acc: 0.6180\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.61800, saving model to /tmp/elmo_15.h5\n",
      "Epoch 2/40\n",
      "4500/4500 [==============================] - 3s 576us/step - loss: 0.6642 - acc: 0.6051 - val_loss: 0.6534 - val_acc: 0.6460\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.61800 to 0.64600, saving model to /tmp/elmo_15.h5\n",
      "Epoch 3/40\n",
      "4500/4500 [==============================] - 3s 572us/step - loss: 0.6359 - acc: 0.6444 - val_loss: 0.6267 - val_acc: 0.6620\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.64600 to 0.66200, saving model to /tmp/elmo_15.h5\n",
      "Epoch 4/40\n",
      "4500/4500 [==============================] - 3s 574us/step - loss: 0.6197 - acc: 0.6629 - val_loss: 0.6067 - val_acc: 0.6700\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.66200 to 0.67000, saving model to /tmp/elmo_15.h5\n",
      "Epoch 5/40\n",
      "4500/4500 [==============================] - 3s 568us/step - loss: 0.5927 - acc: 0.6873 - val_loss: 0.5837 - val_acc: 0.6760\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.67000 to 0.67600, saving model to /tmp/elmo_15.h5\n",
      "Epoch 6/40\n",
      "4500/4500 [==============================] - 3s 574us/step - loss: 0.5773 - acc: 0.6976 - val_loss: 0.5656 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.67600 to 0.70000, saving model to /tmp/elmo_15.h5\n",
      "Epoch 7/40\n",
      "4500/4500 [==============================] - 3s 575us/step - loss: 0.5547 - acc: 0.7229 - val_loss: 0.5508 - val_acc: 0.7120\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.70000 to 0.71200, saving model to /tmp/elmo_15.h5\n",
      "Epoch 8/40\n",
      "4500/4500 [==============================] - 3s 575us/step - loss: 0.5438 - acc: 0.7313 - val_loss: 0.5392 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.71200 to 0.71800, saving model to /tmp/elmo_15.h5\n",
      "Epoch 9/40\n",
      "4500/4500 [==============================] - 3s 568us/step - loss: 0.5340 - acc: 0.7411 - val_loss: 0.5193 - val_acc: 0.7480\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.71800 to 0.74800, saving model to /tmp/elmo_15.h5\n",
      "Epoch 10/40\n",
      "4500/4500 [==============================] - 3s 579us/step - loss: 0.5212 - acc: 0.7489 - val_loss: 0.5111 - val_acc: 0.7560\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.74800 to 0.75600, saving model to /tmp/elmo_15.h5\n",
      "Epoch 11/40\n",
      "4500/4500 [==============================] - 3s 574us/step - loss: 0.5108 - acc: 0.7564 - val_loss: 0.5026 - val_acc: 0.7640\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.75600 to 0.76400, saving model to /tmp/elmo_15.h5\n",
      "Epoch 12/40\n",
      "4500/4500 [==============================] - 3s 581us/step - loss: 0.5033 - acc: 0.7638 - val_loss: 0.4943 - val_acc: 0.7700\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.76400 to 0.77000, saving model to /tmp/elmo_15.h5\n",
      "Epoch 13/40\n",
      "4500/4500 [==============================] - 3s 577us/step - loss: 0.4983 - acc: 0.7704 - val_loss: 0.4878 - val_acc: 0.7740\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.77000 to 0.77400, saving model to /tmp/elmo_15.h5\n",
      "Epoch 14/40\n",
      "4500/4500 [==============================] - 3s 571us/step - loss: 0.4912 - acc: 0.7649 - val_loss: 0.4786 - val_acc: 0.7760\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.77400 to 0.77600, saving model to /tmp/elmo_15.h5\n",
      "Epoch 15/40\n",
      "4500/4500 [==============================] - 3s 571us/step - loss: 0.4939 - acc: 0.7656 - val_loss: 0.4824 - val_acc: 0.7740\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.77600\n",
      "Epoch 16/40\n",
      "4500/4500 [==============================] - 3s 570us/step - loss: 0.4795 - acc: 0.7720 - val_loss: 0.4724 - val_acc: 0.7880\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.77600 to 0.78800, saving model to /tmp/elmo_15.h5\n",
      "Epoch 17/40\n",
      "4500/4500 [==============================] - 3s 574us/step - loss: 0.4735 - acc: 0.7807 - val_loss: 0.4712 - val_acc: 0.7720\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.78800\n",
      "Epoch 18/40\n",
      "4500/4500 [==============================] - 3s 573us/step - loss: 0.4622 - acc: 0.7978 - val_loss: 0.4634 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.78800\n",
      "Epoch 19/40\n",
      "4500/4500 [==============================] - 3s 566us/step - loss: 0.4641 - acc: 0.7887 - val_loss: 0.4617 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.78800 to 0.79000, saving model to /tmp/elmo_15.h5\n",
      "Epoch 20/40\n",
      "4500/4500 [==============================] - 3s 565us/step - loss: 0.4548 - acc: 0.7951 - val_loss: 0.4604 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.79000 to 0.79400, saving model to /tmp/elmo_15.h5\n",
      "Epoch 21/40\n",
      "4500/4500 [==============================] - 3s 575us/step - loss: 0.4516 - acc: 0.7991 - val_loss: 0.4600 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.79400\n",
      "Epoch 22/40\n",
      "4500/4500 [==============================] - 3s 573us/step - loss: 0.4500 - acc: 0.7962 - val_loss: 0.4531 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.79400 to 0.80400, saving model to /tmp/elmo_15.h5\n",
      "Epoch 23/40\n",
      "4500/4500 [==============================] - 3s 607us/step - loss: 0.4481 - acc: 0.8038 - val_loss: 0.4513 - val_acc: 0.8060\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.80400 to 0.80600, saving model to /tmp/elmo_15.h5\n",
      "Epoch 24/40\n",
      "4500/4500 [==============================] - 3s 647us/step - loss: 0.4339 - acc: 0.8091 - val_loss: 0.4495 - val_acc: 0.8040\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.80600\n",
      "Epoch 25/40\n",
      "4500/4500 [==============================] - 3s 657us/step - loss: 0.4302 - acc: 0.8069 - val_loss: 0.4507 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.80600\n",
      "Epoch 26/40\n",
      "4500/4500 [==============================] - 3s 647us/step - loss: 0.4333 - acc: 0.8060 - val_loss: 0.4482 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.80600\n",
      "Epoch 27/40\n",
      "4500/4500 [==============================] - 3s 646us/step - loss: 0.4269 - acc: 0.8078 - val_loss: 0.4434 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.80600\n",
      "Epoch 28/40\n",
      "4500/4500 [==============================] - 3s 655us/step - loss: 0.4191 - acc: 0.8129 - val_loss: 0.4528 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.80600\n",
      "Epoch 29/40\n",
      "4500/4500 [==============================] - 3s 646us/step - loss: 0.4176 - acc: 0.8149 - val_loss: 0.4406 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.80600\n",
      "Epoch 30/40\n",
      "4500/4500 [==============================] - 3s 648us/step - loss: 0.4259 - acc: 0.8133 - val_loss: 0.4423 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.80600\n",
      "Epoch 31/40\n",
      "4500/4500 [==============================] - 3s 642us/step - loss: 0.4059 - acc: 0.8224 - val_loss: 0.4398 - val_acc: 0.7960\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.80600\n",
      "Epoch 32/40\n",
      "4500/4500 [==============================] - 3s 652us/step - loss: 0.4011 - acc: 0.8207 - val_loss: 0.4390 - val_acc: 0.7980\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.80600\n",
      "Epoch 33/40\n",
      "4500/4500 [==============================] - 3s 648us/step - loss: 0.4094 - acc: 0.8220 - val_loss: 0.4385 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.80600\n",
      "Epoch 34/40\n",
      "4500/4500 [==============================] - 3s 644us/step - loss: 0.4031 - acc: 0.8282 - val_loss: 0.4425 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.80600\n",
      "Epoch 35/40\n",
      "4500/4500 [==============================] - 3s 651us/step - loss: 0.3993 - acc: 0.8267 - val_loss: 0.4378 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.80600\n",
      "Epoch 36/40\n",
      "4500/4500 [==============================] - 3s 646us/step - loss: 0.3930 - acc: 0.8316 - val_loss: 0.4455 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.80600\n",
      "Epoch 37/40\n",
      "4500/4500 [==============================] - 3s 650us/step - loss: 0.3937 - acc: 0.8378 - val_loss: 0.4458 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.80600\n",
      "Epoch 38/40\n",
      "4500/4500 [==============================] - 3s 648us/step - loss: 0.3884 - acc: 0.8380 - val_loss: 0.4371 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.80600\n",
      "Epoch 39/40\n",
      "4500/4500 [==============================] - 3s 646us/step - loss: 0.3845 - acc: 0.8327 - val_loss: 0.4394 - val_acc: 0.7920\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.80600\n",
      "Epoch 40/40\n",
      "4500/4500 [==============================] - 3s 644us/step - loss: 0.3818 - acc: 0.8351 - val_loss: 0.4359 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.80600\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, BaseLogger\n",
    "\n",
    "checkpointer = ModelCheckpoint('/tmp/elmo_15.h5', \n",
    "                               save_best_only=True, monitor='val_acc', verbose=1)\n",
    "logger = BaseLogger(['accuracy'])\n",
    "\n",
    "history_callback = model.fit(X_train, y_train, callbacks=[logger, checkpointer], \n",
    "                             validation_data=(X_dev, y_dev), epochs=40, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = history_callback.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8060000004768372"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 16:31:51,768 INFO: 8 batches, avg len: 62.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 274us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 16:31:55,245 INFO: 8 batches, avg len: 62.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss        : 0.4513\n",
      "Accuracy    : 0.8060\n",
      "Precision   : 0.7990\n",
      "Recall      : 0.7523\n",
      "F1          : 0.7749\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "model.load_weights(checkpointer.filepath)\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 16:34:25,682 INFO: 25 batches, avg len: 62.0\n",
      "2019-01-20 16:34:30,822 INFO: Finished 1000 sentences.\n",
      "2019-01-20 16:34:35,083 INFO: 8 batches, avg len: 62.0\n"
     ]
    }
   ],
   "source": [
    "df_test[\"preds\"] = (model.predict(df_test[\"text\"]) >= 0.5).astype(int)\n",
    "df_dev[\"preds\"] = (model.predict(df_dev[\"text\"]) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dev_submission = \"../../../submissions/dev/15_elmo.tsv\" \n",
    "\n",
    "df_test.to_csv(\"../../../submissions/15_elmo.tsv\", columns=[\"id\", \"preds\"], \n",
    "              sep='\\t', quoting=csv.QUOTE_NONE, header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, r = list(df_test.iterrows())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('es_a.tsv', 'w') as f:\n",
    "    for i, row in df_test.iterrows():\n",
    "        f.write('{}\\t{}\\n'.format(i, row[\"preds\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp es_a.tsv ../../../submissions/15_elmo.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"es_a.tsv.zip\", 'w') as f:\n",
    "    f.write('es_a.tsv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
