{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU  + ElMO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_table(\"../../../data/es/train_es.tsv\", index_col=\"id\")\n",
    "df_dev = pd.read_table(\"../../../data/es/dev_es.tsv\", index_col=\"id\")\n",
    "\n",
    "text_train, y_train = df_train[\"text\"].values, df_train[\"HS\"].values\n",
    "text_dev, y_dev = df_dev[\"text\"].values, df_dev[\"HS\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tengo que hacer dos cosas:\n",
    "\n",
    "- Primero, convertir los tweets a secuencias de texto\n",
    "- Luego, paddear las secuencias a cierta longitud (Keras necesita esto para poder paralelizar cálculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "max_length = 30\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    if len(tokens) >= max_length:\n",
    "        tokens = tokens[:max_length]\n",
    "    else:\n",
    "        tokens = tokens + [''] * (max_length - len(tokens))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "text_train = [preprocess_tweet(tweet) for tweet in df_train[\"text\"].values]\n",
    "text_dev = [preprocess_tweet(tweet) for tweet in df_dev[\"text\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 17:23:13,504 INFO: char embedding size: 2637\n",
      "2019-01-10 17:23:14,437 INFO: word embedding size: 185214\n",
      "2019-01-10 17:23:23,671 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(185214, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2637, 50, padding_idx=2634)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from elmoformanylangs import Embedder\n",
    "\n",
    "e = Embedder(\"../../../models/elmo/es/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['easyjet', 'quiere', 'duplicar', 'el', 'número', 'de', 'mujeres', 'piloto', \"'\", 'verás', 'tú', 'para', 'aparcar', 'el', 'avión', '..', 'http://t.co/46NuLkm09x', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-10 17:23:30,714 INFO: 70 batches, avg len: 32.0\n",
      "2019-01-10 17:23:33,326 INFO: Finished 1000 sentences.\n",
      "2019-01-10 17:23:35,286 INFO: Finished 2000 sentences.\n",
      "2019-01-10 17:23:37,306 INFO: Finished 3000 sentences.\n",
      "2019-01-10 17:23:39,181 INFO: Finished 4000 sentences.\n",
      "2019-01-10 17:23:41,085 INFO: 8 batches, avg len: 32.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(text_train[0])\n",
    "\n",
    "\n",
    "X_train = np.array(e.sents2elmo(text_train))\n",
    "X_dev = np.array(e.sents2elmo(text_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4469, 30, 1024), (500, 30, 1024))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 256)               983808    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,049,857\n",
      "Trainable params: 1,049,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4469 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "4469/4469 [==============================] - 7s 2ms/step - loss: 0.7733 - acc: 0.5473 - val_loss: 0.6879 - val_acc: 0.5580\n",
      "Epoch 2/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.7235 - acc: 0.5637 - val_loss: 0.6727 - val_acc: 0.5760\n",
      "Epoch 3/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.6977 - acc: 0.5690 - val_loss: 0.6647 - val_acc: 0.6160\n",
      "Epoch 4/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.6756 - acc: 0.6026 - val_loss: 0.6587 - val_acc: 0.6180\n",
      "Epoch 5/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.6550 - acc: 0.6200 - val_loss: 0.6415 - val_acc: 0.6720\n",
      "Epoch 6/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.6292 - acc: 0.6498 - val_loss: 0.6220 - val_acc: 0.6780\n",
      "Epoch 7/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5958 - acc: 0.6885 - val_loss: 0.5876 - val_acc: 0.7020\n",
      "Epoch 8/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5603 - acc: 0.7140 - val_loss: 0.5444 - val_acc: 0.7300\n",
      "Epoch 9/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5159 - acc: 0.7512 - val_loss: 0.5079 - val_acc: 0.7480\n",
      "Epoch 10/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4976 - acc: 0.7606 - val_loss: 0.5003 - val_acc: 0.7520\n",
      "Epoch 11/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4664 - acc: 0.7872 - val_loss: 0.4709 - val_acc: 0.7720\n",
      "Epoch 12/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4490 - acc: 0.7948 - val_loss: 0.4706 - val_acc: 0.7760\n",
      "Epoch 13/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4299 - acc: 0.8029 - val_loss: 0.4662 - val_acc: 0.7720\n",
      "Epoch 14/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4088 - acc: 0.8176 - val_loss: 0.4524 - val_acc: 0.8020\n",
      "Epoch 15/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3984 - acc: 0.8281 - val_loss: 0.4528 - val_acc: 0.8020\n",
      "Epoch 16/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3881 - acc: 0.8284 - val_loss: 0.4555 - val_acc: 0.7820\n",
      "Epoch 17/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3776 - acc: 0.8362 - val_loss: 0.4489 - val_acc: 0.8000\n",
      "Epoch 18/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3595 - acc: 0.8499 - val_loss: 0.4560 - val_acc: 0.7960\n",
      "Epoch 19/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3528 - acc: 0.8505 - val_loss: 0.4639 - val_acc: 0.7900\n",
      "Epoch 20/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3410 - acc: 0.8552 - val_loss: 0.4543 - val_acc: 0.8020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50c252f9b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU, Dropout, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "optimizer_args = {\n",
    "    \"lr\": 0.0005,\n",
    "    \"decay\": 0.01\n",
    "}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(256, input_shape=(max_length, embedding_dim)))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 549us/step\n",
      "Loss        : 0.4543\n",
      "Accuracy    : 0.8020\n",
      "Precision   : 0.7808\n",
      "Recall      : 0.7703\n",
      "F1          : 0.7755\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU, Dropout, LSTM, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(256, input_shape=(max_length, embedding_dim))))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4469 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "4469/4469 [==============================] - 11s 2ms/step - loss: 0.7913 - acc: 0.5596 - val_loss: 0.6472 - val_acc: 0.6380\n",
      "Epoch 2/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.6759 - acc: 0.6245 - val_loss: 0.6254 - val_acc: 0.6660\n",
      "Epoch 3/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.6302 - acc: 0.6626 - val_loss: 0.6016 - val_acc: 0.6820\n",
      "Epoch 4/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5969 - acc: 0.6917 - val_loss: 0.5722 - val_acc: 0.7260\n",
      "Epoch 5/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5678 - acc: 0.7174 - val_loss: 0.5465 - val_acc: 0.7420\n",
      "Epoch 6/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5338 - acc: 0.7369 - val_loss: 0.5271 - val_acc: 0.7500\n",
      "Epoch 7/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5060 - acc: 0.7603 - val_loss: 0.4950 - val_acc: 0.7700\n",
      "Epoch 8/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4835 - acc: 0.7680 - val_loss: 0.4863 - val_acc: 0.7840\n",
      "Epoch 9/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4743 - acc: 0.7774 - val_loss: 0.4760 - val_acc: 0.7700\n",
      "Epoch 10/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4531 - acc: 0.7901 - val_loss: 0.4669 - val_acc: 0.7900\n",
      "Epoch 11/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4389 - acc: 0.8009 - val_loss: 0.4611 - val_acc: 0.8040\n",
      "Epoch 12/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4158 - acc: 0.8170 - val_loss: 0.4505 - val_acc: 0.8040\n",
      "Epoch 13/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4062 - acc: 0.8190 - val_loss: 0.4472 - val_acc: 0.7940\n",
      "Epoch 14/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3945 - acc: 0.8246 - val_loss: 0.4502 - val_acc: 0.7920\n",
      "Epoch 15/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3879 - acc: 0.8281 - val_loss: 0.4310 - val_acc: 0.8140\n",
      "Epoch 16/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3762 - acc: 0.8335 - val_loss: 0.4427 - val_acc: 0.8000\n",
      "Epoch 17/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3598 - acc: 0.8438 - val_loss: 0.4445 - val_acc: 0.8000\n",
      "Epoch 18/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3581 - acc: 0.8407 - val_loss: 0.4389 - val_acc: 0.8000\n",
      "Epoch 19/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3411 - acc: 0.8483 - val_loss: 0.4309 - val_acc: 0.8100\n",
      "Epoch 20/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3445 - acc: 0.8469 - val_loss: 0.4325 - val_acc: 0.8060\n",
      "Epoch 21/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3299 - acc: 0.8606 - val_loss: 0.4305 - val_acc: 0.8060\n",
      "Epoch 22/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3192 - acc: 0.8653 - val_loss: 0.4396 - val_acc: 0.8100\n",
      "Epoch 23/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3134 - acc: 0.8653 - val_loss: 0.4371 - val_acc: 0.8040\n",
      "Epoch 24/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3054 - acc: 0.8727 - val_loss: 0.4371 - val_acc: 0.7960\n",
      "Epoch 25/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3038 - acc: 0.8669 - val_loss: 0.4378 - val_acc: 0.8120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f507c146fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=25, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 994us/step\n",
      "Loss        : 0.4378\n",
      "Accuracy    : 0.8120\n",
      "Precision   : 0.7832\n",
      "Recall      : 0.7973\n",
      "F1          : 0.7902\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv+GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU, Dropout, LSTM, Bidirectional, Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(GRU(256)))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4469 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "4469/4469 [==============================] - 8s 2ms/step - loss: 0.6913 - acc: 0.5809 - val_loss: 0.6320 - val_acc: 0.6620\n",
      "Epoch 2/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5924 - acc: 0.6867 - val_loss: 0.5889 - val_acc: 0.7060\n",
      "Epoch 3/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5189 - acc: 0.7463 - val_loss: 0.5593 - val_acc: 0.7040\n",
      "Epoch 4/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4646 - acc: 0.7868 - val_loss: 0.4952 - val_acc: 0.7780\n",
      "Epoch 5/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4077 - acc: 0.8188 - val_loss: 0.4699 - val_acc: 0.7880\n",
      "Epoch 6/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3653 - acc: 0.8445 - val_loss: 0.4654 - val_acc: 0.7880\n",
      "Epoch 7/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3174 - acc: 0.8713 - val_loss: 0.4574 - val_acc: 0.7980\n",
      "Epoch 8/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.2673 - acc: 0.8946 - val_loss: 0.4695 - val_acc: 0.8000\n",
      "Epoch 9/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.2315 - acc: 0.9139 - val_loss: 0.4788 - val_acc: 0.7900\n",
      "Epoch 10/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.1852 - acc: 0.9320 - val_loss: 0.5359 - val_acc: 0.7780\n",
      "Epoch 11/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.1527 - acc: 0.9461 - val_loss: 0.5734 - val_acc: 0.7920\n",
      "Epoch 12/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.1327 - acc: 0.9552 - val_loss: 0.6124 - val_acc: 0.7900\n",
      "Epoch 13/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.1021 - acc: 0.9707 - val_loss: 0.6567 - val_acc: 0.7840\n",
      "Epoch 14/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0821 - acc: 0.9770 - val_loss: 0.7057 - val_acc: 0.7860\n",
      "Epoch 15/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0702 - acc: 0.9803 - val_loss: 0.7838 - val_acc: 0.7840\n",
      "Epoch 16/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0554 - acc: 0.9861 - val_loss: 0.8505 - val_acc: 0.7900\n",
      "Epoch 17/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0477 - acc: 0.9904 - val_loss: 0.9212 - val_acc: 0.7900\n",
      "Epoch 18/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0402 - acc: 0.9910 - val_loss: 1.0201 - val_acc: 0.7840\n",
      "Epoch 19/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0387 - acc: 0.9924 - val_loss: 1.0059 - val_acc: 0.7680\n",
      "Epoch 20/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0306 - acc: 0.9928 - val_loss: 1.0565 - val_acc: 0.7780\n",
      "Epoch 21/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0283 - acc: 0.9949 - val_loss: 1.0888 - val_acc: 0.7820\n",
      "Epoch 22/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0239 - acc: 0.9951 - val_loss: 1.1547 - val_acc: 0.7760\n",
      "Epoch 23/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0236 - acc: 0.9955 - val_loss: 1.2643 - val_acc: 0.7820\n",
      "Epoch 24/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0186 - acc: 0.9962 - val_loss: 1.2699 - val_acc: 0.7760\n",
      "Epoch 25/25\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.0186 - acc: 0.9960 - val_loss: 1.3088 - val_acc: 0.7840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f50426e2ef0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 620us/step\n",
      "Loss        : 1.3088\n",
      "Accuracy    : 0.7840\n",
      "Precision   : 0.7689\n",
      "Recall      : 0.7342\n",
      "F1          : 0.7512\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
