{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU  + ElMO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_table(\"../../../data/es/train_es.tsv\", index_col=\"id\")\n",
    "df_dev = pd.read_table(\"../../../data/es/dev_es.tsv\", index_col=\"id\")\n",
    "\n",
    "text_train, y_train = df_train[\"text\"].values, df_train[\"HS\"].values\n",
    "text_dev, y_dev = df_dev[\"text\"].values, df_dev[\"HS\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tengo que hacer dos cosas:\n",
    "\n",
    "- Primero, convertir los tweets a secuencias de texto\n",
    "- Luego, paddear las secuencias a cierta longitud (Keras necesita esto para poder paralelizar c√°lculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "max_length = 30\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    if len(tokens) >= max_length:\n",
    "        tokens = tokens[:max_length]\n",
    "    else:\n",
    "        tokens = tokens + [''] * (max_length - len(tokens))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "text_train = [preprocess_tweet(tweet) for tweet in df_train[\"text\"].values]\n",
    "text_dev = [preprocess_tweet(tweet) for tweet in df_dev[\"text\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from elmoformanylangs import Embedder\n",
    "\n",
    "e = Embedder(\"../../../models/elmo/es/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['easyjet', 'quiere', 'duplicar', 'el', 'n√∫mero', 'de', 'mujeres', 'piloto', \"'\", 'ver√°s', 't√∫', 'para', 'aparcar', 'el', 'avi√≥n', '..', 'http://t.co/46NuLkm09x', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(text_train[0])\n",
    "\n",
    "\n",
    "X_train = np.array(e.sents2elmo(text_train))\n",
    "X_dev = np.array(e.sents2elmo(text_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4469, 30, 1024), (500, 30, 1024))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 256)               983808    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,049,857\n",
      "Trainable params: 1,049,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4469 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "4469/4469 [==============================] - 7s 2ms/step - loss: 0.7864 - acc: 0.5440 - val_loss: 0.6708 - val_acc: 0.5880\n",
      "Epoch 2/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.7157 - acc: 0.5666 - val_loss: 0.6840 - val_acc: 0.5600\n",
      "Epoch 3/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.7003 - acc: 0.5775 - val_loss: 0.6671 - val_acc: 0.6180\n",
      "Epoch 4/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.6820 - acc: 0.5863 - val_loss: 0.6565 - val_acc: 0.6360\n",
      "Epoch 5/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.6581 - acc: 0.6236 - val_loss: 0.6354 - val_acc: 0.6700\n",
      "Epoch 6/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.6316 - acc: 0.6556 - val_loss: 0.6176 - val_acc: 0.6800\n",
      "Epoch 7/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5947 - acc: 0.6820 - val_loss: 0.5798 - val_acc: 0.7060\n",
      "Epoch 8/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5715 - acc: 0.7091 - val_loss: 0.5400 - val_acc: 0.7300\n",
      "Epoch 9/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5396 - acc: 0.7317 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 10/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5077 - acc: 0.7503 - val_loss: 0.4866 - val_acc: 0.7640\n",
      "Epoch 11/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4675 - acc: 0.7816 - val_loss: 0.4699 - val_acc: 0.7840\n",
      "Epoch 12/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4532 - acc: 0.7865 - val_loss: 0.4563 - val_acc: 0.7900\n",
      "Epoch 13/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4387 - acc: 0.8006 - val_loss: 0.4575 - val_acc: 0.7980\n",
      "Epoch 14/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4179 - acc: 0.8172 - val_loss: 0.4466 - val_acc: 0.8040\n",
      "Epoch 15/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4043 - acc: 0.8174 - val_loss: 0.4421 - val_acc: 0.7960\n",
      "Epoch 16/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3905 - acc: 0.8320 - val_loss: 0.4443 - val_acc: 0.8000\n",
      "Epoch 17/20\n",
      "4469/4469 [==============================] - 5s 1ms/step - loss: 0.3821 - acc: 0.8355 - val_loss: 0.4402 - val_acc: 0.8020\n",
      "Epoch 18/20\n",
      "4469/4469 [==============================] - 5s 1ms/step - loss: 0.3703 - acc: 0.8369 - val_loss: 0.4424 - val_acc: 0.8020\n",
      "Epoch 19/20\n",
      "4469/4469 [==============================] - 5s 1ms/step - loss: 0.3626 - acc: 0.8483 - val_loss: 0.4432 - val_acc: 0.7920\n",
      "Epoch 20/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3515 - acc: 0.8523 - val_loss: 0.4448 - val_acc: 0.7920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18b6470f28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU, Dropout, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "optimizer_args = {\n",
    "    \"lr\": 0.0005,\n",
    "    \"decay\": 0.01\n",
    "}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(256, input_shape=(max_length, embedding_dim)))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 559us/step\n",
      "Loss        : 0.4448\n",
      "Accuracy    : 0.7920\n",
      "Precision   : 0.8073\n",
      "Recall      : 0.6982\n",
      "F1          : 0.7488\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU, Dropout, LSTM, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(256, input_shape=(max_length, embedding_dim))))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4469 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "4469/4469 [==============================] - 11s 2ms/step - loss: 0.7846 - acc: 0.5659 - val_loss: 0.6508 - val_acc: 0.6280\n",
      "Epoch 2/25\n",
      "4469/4469 [==============================] - 9s 2ms/step - loss: 0.6780 - acc: 0.6212 - val_loss: 0.6331 - val_acc: 0.6480\n",
      "Epoch 3/25\n",
      "4469/4469 [==============================] - 9s 2ms/step - loss: 0.6264 - acc: 0.6599 - val_loss: 0.6091 - val_acc: 0.6840\n",
      "Epoch 4/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5968 - acc: 0.6894 - val_loss: 0.5853 - val_acc: 0.6920\n",
      "Epoch 5/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5863 - acc: 0.6928 - val_loss: 0.5657 - val_acc: 0.7180\n",
      "Epoch 6/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5453 - acc: 0.7288 - val_loss: 0.5359 - val_acc: 0.7500\n",
      "Epoch 7/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5095 - acc: 0.7545 - val_loss: 0.5120 - val_acc: 0.7540\n",
      "Epoch 8/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4839 - acc: 0.7628 - val_loss: 0.4984 - val_acc: 0.7760\n",
      "Epoch 9/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4761 - acc: 0.7818 - val_loss: 0.4838 - val_acc: 0.7740\n",
      "Epoch 10/25\n",
      "4469/4469 [==============================] - 9s 2ms/step - loss: 0.4471 - acc: 0.7910 - val_loss: 0.4807 - val_acc: 0.7740\n",
      "Epoch 11/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4372 - acc: 0.8029 - val_loss: 0.4660 - val_acc: 0.7880\n",
      "Epoch 12/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4230 - acc: 0.8094 - val_loss: 0.4598 - val_acc: 0.7920\n",
      "Epoch 13/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4121 - acc: 0.8149 - val_loss: 0.4581 - val_acc: 0.7920\n",
      "Epoch 14/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3996 - acc: 0.8156 - val_loss: 0.4463 - val_acc: 0.7960\n",
      "Epoch 15/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3965 - acc: 0.8235 - val_loss: 0.4451 - val_acc: 0.7880\n",
      "Epoch 16/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3824 - acc: 0.8344 - val_loss: 0.4399 - val_acc: 0.7940\n",
      "Epoch 17/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3642 - acc: 0.8452 - val_loss: 0.4395 - val_acc: 0.7980\n",
      "Epoch 18/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3605 - acc: 0.8389 - val_loss: 0.4400 - val_acc: 0.8000\n",
      "Epoch 19/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3562 - acc: 0.8521 - val_loss: 0.4389 - val_acc: 0.7880\n",
      "Epoch 20/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3413 - acc: 0.8505 - val_loss: 0.4459 - val_acc: 0.7960\n",
      "Epoch 21/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3394 - acc: 0.8599 - val_loss: 0.4512 - val_acc: 0.8060\n",
      "Epoch 22/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3327 - acc: 0.8570 - val_loss: 0.4383 - val_acc: 0.8000\n",
      "Epoch 23/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3047 - acc: 0.8718 - val_loss: 0.4401 - val_acc: 0.7980\n",
      "Epoch 24/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3135 - acc: 0.8687 - val_loss: 0.4452 - val_acc: 0.7980\n",
      "Epoch 25/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3053 - acc: 0.8718 - val_loss: 0.4446 - val_acc: 0.7940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1888161828>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=25, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 1ms/step\n",
      "Loss        : 0.4446\n",
      "Accuracy    : 0.7940\n",
      "Precision   : 0.7692\n",
      "Recall      : 0.7658\n",
      "F1          : 0.7675\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Vamos a ver los tweets con mayores errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev[\"proba\"] = model.predict_proba(X_dev)\n",
    "\n",
    "true_positives = df_dev[(df_dev[\"HS\"] == 1) & (df_dev[\"proba\"] >= 0.5)].copy()\n",
    "true_negatives = df_dev[(df_dev[\"HS\"] == 0) & (df_dev[\"proba\"] < 0.5)].copy()\n",
    "\n",
    "false_positives = df_dev[(df_dev[\"HS\"] == 0) & (df_dev[\"proba\"] > 0.5)].copy()\n",
    "false_positives.sort_values(\"proba\", ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "false_negatives = df_dev[(df_dev[\"HS\"] == 1) & (df_dev[\"proba\"] < 0.5)].copy()\n",
    "false_negatives.sort_values(\"proba\", ascending=True, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_true</th>\n",
       "      <th>pred_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hs=1</th>\n",
       "      <td>170</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs=0</th>\n",
       "      <td>51</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_true  pred_false\n",
       "real                       \n",
       "hs=1        170          52\n",
       "hs=0         51         227"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = pd.DataFrame([\n",
    "    {\"real\":\"hs=1\", \"pred_true\": len(true_positives), \"pred_false\": len(false_negatives)},\n",
    "    {\"real\":\"hs=0\", \"pred_true\": len(false_positives), \"pred_false\": len(true_negatives)}\n",
    "])\n",
    "\n",
    "conf_matrix.set_index(\"real\", inplace=True)\n",
    "\n",
    "conf_matrix[[\"pred_true\", \"pred_false\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21152</th>\n",
       "      <td>@NatyBurgos15 @Horaciogenta @PaolaPa05 C√°llate vos Black and bitch como la puta falsa abogada. Espero se pudra en la c√°rcel y devuelva todo. Ded√≠cate a estudiar en serio. La dr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21535</th>\n",
       "      <td>#VOX critica duramente a ‚Å¶@pablocasado_‚Å© ‚ÄúLes da la bienvenida como si fuera un cartel del welcome de #Carmena ‚Äú ¬°Expulsi√≥n inmediata de moromierdas!  https://t.co/HaySDibj2l</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23415</th>\n",
       "      <td>Exacto! #puralata #feminazis #HombreAbusado https://t.co/zTEvaftxcd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24488</th>\n",
       "      <td>Un indocumentado...habla y habla y no para y acaba hablando su ignorancia.Empezamos bien. https://t.co/SMRsqjtEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24590</th>\n",
       "      <td>SOMOS MUCHO M√ÅS DE LO QUE SUE√ëAS SER PINCH√â SUDACA CAGADO, y si no te gusta dime donde nos topamos pa reventarnos el hocico 1:1 @amarchesin1 https://t.co/vHHPBKS1AK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>En que se parece superman a una mujer lista: En que los dos son personajes de ciencia-ficci√≥n.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22065</th>\n",
       "      <td>| lo √∫nico que dominas es mi polla en tu cara. https://t.co/qlYOd4zPwW</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20019</th>\n",
       "      <td>Y NADIE SE HA PREGUNTADO LO QUE LE VA A COSTAR AL HOMBRE DEL GUANTAZO LA SITUACION..?!? PORQUE SEGURO ES, QUE EL MENDA MUSULMONO LE VA A PONER UNA DENUNCIA, QUE EL FALLO VA A S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>¬øVes que tu co√±o me importe? C√≥mete mi polla, basura https://t.co/ht02KyYWZh</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21887</th>\n",
       "      <td>@A3Noticias Esta tiene que ser una 'fake new' porque las mujeres son siempre las v√≠ctimas, no las hijas de puta maltratadoras. Eso o el chaval es un machista que se lo ha merec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                      text  \\\n",
       "id                                                                                                                                                                                           \n",
       "21152  @NatyBurgos15 @Horaciogenta @PaolaPa05 C√°llate vos Black and bitch como la puta falsa abogada. Espero se pudra en la c√°rcel y devuelva todo. Ded√≠cate a estudiar en serio. La dr...   \n",
       "21535       #VOX critica duramente a ‚Å¶@pablocasado_‚Å© ‚ÄúLes da la bienvenida como si fuera un cartel del welcome de #Carmena ‚Äú ¬°Expulsi√≥n inmediata de moromierdas!  https://t.co/HaySDibj2l   \n",
       "23415                                                                                                                  Exacto! #puralata #feminazis #HombreAbusado https://t.co/zTEvaftxcd   \n",
       "24488                                                                    Un indocumentado...habla y habla y no para y acaba hablando su ignorancia.Empezamos bien. https://t.co/SMRsqjtEBT   \n",
       "24590                 SOMOS MUCHO M√ÅS DE LO QUE SUE√ëAS SER PINCH√â SUDACA CAGADO, y si no te gusta dime donde nos topamos pa reventarnos el hocico 1:1 @amarchesin1 https://t.co/vHHPBKS1AK   \n",
       "24481                                                                                       En que se parece superman a una mujer lista: En que los dos son personajes de ciencia-ficci√≥n.   \n",
       "22065                                                                                                               | lo √∫nico que dominas es mi polla en tu cara. https://t.co/qlYOd4zPwW   \n",
       "20019  Y NADIE SE HA PREGUNTADO LO QUE LE VA A COSTAR AL HOMBRE DEL GUANTAZO LA SITUACION..?!? PORQUE SEGURO ES, QUE EL MENDA MUSULMONO LE VA A PONER UNA DENUNCIA, QUE EL FALLO VA A S...   \n",
       "24352                                                                                                         ¬øVes que tu co√±o me importe? C√≥mete mi polla, basura https://t.co/ht02KyYWZh   \n",
       "21887  @A3Noticias Esta tiene que ser una 'fake new' porque las mujeres son siempre las v√≠ctimas, no las hijas de puta maltratadoras. Eso o el chaval es un machista que se lo ha merec...   \n",
       "\n",
       "       HS  TR  AG     proba  \n",
       "id                           \n",
       "21152   1   1   1  0.018355  \n",
       "21535   1   0   1  0.026838  \n",
       "23415   1   0   1  0.067498  \n",
       "24488   1   0   0  0.068196  \n",
       "24590   1   1   1  0.076638  \n",
       "24481   1   0   0  0.083606  \n",
       "22065   1   1   1  0.083916  \n",
       "20019   1   0   1  0.096642  \n",
       "24352   1   1   1  0.097788  \n",
       "21887   1   0   1  0.104357  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives.iloc[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22014</th>\n",
       "      <td>Ni t√∫ eres una zorra hambrienta ni yo un incorregible depredador.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22889</th>\n",
       "      <td>@elajidetuvida .El acoso y la violaci√≥n tiene connotaciones muy prifundas. El poder econ√≥mico de estos acosadores tiene el mismo efecto que un cuchillo en el cuello por violado...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24159</th>\n",
       "      <td>@LeonDeJapon Jajajajajaja tu eres uno, diego jajajajajaja mentira perra perra perrraaaaaaaaaa de mierda jajaja ‚ô°</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24209</th>\n",
       "      <td>¬øYa les he contado que si fuera rica/millonaria ser√≠a toda una PERRA?, Yisus me est√° ense√±ando humildad... Y no he aprendido mucho ldvdd.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22938</th>\n",
       "      <td>Masculinidad fr√°gil es mi crush franc√©s ech√°ndose un clavado al cenote solo porque un grupo de √°rabes le dijo pussy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.749029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23021</th>\n",
       "      <td>Creo que los colegios que impartan el Islam debe de ser el mismo numero de co!egiosque en los pa√≠ses √°rabes  imparten el cristianismo.Que no somos m√°s tontos porque no ensayamo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.761440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22517</th>\n",
       "      <td>-¬øeres poblana? -soy colombiana -¬øy por qu√© eres g√ºera? en Colombia TODAS son morenas, fui a Colombia 3 veces. -ok, ment√≠ üôÑ solo me pinto el cabello</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23380</th>\n",
       "      <td>Pero es que pones Egipto o Emiratos √Årabes que son nuestros casos e igual juran que vamos a Qatar gracias a Korea... https://t.co/fJScL7bYfL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24066</th>\n",
       "      <td>üëûLa huella dejada por los √°rabes en Al-Andalus, es decir, en Espa√±a https://t.co/HBoW2AOBey https://t.co/sYejNvzv6j</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24402</th>\n",
       "      <td>zorra eres tu que no te sientes hombre y no entiendes que toda mujer es bella</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23912</th>\n",
       "      <td>@RoyBarreras mira que tu eres bandido y criminal al igual que santos mas temprano que tarde pagaran sus crimenes escoria basura</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.638719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20952</th>\n",
       "      <td>@NicolasMaduro Callate la jeta perra que de este a√±o no pasas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22165</th>\n",
       "      <td>Uno de mis prop√≥sitos para este 2018: ense√±arle a mi perra a traerme el desayuno a la cama.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.621148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21892</th>\n",
       "      <td>@saancisco Callate puta tu eres el traidor.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21788</th>\n",
       "      <td>@Habubus_ PERO QUIEN ES. MATEO ahora tu eres mateo y m voy a la puta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.567772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                      text  \\\n",
       "id                                                                                                                                                                                           \n",
       "22014                                                                                                                    Ni t√∫ eres una zorra hambrienta ni yo un incorregible depredador.   \n",
       "22889  @elajidetuvida .El acoso y la violaci√≥n tiene connotaciones muy prifundas. El poder econ√≥mico de estos acosadores tiene el mismo efecto que un cuchillo en el cuello por violado...   \n",
       "24159                                                                     @LeonDeJapon Jajajajajaja tu eres uno, diego jajajajajaja mentira perra perra perrraaaaaaaaaa de mierda jajaja ‚ô°   \n",
       "24209                                            ¬øYa les he contado que si fuera rica/millonaria ser√≠a toda una PERRA?, Yisus me est√° ense√±ando humildad... Y no he aprendido mucho ldvdd.   \n",
       "22938                                                                  Masculinidad fr√°gil es mi crush franc√©s ech√°ndose un clavado al cenote solo porque un grupo de √°rabes le dijo pussy   \n",
       "23021  Creo que los colegios que impartan el Islam debe de ser el mismo numero de co!egiosque en los pa√≠ses √°rabes  imparten el cristianismo.Que no somos m√°s tontos porque no ensayamo...   \n",
       "22517                                 -¬øeres poblana? -soy colombiana -¬øy por qu√© eres g√ºera? en Colombia TODAS son morenas, fui a Colombia 3 veces. -ok, ment√≠ üôÑ solo me pinto el cabello   \n",
       "23380                                         Pero es que pones Egipto o Emiratos √Årabes que son nuestros casos e igual juran que vamos a Qatar gracias a Korea... https://t.co/fJScL7bYfL   \n",
       "24066                                                                  üëûLa huella dejada por los √°rabes en Al-Andalus, es decir, en Espa√±a https://t.co/HBoW2AOBey https://t.co/sYejNvzv6j   \n",
       "24402                                                                                                        zorra eres tu que no te sientes hombre y no entiendes que toda mujer es bella   \n",
       "23912                                                      @RoyBarreras mira que tu eres bandido y criminal al igual que santos mas temprano que tarde pagaran sus crimenes escoria basura   \n",
       "20952                                                                                                                        @NicolasMaduro Callate la jeta perra que de este a√±o no pasas   \n",
       "22165                                                                                          Uno de mis prop√≥sitos para este 2018: ense√±arle a mi perra a traerme el desayuno a la cama.   \n",
       "21892                                                                                                                                          @saancisco Callate puta tu eres el traidor.   \n",
       "21788                                                                                                                 @Habubus_ PERO QUIEN ES. MATEO ahora tu eres mateo y m voy a la puta   \n",
       "\n",
       "       HS  TR  AG     proba  \n",
       "id                           \n",
       "22014   0   0   0  0.868541  \n",
       "22889   0   0   0  0.624661  \n",
       "24159   0   0   0  0.962730  \n",
       "24209   0   0   0  0.712699  \n",
       "22938   0   0   0  0.749029  \n",
       "23021   0   0   0  0.761440  \n",
       "22517   0   0   0  0.974465  \n",
       "23380   0   0   0  0.538016  \n",
       "24066   0   0   0  0.685159  \n",
       "24402   0   0   0  0.950535  \n",
       "23912   0   0   0  0.638719  \n",
       "20952   0   0   0  0.720920  \n",
       "22165   0   0   0  0.621148  \n",
       "21892   0   0   0  0.969750  \n",
       "21788   0   0   0  0.567772  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives.sample(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
