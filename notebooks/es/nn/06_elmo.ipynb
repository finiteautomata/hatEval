{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU  + ElMO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.read_table(\"../../../data/es/train_es.tsv\", index_col=\"id\")\n",
    "df_dev = pd.read_table(\"../../../data/es/dev_es.tsv\", index_col=\"id\")\n",
    "\n",
    "text_train, y_train = df_train[\"text\"].values, df_train[\"HS\"].values\n",
    "text_dev, y_dev = df_dev[\"text\"].values, df_dev[\"HS\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tengo que hacer dos cosas:\n",
    "\n",
    "- Primero, convertir los tweets a secuencias de texto\n",
    "- Luego, paddear las secuencias a cierta longitud (Keras necesita esto para poder paralelizar cálculo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "max_length = 30\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    \n",
    "    if len(tokens) >= max_length:\n",
    "        tokens = tokens[:max_length]\n",
    "    else:\n",
    "        tokens = tokens + [''] * (max_length - len(tokens))\n",
    "    return tokens\n",
    "\n",
    "\n",
    "text_train = [preprocess_tweet(tweet) for tweet in df_train[\"text\"].values]\n",
    "text_dev = [preprocess_tweet(tweet) for tweet in df_dev[\"text\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from elmoformanylangs import Embedder\n",
    "\n",
    "e = Embedder(\"../../../models/elmo/es/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['easyjet', 'quiere', 'duplicar', 'el', 'número', 'de', 'mujeres', 'piloto', \"'\", 'verás', 'tú', 'para', 'aparcar', 'el', 'avión', '..', 'http://t.co/46NuLkm09x', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print(text_train[0])\n",
    "\n",
    "\n",
    "X_train = np.array(e.sents2elmo(text_train))\n",
    "X_dev = np.array(e.sents2elmo(text_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4469, 30, 1024), (500, 30, 1024))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, 256)               983808    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,049,857\n",
      "Trainable params: 1,049,857\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 4469 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "4469/4469 [==============================] - 7s 2ms/step - loss: 0.7864 - acc: 0.5440 - val_loss: 0.6708 - val_acc: 0.5880\n",
      "Epoch 2/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.7157 - acc: 0.5666 - val_loss: 0.6840 - val_acc: 0.5600\n",
      "Epoch 3/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.7003 - acc: 0.5775 - val_loss: 0.6671 - val_acc: 0.6180\n",
      "Epoch 4/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.6820 - acc: 0.5863 - val_loss: 0.6565 - val_acc: 0.6360\n",
      "Epoch 5/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.6581 - acc: 0.6236 - val_loss: 0.6354 - val_acc: 0.6700\n",
      "Epoch 6/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.6316 - acc: 0.6556 - val_loss: 0.6176 - val_acc: 0.6800\n",
      "Epoch 7/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5947 - acc: 0.6820 - val_loss: 0.5798 - val_acc: 0.7060\n",
      "Epoch 8/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5715 - acc: 0.7091 - val_loss: 0.5400 - val_acc: 0.7300\n",
      "Epoch 9/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5396 - acc: 0.7317 - val_loss: 0.5156 - val_acc: 0.7500\n",
      "Epoch 10/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.5077 - acc: 0.7503 - val_loss: 0.4866 - val_acc: 0.7640\n",
      "Epoch 11/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4675 - acc: 0.7816 - val_loss: 0.4699 - val_acc: 0.7840\n",
      "Epoch 12/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4532 - acc: 0.7865 - val_loss: 0.4563 - val_acc: 0.7900\n",
      "Epoch 13/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4387 - acc: 0.8006 - val_loss: 0.4575 - val_acc: 0.7980\n",
      "Epoch 14/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4179 - acc: 0.8172 - val_loss: 0.4466 - val_acc: 0.8040\n",
      "Epoch 15/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.4043 - acc: 0.8174 - val_loss: 0.4421 - val_acc: 0.7960\n",
      "Epoch 16/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3905 - acc: 0.8320 - val_loss: 0.4443 - val_acc: 0.8000\n",
      "Epoch 17/20\n",
      "4469/4469 [==============================] - 5s 1ms/step - loss: 0.3821 - acc: 0.8355 - val_loss: 0.4402 - val_acc: 0.8020\n",
      "Epoch 18/20\n",
      "4469/4469 [==============================] - 5s 1ms/step - loss: 0.3703 - acc: 0.8369 - val_loss: 0.4424 - val_acc: 0.8020\n",
      "Epoch 19/20\n",
      "4469/4469 [==============================] - 5s 1ms/step - loss: 0.3626 - acc: 0.8483 - val_loss: 0.4432 - val_acc: 0.7920\n",
      "Epoch 20/20\n",
      "4469/4469 [==============================] - 6s 1ms/step - loss: 0.3515 - acc: 0.8523 - val_loss: 0.4448 - val_acc: 0.7920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f18b6470f28>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU, Dropout, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "optimizer_args = {\n",
    "    \"lr\": 0.0005,\n",
    "    \"decay\": 0.01\n",
    "}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(256, input_shape=(max_length, embedding_dim)))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 0s 559us/step\n",
      "Loss        : 0.4448\n",
      "Accuracy    : 0.7920\n",
      "Precision   : 0.8073\n",
      "Recall      : 0.6982\n",
      "F1          : 0.7488\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import GRU, Dropout, LSTM, Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "embedding_dim = 1024\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(256, input_shape=(max_length, embedding_dim))))\n",
    "model.add(Dropout(0.75))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=Adam(**optimizer_args), \n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4469 samples, validate on 500 samples\n",
      "Epoch 1/25\n",
      "4469/4469 [==============================] - 11s 2ms/step - loss: 0.7846 - acc: 0.5659 - val_loss: 0.6508 - val_acc: 0.6280\n",
      "Epoch 2/25\n",
      "4469/4469 [==============================] - 9s 2ms/step - loss: 0.6780 - acc: 0.6212 - val_loss: 0.6331 - val_acc: 0.6480\n",
      "Epoch 3/25\n",
      "4469/4469 [==============================] - 9s 2ms/step - loss: 0.6264 - acc: 0.6599 - val_loss: 0.6091 - val_acc: 0.6840\n",
      "Epoch 4/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5968 - acc: 0.6894 - val_loss: 0.5853 - val_acc: 0.6920\n",
      "Epoch 5/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5863 - acc: 0.6928 - val_loss: 0.5657 - val_acc: 0.7180\n",
      "Epoch 6/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5453 - acc: 0.7288 - val_loss: 0.5359 - val_acc: 0.7500\n",
      "Epoch 7/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.5095 - acc: 0.7545 - val_loss: 0.5120 - val_acc: 0.7540\n",
      "Epoch 8/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4839 - acc: 0.7628 - val_loss: 0.4984 - val_acc: 0.7760\n",
      "Epoch 9/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4761 - acc: 0.7818 - val_loss: 0.4838 - val_acc: 0.7740\n",
      "Epoch 10/25\n",
      "4469/4469 [==============================] - 9s 2ms/step - loss: 0.4471 - acc: 0.7910 - val_loss: 0.4807 - val_acc: 0.7740\n",
      "Epoch 11/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4372 - acc: 0.8029 - val_loss: 0.4660 - val_acc: 0.7880\n",
      "Epoch 12/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4230 - acc: 0.8094 - val_loss: 0.4598 - val_acc: 0.7920\n",
      "Epoch 13/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.4121 - acc: 0.8149 - val_loss: 0.4581 - val_acc: 0.7920\n",
      "Epoch 14/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3996 - acc: 0.8156 - val_loss: 0.4463 - val_acc: 0.7960\n",
      "Epoch 15/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3965 - acc: 0.8235 - val_loss: 0.4451 - val_acc: 0.7880\n",
      "Epoch 16/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3824 - acc: 0.8344 - val_loss: 0.4399 - val_acc: 0.7940\n",
      "Epoch 17/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3642 - acc: 0.8452 - val_loss: 0.4395 - val_acc: 0.7980\n",
      "Epoch 18/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3605 - acc: 0.8389 - val_loss: 0.4400 - val_acc: 0.8000\n",
      "Epoch 19/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3562 - acc: 0.8521 - val_loss: 0.4389 - val_acc: 0.7880\n",
      "Epoch 20/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3413 - acc: 0.8505 - val_loss: 0.4459 - val_acc: 0.7960\n",
      "Epoch 21/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3394 - acc: 0.8599 - val_loss: 0.4512 - val_acc: 0.8060\n",
      "Epoch 22/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3327 - acc: 0.8570 - val_loss: 0.4383 - val_acc: 0.8000\n",
      "Epoch 23/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3047 - acc: 0.8718 - val_loss: 0.4401 - val_acc: 0.7980\n",
      "Epoch 24/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3135 - acc: 0.8687 - val_loss: 0.4452 - val_acc: 0.7980\n",
      "Epoch 25/25\n",
      "4469/4469 [==============================] - 10s 2ms/step - loss: 0.3053 - acc: 0.8718 - val_loss: 0.4446 - val_acc: 0.7940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1888161828>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train, validation_data=(X_dev, y_dev), epochs=25, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 1s 1ms/step\n",
      "Loss        : 0.4446\n",
      "Accuracy    : 0.7940\n",
      "Precision   : 0.7692\n",
      "Recall      : 0.7658\n",
      "F1          : 0.7675\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "Vamos a ver los tweets con mayores errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev[\"proba\"] = model.predict_proba(X_dev)\n",
    "\n",
    "true_positives = df_dev[(df_dev[\"HS\"] == 1) & (df_dev[\"proba\"] >= 0.5)].copy()\n",
    "true_negatives = df_dev[(df_dev[\"HS\"] == 0) & (df_dev[\"proba\"] < 0.5)].copy()\n",
    "\n",
    "false_positives = df_dev[(df_dev[\"HS\"] == 0) & (df_dev[\"proba\"] > 0.5)].copy()\n",
    "false_positives.sort_values(\"proba\", ascending=False, inplace=True)\n",
    "\n",
    "\n",
    "false_negatives = df_dev[(df_dev[\"HS\"] == 1) & (df_dev[\"proba\"] < 0.5)].copy()\n",
    "false_negatives.sort_values(\"proba\", ascending=True, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_true</th>\n",
       "      <th>pred_false</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hs=1</th>\n",
       "      <td>170</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hs=0</th>\n",
       "      <td>51</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred_true  pred_false\n",
       "real                       \n",
       "hs=1        170          52\n",
       "hs=0         51         227"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf_matrix = pd.DataFrame([\n",
    "    {\"real\":\"hs=1\", \"pred_true\": len(true_positives), \"pred_false\": len(false_negatives)},\n",
    "    {\"real\":\"hs=0\", \"pred_true\": len(false_positives), \"pred_false\": len(true_negatives)}\n",
    "])\n",
    "\n",
    "conf_matrix.set_index(\"real\", inplace=True)\n",
    "\n",
    "conf_matrix[[\"pred_true\", \"pred_false\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21152</th>\n",
       "      <td>@NatyBurgos15 @Horaciogenta @PaolaPa05 Cállate vos Black and bitch como la puta falsa abogada. Espero se pudra en la cárcel y devuelva todo. Dedícate a estudiar en serio. La dr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21535</th>\n",
       "      <td>#VOX critica duramente a ⁦@pablocasado_⁩ “Les da la bienvenida como si fuera un cartel del welcome de #Carmena “ ¡Expulsión inmediata de moromierdas!  https://t.co/HaySDibj2l</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23415</th>\n",
       "      <td>Exacto! #puralata #feminazis #HombreAbusado https://t.co/zTEvaftxcd</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.067498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24488</th>\n",
       "      <td>Un indocumentado...habla y habla y no para y acaba hablando su ignorancia.Empezamos bien. https://t.co/SMRsqjtEBT</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24590</th>\n",
       "      <td>SOMOS MUCHO MÁS DE LO QUE SUEÑAS SER PINCHÉ SUDACA CAGADO, y si no te gusta dime donde nos topamos pa reventarnos el hocico 1:1 @amarchesin1 https://t.co/vHHPBKS1AK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.076638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24481</th>\n",
       "      <td>En que se parece superman a una mujer lista: En que los dos son personajes de ciencia-ficción.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22065</th>\n",
       "      <td>| lo único que dominas es mi polla en tu cara. https://t.co/qlYOd4zPwW</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20019</th>\n",
       "      <td>Y NADIE SE HA PREGUNTADO LO QUE LE VA A COSTAR AL HOMBRE DEL GUANTAZO LA SITUACION..?!? PORQUE SEGURO ES, QUE EL MENDA MUSULMONO LE VA A PONER UNA DENUNCIA, QUE EL FALLO VA A S...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.096642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24352</th>\n",
       "      <td>¿Ves que tu coño me importe? Cómete mi polla, basura https://t.co/ht02KyYWZh</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21887</th>\n",
       "      <td>@A3Noticias Esta tiene que ser una 'fake new' porque las mujeres son siempre las víctimas, no las hijas de puta maltratadoras. Eso o el chaval es un machista que se lo ha merec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                      text  \\\n",
       "id                                                                                                                                                                                           \n",
       "21152  @NatyBurgos15 @Horaciogenta @PaolaPa05 Cállate vos Black and bitch como la puta falsa abogada. Espero se pudra en la cárcel y devuelva todo. Dedícate a estudiar en serio. La dr...   \n",
       "21535       #VOX critica duramente a ⁦@pablocasado_⁩ “Les da la bienvenida como si fuera un cartel del welcome de #Carmena “ ¡Expulsión inmediata de moromierdas!  https://t.co/HaySDibj2l   \n",
       "23415                                                                                                                  Exacto! #puralata #feminazis #HombreAbusado https://t.co/zTEvaftxcd   \n",
       "24488                                                                    Un indocumentado...habla y habla y no para y acaba hablando su ignorancia.Empezamos bien. https://t.co/SMRsqjtEBT   \n",
       "24590                 SOMOS MUCHO MÁS DE LO QUE SUEÑAS SER PINCHÉ SUDACA CAGADO, y si no te gusta dime donde nos topamos pa reventarnos el hocico 1:1 @amarchesin1 https://t.co/vHHPBKS1AK   \n",
       "24481                                                                                       En que se parece superman a una mujer lista: En que los dos son personajes de ciencia-ficción.   \n",
       "22065                                                                                                               | lo único que dominas es mi polla en tu cara. https://t.co/qlYOd4zPwW   \n",
       "20019  Y NADIE SE HA PREGUNTADO LO QUE LE VA A COSTAR AL HOMBRE DEL GUANTAZO LA SITUACION..?!? PORQUE SEGURO ES, QUE EL MENDA MUSULMONO LE VA A PONER UNA DENUNCIA, QUE EL FALLO VA A S...   \n",
       "24352                                                                                                         ¿Ves que tu coño me importe? Cómete mi polla, basura https://t.co/ht02KyYWZh   \n",
       "21887  @A3Noticias Esta tiene que ser una 'fake new' porque las mujeres son siempre las víctimas, no las hijas de puta maltratadoras. Eso o el chaval es un machista que se lo ha merec...   \n",
       "\n",
       "       HS  TR  AG     proba  \n",
       "id                           \n",
       "21152   1   1   1  0.018355  \n",
       "21535   1   0   1  0.026838  \n",
       "23415   1   0   1  0.067498  \n",
       "24488   1   0   0  0.068196  \n",
       "24590   1   1   1  0.076638  \n",
       "24481   1   0   0  0.083606  \n",
       "22065   1   1   1  0.083916  \n",
       "20019   1   0   1  0.096642  \n",
       "24352   1   1   1  0.097788  \n",
       "21887   1   0   1  0.104357  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_negatives.iloc[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>HS</th>\n",
       "      <th>TR</th>\n",
       "      <th>AG</th>\n",
       "      <th>proba</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22014</th>\n",
       "      <td>Ni tú eres una zorra hambrienta ni yo un incorregible depredador.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22889</th>\n",
       "      <td>@elajidetuvida .El acoso y la violación tiene connotaciones muy prifundas. El poder económico de estos acosadores tiene el mismo efecto que un cuchillo en el cuello por violado...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.624661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24159</th>\n",
       "      <td>@LeonDeJapon Jajajajajaja tu eres uno, diego jajajajajaja mentira perra perra perrraaaaaaaaaa de mierda jajaja ♡</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.962730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24209</th>\n",
       "      <td>¿Ya les he contado que si fuera rica/millonaria sería toda una PERRA?, Yisus me está enseñando humildad... Y no he aprendido mucho ldvdd.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.712699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22938</th>\n",
       "      <td>Masculinidad frágil es mi crush francés echándose un clavado al cenote solo porque un grupo de árabes le dijo pussy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.749029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23021</th>\n",
       "      <td>Creo que los colegios que impartan el Islam debe de ser el mismo numero de co!egiosque en los países árabes  imparten el cristianismo.Que no somos más tontos porque no ensayamo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.761440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22517</th>\n",
       "      <td>-¿eres poblana? -soy colombiana -¿y por qué eres güera? en Colombia TODAS son morenas, fui a Colombia 3 veces. -ok, mentí 🙄 solo me pinto el cabello</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.974465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23380</th>\n",
       "      <td>Pero es que pones Egipto o Emiratos Árabes que son nuestros casos e igual juran que vamos a Qatar gracias a Korea... https://t.co/fJScL7bYfL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24066</th>\n",
       "      <td>👞La huella dejada por los árabes en Al-Andalus, es decir, en España https://t.co/HBoW2AOBey https://t.co/sYejNvzv6j</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24402</th>\n",
       "      <td>zorra eres tu que no te sientes hombre y no entiendes que toda mujer es bella</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.950535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23912</th>\n",
       "      <td>@RoyBarreras mira que tu eres bandido y criminal al igual que santos mas temprano que tarde pagaran sus crimenes escoria basura</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.638719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20952</th>\n",
       "      <td>@NicolasMaduro Callate la jeta perra que de este año no pasas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.720920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22165</th>\n",
       "      <td>Uno de mis propósitos para este 2018: enseñarle a mi perra a traerme el desayuno a la cama.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.621148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21892</th>\n",
       "      <td>@saancisco Callate puta tu eres el traidor.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.969750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21788</th>\n",
       "      <td>@Habubus_ PERO QUIEN ES. MATEO ahora tu eres mateo y m voy a la puta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.567772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                      text  \\\n",
       "id                                                                                                                                                                                           \n",
       "22014                                                                                                                    Ni tú eres una zorra hambrienta ni yo un incorregible depredador.   \n",
       "22889  @elajidetuvida .El acoso y la violación tiene connotaciones muy prifundas. El poder económico de estos acosadores tiene el mismo efecto que un cuchillo en el cuello por violado...   \n",
       "24159                                                                     @LeonDeJapon Jajajajajaja tu eres uno, diego jajajajajaja mentira perra perra perrraaaaaaaaaa de mierda jajaja ♡   \n",
       "24209                                            ¿Ya les he contado que si fuera rica/millonaria sería toda una PERRA?, Yisus me está enseñando humildad... Y no he aprendido mucho ldvdd.   \n",
       "22938                                                                  Masculinidad frágil es mi crush francés echándose un clavado al cenote solo porque un grupo de árabes le dijo pussy   \n",
       "23021  Creo que los colegios que impartan el Islam debe de ser el mismo numero de co!egiosque en los países árabes  imparten el cristianismo.Que no somos más tontos porque no ensayamo...   \n",
       "22517                                 -¿eres poblana? -soy colombiana -¿y por qué eres güera? en Colombia TODAS son morenas, fui a Colombia 3 veces. -ok, mentí 🙄 solo me pinto el cabello   \n",
       "23380                                         Pero es que pones Egipto o Emiratos Árabes que son nuestros casos e igual juran que vamos a Qatar gracias a Korea... https://t.co/fJScL7bYfL   \n",
       "24066                                                                  👞La huella dejada por los árabes en Al-Andalus, es decir, en España https://t.co/HBoW2AOBey https://t.co/sYejNvzv6j   \n",
       "24402                                                                                                        zorra eres tu que no te sientes hombre y no entiendes que toda mujer es bella   \n",
       "23912                                                      @RoyBarreras mira que tu eres bandido y criminal al igual que santos mas temprano que tarde pagaran sus crimenes escoria basura   \n",
       "20952                                                                                                                        @NicolasMaduro Callate la jeta perra que de este año no pasas   \n",
       "22165                                                                                          Uno de mis propósitos para este 2018: enseñarle a mi perra a traerme el desayuno a la cama.   \n",
       "21892                                                                                                                                          @saancisco Callate puta tu eres el traidor.   \n",
       "21788                                                                                                                 @Habubus_ PERO QUIEN ES. MATEO ahora tu eres mateo y m voy a la puta   \n",
       "\n",
       "       HS  TR  AG     proba  \n",
       "id                           \n",
       "22014   0   0   0  0.868541  \n",
       "22889   0   0   0  0.624661  \n",
       "24159   0   0   0  0.962730  \n",
       "24209   0   0   0  0.712699  \n",
       "22938   0   0   0  0.749029  \n",
       "23021   0   0   0  0.761440  \n",
       "22517   0   0   0  0.974465  \n",
       "23380   0   0   0  0.538016  \n",
       "24066   0   0   0  0.685159  \n",
       "24402   0   0   0  0.950535  \n",
       "23912   0   0   0  0.638719  \n",
       "20952   0   0   0  0.720920  \n",
       "22165   0   0   0  0.621148  \n",
       "21892   0   0   0  0.969750  \n",
       "21788   0   0   0  0.567772  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_positives.sample(n=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
