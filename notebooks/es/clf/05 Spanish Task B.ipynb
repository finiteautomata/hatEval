{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hate.settings import corpora\n",
    "train = corpora['train_es']\n",
    "X_train, y_train = list(train.X()), list(train.y())\n",
    "dev = corpora['dev_es']\n",
    "X_dev, y_dev = list(dev.X()), list(dev.y())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('id', '20005'),\n",
       "             ('text', 'Me estoy comiendo la picada √°rabe m√°s rica de mi vida'),\n",
       "             ('HS', '0'),\n",
       "             ('TR', '0'),\n",
       "             ('AG', '0')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.entries[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Official evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "def evaluate_b(corpus, preds):\n",
    "    levels = [\"HS\", \"TargetRange\", \"Aggressiveness\"]\n",
    "    \n",
    "    gold = '/users/jsanchez/francolq/HATEVAL/A/public_development_es/dev_es.tsv'\n",
    "    ground_truth = pd.read_csv(gold, sep=\"\\t\", names=[\"ID\", \"Tweet-text\", \"HS\", \"TargetRange\", \"Aggressiveness\"],\n",
    "                               #skiprows=check_file(gold, 5),\n",
    "                               skiprows=1,\n",
    "                               converters={0: str, 1: str, 2: int, 3: int, 4: int}, header=None)\n",
    "\n",
    "    #predicted = pd.read_csv(pred, sep=\"\\t\", names=[\"ID\"] + levels , skiprows=check_file(pred, 4),\n",
    "    #                        converters={0: str, 1: int, 2: int, 3: int}, header=None)\n",
    "    ids = [e['id'] for e in corpus.entries]\n",
    "    hs = [int(p[0]) for p in preds]\n",
    "    tr = [int(p[1]) for p in preds]\n",
    "    ag = [int(p[2]) for p in preds]\n",
    "    predicted = pd.DataFrame({\n",
    "        'ID': ids,\n",
    "        'HS': hs,\n",
    "        'TargetRange': tr,\n",
    "        'Aggressiveness': ag,\n",
    "    })\n",
    "\n",
    "    # Check length files\n",
    "    if (len(ground_truth) != len(predicted)):\n",
    "        sys.exit('Prediction and gold data have different number of lines.')\n",
    "\n",
    "    # Check predicted classes\n",
    "    for c in levels:\n",
    "        gt_class = list(ground_truth[c].value_counts().keys())\n",
    "        if not (predicted[c].isin(gt_class).all()):\n",
    "            sys.exit(\"Wrong value in \" + c + \" prediction column.\")\n",
    "\n",
    "    data = pd.merge(ground_truth, predicted, on=\"ID\")\n",
    "\n",
    "    if (len(ground_truth) != len(data)):\n",
    "        sys.exit('Invalid tweet IDs in prediction.')\n",
    "\n",
    "    # Compute Performance Measures\n",
    "    acc_levels = dict.fromkeys(levels)\n",
    "    p_levels = dict.fromkeys(levels)\n",
    "    r_levels = dict.fromkeys(levels)\n",
    "    f1_levels = dict.fromkeys(levels)\n",
    "    for l in levels:\n",
    "        acc_levels[l] = accuracy_score(data[l + \"_x\"], data[l + \"_y\"])\n",
    "        p_levels[l], r_levels[l], f1_levels[l], _ = precision_recall_fscore_support(data[l + \"_x\"], data[l + \"_y\"], average=\"macro\")\n",
    "    macro_f1 = np.mean(list(f1_levels.values()))\n",
    "\n",
    "    # Compute Exact Match Ratio\n",
    "    check_emr = np.ones(len(data), dtype=bool)\n",
    "    for l in levels:\n",
    "        check_label = data[l + \"_x\"] == data[l + \"_y\"]\n",
    "        check_emr = check_emr & check_label\n",
    "    emr = sum(check_emr) / len(data)\n",
    "\n",
    "    return macro_f1, emr, acc_levels, p_levels, r_levels, f1_levels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 0\n",
    "\n",
    "df = pd.DataFrame(train.entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HS=0 implies TR=0 and AG=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = train.entries\n",
    "assert [e for e in es if e['HS'] == '0' and e['TR'] == '1'] == []\n",
    "assert [e for e in es if e['HS'] == '0' and e['AG'] == '1'] == []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'000': 2643, '111': 1053, '101': 449, '100': 279, '110': 76})\n",
      "Counter({'000': 278, '111': 127, '101': 49, '100': 36, '110': 10})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(Counter([e['HS']+e['TR']+e['AG'] for e in train.entries]))\n",
    "print(Counter([e['HS']+e['TR']+e['AG'] for e in dev.entries]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Approach\n",
    "\n",
    "Joint multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = [e['HS']+e['TR']+e['AG'] for e in train.entries]\n",
    "y_dev = [e['HS']+e['TR']+e['AG'] for e in dev.entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:736: FutureWarning: Possible nested set at position 8\n",
      "  re.IGNORECASE | re.VERBOSE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:2025: FutureWarning: Possible nested set at position 152\n",
      "  re.VERBOSE | re.IGNORECASE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:2048: FutureWarning: Possible nested set at position 409\n",
      "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:2060: FutureWarning: Possible nested set at position 192\n",
      "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.75\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         000       0.82      0.85      0.83       278\n",
      "         100       0.39      0.19      0.26        36\n",
      "         101       0.51      0.57      0.54        49\n",
      "         110       0.00      0.00      0.00        10\n",
      "         111       0.76      0.83      0.79       127\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       500\n",
      "   macro avg       0.49      0.49      0.48       500\n",
      "weighted avg       0.73      0.75      0.74       500\n",
      "\n",
      "[[235   7  12   0  24]\n",
      " [ 15   7  14   0   0]\n",
      " [ 13   4  28   0   4]\n",
      " [  4   0   0   0   6]\n",
      " [ 20   0   1   0 106]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from hate.classifier import HateClassifier\n",
    "filename = '/users/jsanchez/francolq/hatEval/tass2018/SENTIMENT_UBAv2_50_2.bin'\n",
    "clf = HateClassifier(\n",
    "    lang='es',\n",
    "    bow=True,\n",
    "    bow_params={\n",
    "        'binary': True,\n",
    "        'ngram_range': (1, 2),\n",
    "    },\n",
    "    boc=True,\n",
    "    boc_params={\n",
    "        'analyzer': 'char',\n",
    "        'binary': True,\n",
    "        'ngram_range': (1, 5),\n",
    "    },\n",
    "    #emb='fasttext',\n",
    "    emb='wfasttext',\n",
    "    emb_params={\n",
    "        'file': filename,\n",
    "    },\n",
    "    clf='maxent'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "clf.eval(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8250497668428715,\n",
       " 0.752,\n",
       " {'HS': 0.81, 'TargetRange': 0.894, 'Aggressiveness': 0.814},\n",
       " {'HS': 0.8084686983690763,\n",
       "  'TargetRange': 0.8652777777777778,\n",
       "  'Aggressiveness': 0.7957545187053383},\n",
       " {'HS': 0.8055447533864799,\n",
       "  'TargetRange': 0.8701916309746436,\n",
       "  'Aggressiveness': 0.8084666105499438},\n",
       " {'HS': 0.8067338012409724,\n",
       "  'TargetRange': 0.8676792945558768,\n",
       "  'Aggressiveness': 0.8007362047317653})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(X_dev)\n",
    "evaluate_b(dev, y_pred)\n",
    "# macro_f1, emr, acc_levels, p_levels, r_levels, f1_levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'110' label is doing really bad, check it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ea pues ya solo falta que Albert Rivera vaya a Algeciras a abrazarte con los inmigrantes subsaharianos</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Pobre JP no se merecia ser traicionado de esa forma tan ruin y sucia, esa zorra que iba de enamorada pero luego lo vota traicio... ‚Äî Pero si Ashley no iba de enamorada, JP era un perrito faldero de Chrissy as√≠ que nose donde ves q... https://t.co/WjlNyOf1HE</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>@ferdiazgil @ilseCeroUno01 @Compotita Exacto. Guarra y ego√≠sta, que el que venga detr√°s se busque la vida.</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>@Namurii @medicaster_xz @Yorha2d @KeloKlau_ Se merec√≠a de puta y no quiere que le metan la verga, jajaja no mamen</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Mi novia es como mi polla. S√© que est√° ah√≠ porque de vez en cuando se levanta. Una de mis pantalones y la otra de la cama.</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>- El otro d√≠a me com√≠ a Laura es muy f√°cil que guarra jajajaja - Laura tambi√©n te comi√≥ a ti entonces t√∫ eres igual de guarro e igual de f√°cil. - Puto feminazi putas modas eres feminista solo para ligar bien queda gilipollas - em, ok</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>@CaccoL T√∫ eres m√°s puta jijijiji</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Yo nunca le he dicho puta a una mujer pero socia t√∫ eres senda petardo üòÇüòÇ estas navidades no voy a comprar pirotecnias ya contigo vasta üòÇüòÇüòÇ</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>Somos animales: t√∫ eres una perra y yo la ladilla que no se quiere despegar de esa totona.</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>Hoy, 20hrs, haremos un twittazo en contra Rodolfo Noriega, quien, pese a ser un incitador al odio e inmigrante, sigue en Chile. El hashtag, ser√° #FueraRodolfoNoriega. https://t.co/1AvN3N7AvJ</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                  item  \\\n",
       "13   Ea pues ya solo falta que Albert Rivera vaya a Algeciras a abrazarte con los inmigrantes subsaharianos                                                                                                                                                              \n",
       "167  Pobre JP no se merecia ser traicionado de esa forma tan ruin y sucia, esa zorra que iba de enamorada pero luego lo vota traicio... ‚Äî Pero si Ashley no iba de enamorada, JP era un perrito faldero de Chrissy as√≠ que nose donde ves q... https://t.co/WjlNyOf1HE   \n",
       "168  @ferdiazgil @ilseCeroUno01 @Compotita Exacto. Guarra y ego√≠sta, que el que venga detr√°s se busque la vida.                                                                                                                                                          \n",
       "212  @Namurii @medicaster_xz @Yorha2d @KeloKlau_ Se merec√≠a de puta y no quiere que le metan la verga, jajaja no mamen                                                                                                                                                   \n",
       "229  Mi novia es como mi polla. S√© que est√° ah√≠ porque de vez en cuando se levanta. Una de mis pantalones y la otra de la cama.                                                                                                                                          \n",
       "376  - El otro d√≠a me com√≠ a Laura es muy f√°cil que guarra jajajaja - Laura tambi√©n te comi√≥ a ti entonces t√∫ eres igual de guarro e igual de f√°cil. - Puto feminazi putas modas eres feminista solo para ligar bien queda gilipollas - em, ok                           \n",
       "399  @CaccoL T√∫ eres m√°s puta jijijiji                                                                                                                                                                                                                                   \n",
       "449  Yo nunca le he dicho puta a una mujer pero socia t√∫ eres senda petardo üòÇüòÇ estas navidades no voy a comprar pirotecnias ya contigo vasta üòÇüòÇüòÇ                                                                                                                         \n",
       "453  Somos animales: t√∫ eres una perra y yo la ladilla que no se quiere despegar de esa totona.                                                                                                                                                                          \n",
       "494  Hoy, 20hrs, haremos un twittazo en contra Rodolfo Noriega, quien, pese a ser un incitador al odio e inmigrante, sigue en Chile. El hashtag, ser√° #FueraRodolfoNoriega. https://t.co/1AvN3N7AvJ                                                                      \n",
       "\n",
       "    label  \n",
       "13   110   \n",
       "167  110   \n",
       "168  110   \n",
       "212  110   \n",
       "229  110   \n",
       "376  110   \n",
       "399  110   \n",
       "449  110   \n",
       "453  110   \n",
       "494  110   "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'item':X_dev, 'label': y_dev})\n",
    "df[df['label'] == '110']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hate.settings import corpora\n",
    "test = corpora['test_es']\n",
    "X_test = list(test.X())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'000', '100', '101', '110', '111'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [e['id'] for e in test.entries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write submission\n",
    "f = open('es_b.tsv', 'w')\n",
    "for id, y in zip(ids, y_pred):\n",
    "    f.write('{}\\t{}\\t{}\\t{}\\n'.format(id, y[0], y[1], y[2]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('es_b.zip', 'w') as myzip:\n",
    "    myzip.write('es_b.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Approach\n",
    "\n",
    "Independent classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
