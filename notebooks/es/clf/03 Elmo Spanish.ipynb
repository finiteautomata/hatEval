{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMO in Spanish\n",
    "\n",
    "https://github.com/HIT-SCIR/ELMoForManyLangs\n",
    "\n",
    "http://vectors.nlpl.eu/repository/11/145.zip\n",
    "\n",
    "Edit config.json:\n",
    "\n",
    "\"config_path\": \"../configs/cnn_50_100_512_4096_sample.json\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "git clone https://github.com/HIT-SCIR/ELMoForManyLangs.git\n",
    "cd ELMoForManyLangs\n",
    "python setup install.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 04:58:56,797 INFO: char embedding size: 2637\n",
      "2019-01-20 04:58:58,399 INFO: word embedding size: 185214\n",
      "2019-01-20 04:59:11,306 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(185214, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2637, 50, padding_idx=2634)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from elmoformanylangs import Embedder\n",
    "e = Embedder('../../ELMoForManyLangs-es', batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hate.settings import corpora\n",
    "train = corpora['train_es']\n",
    "X_train = list(train.X())\n",
    "y_train = list(train.y())\n",
    "dev = corpora['dev_es']\n",
    "X_dev = list(dev.X())\n",
    "y_dev = list(dev.y())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOKENIZE\n",
    "# TODO: remove repeated tokens?\n",
    "from hate.elmo import ElmoTokenizer\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "tkn = ElmoTokenizer(reduce_len=True)\n",
    "X_train_tokens = [tkn(x) for x in X_train]\n",
    "X_dev_tokens = [tkn(x) for x in X_dev]\n",
    "# X_tokens = [tkn.tokenize(x) for x in X_dev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Me estoy comiendo la picada √°rabe m√°s rica de mi vida</td>\n",
       "      <td>[me, estoy, comiendo, la, picada, √°rabe, m√°s, rica, de, mi, vida]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@Haryachyzaychyk Callate zorra y mama duro! üòç</td>\n",
       "      <td>[@user, callate, zorra, y, mama, duro, !, üòç]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acabo de escuchar a Casado diciendo que hay DECENAS DE MILLONES de subsaharianos ahora mismo reuniendo dinero para venir a Europa. No s√© qu√© me asusta m√°s, que este idiota diga esas cosas o que haya tantos tarados deseando cre√©rselas.</td>\n",
       "      <td>[acabo, de, escuchar, a, casado, diciendo, que, hay, decenas, de, millones, de, subsaharianos, ahora, mismo, reuniendo, dinero, para, venir, a, europa, ., no, s√©, qu√©, me, asusta, m√°s, ,, que, este, idiota, diga, esas, cosas, o, que, haya, tantos, tarados, deseando, cre√©rselas, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Y NADIE SE HA PREGUNTADO LO QUE LE VA A COSTAR AL HOMBRE DEL GUANTAZO LA SITUACION..?!? PORQUE SEGURO ES, QUE EL MENDA MUSULMONO LE VA A PONER UNA DENUNCIA, QUE EL FALLO VA A SER \"\"CULPABLE\"\", QUE UNA PANDILLA DE MUSULMONOS LE VA A ESTAR ESPERANDO DELANTE DE LA PUERTA DE SU NEGOCIO https://t.co/DjfA63A0T2\"</td>\n",
       "      <td>[\", y, nadie, se, ha, preguntado, lo, que, le, va, a, costar, al, hombre, del, guantazo, la, situacion, .., ?, !, ?, porque, seguro, es, ,, que, el, menda, musulmono, le, va, a, poner, una, denuncia, ,, que, el, fallo, va, a, ser, \", \", culpable, \", \", ,, que, una, pandilla, de, musulmonos, le, va, a, estar, esperando, delante, de, la, puerta, de, su, negocio, url, \"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@Fed_Durand Callate come sobra, m√°s zorra son las tuyas</td>\n",
       "      <td>[@user, callate, come, sobra, ,, m√°s, zorra, son, las, tuyas]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>te quiero hacer mi reina √°rabe bomboncitocaramel</td>\n",
       "      <td>[te, quiero, hacer, mi, reina, √°rabe, bomboncitocaramel]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@andreaacata c√°llate perra JAJAJAJAJAJA</td>\n",
       "      <td>[@user, c√°llate, perra, jajajajajaja]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>\"En \"\"La Reina del Sur\"\" de @perezreverte , el personaje del \"\"G√ºero\"\" D√°vila tambien lleva un registro en cuaderno los detalles de todos los vuelos realizados transportando droga. Esto le cuesta finalmente su vida.  https://t.co/oy4zkrJYaJ\"</td>\n",
       "      <td>[\", en, \", \", la, reina, del, sur, \", \", de, @user, ,, el, personaje, del, \", \", g√ºero, \", \", d√°vila, tambien, lleva, un, registro, en, cuaderno, los, detalles, de, todos, los, vuelos, realizados, transportando, droga, ., esto, le, cuesta, finalmente, su, vida, ., url, \"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@AnderssonBoscan Vieja zorra imb√©cil y MENTIROSA, que nos cree unos solemnes cojudos. Se√±or Lenin, por favor dignifique al Ecuador, pobres, pero no en la cloaca robolucionaria!!</td>\n",
       "      <td>[@user, vieja, zorra, imb√©cil, y, mentirosa, ,, que, nos, cree, unos, solemnes, cojudos, ., se√±or, lenin, ,, por, favor, dignifique, al, ecuador, ,, pobres, ,, pero, no, en, la, cloaca, robolucionaria, !, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@rjimenez_perez tu eres un hijo de puta pervertido y pedofilo, una lacra que se debe exterminar, basura de mierda, no mereces vivir</td>\n",
       "      <td>[@user, tu, eres, un, hijo, de, puta, pervertido, y, pedofilo, ,, una, lacra, que, se, debe, exterminar, ,, basura, de, mierda, ,, no, mereces, vivir]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                      0  \\\n",
       "0  Me estoy comiendo la picada √°rabe m√°s rica de mi vida                                                                                                                                                                                                                                                                  \n",
       "1  @Haryachyzaychyk Callate zorra y mama duro! üòç                                                                                                                                                                                                                                                                          \n",
       "2  Acabo de escuchar a Casado diciendo que hay DECENAS DE MILLONES de subsaharianos ahora mismo reuniendo dinero para venir a Europa. No s√© qu√© me asusta m√°s, que este idiota diga esas cosas o que haya tantos tarados deseando cre√©rselas.                                                                             \n",
       "3  \"Y NADIE SE HA PREGUNTADO LO QUE LE VA A COSTAR AL HOMBRE DEL GUANTAZO LA SITUACION..?!? PORQUE SEGURO ES, QUE EL MENDA MUSULMONO LE VA A PONER UNA DENUNCIA, QUE EL FALLO VA A SER \"\"CULPABLE\"\", QUE UNA PANDILLA DE MUSULMONOS LE VA A ESTAR ESPERANDO DELANTE DE LA PUERTA DE SU NEGOCIO https://t.co/DjfA63A0T2\"   \n",
       "4  @Fed_Durand Callate come sobra, m√°s zorra son las tuyas                                                                                                                                                                                                                                                                \n",
       "5  te quiero hacer mi reina √°rabe bomboncitocaramel                                                                                                                                                                                                                                                                       \n",
       "6  @andreaacata c√°llate perra JAJAJAJAJAJA                                                                                                                                                                                                                                                                                \n",
       "7  \"En \"\"La Reina del Sur\"\" de @perezreverte , el personaje del \"\"G√ºero\"\" D√°vila tambien lleva un registro en cuaderno los detalles de todos los vuelos realizados transportando droga. Esto le cuesta finalmente su vida.  https://t.co/oy4zkrJYaJ\"                                                                      \n",
       "8  @AnderssonBoscan Vieja zorra imb√©cil y MENTIROSA, que nos cree unos solemnes cojudos. Se√±or Lenin, por favor dignifique al Ecuador, pobres, pero no en la cloaca robolucionaria!!                                                                                                                                      \n",
       "9  @rjimenez_perez tu eres un hijo de puta pervertido y pedofilo, una lacra que se debe exterminar, basura de mierda, no mereces vivir                                                                                                                                                                                    \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                    1  \n",
       "0  [me, estoy, comiendo, la, picada, √°rabe, m√°s, rica, de, mi, vida]                                                                                                                                                                                                                                                                                                                   \n",
       "1  [@user, callate, zorra, y, mama, duro, !, üòç]                                                                                                                                                                                                                                                                                                                                        \n",
       "2  [acabo, de, escuchar, a, casado, diciendo, que, hay, decenas, de, millones, de, subsaharianos, ahora, mismo, reuniendo, dinero, para, venir, a, europa, ., no, s√©, qu√©, me, asusta, m√°s, ,, que, este, idiota, diga, esas, cosas, o, que, haya, tantos, tarados, deseando, cre√©rselas, .]                                                                                           \n",
       "3  [\", y, nadie, se, ha, preguntado, lo, que, le, va, a, costar, al, hombre, del, guantazo, la, situacion, .., ?, !, ?, porque, seguro, es, ,, que, el, menda, musulmono, le, va, a, poner, una, denuncia, ,, que, el, fallo, va, a, ser, \", \", culpable, \", \", ,, que, una, pandilla, de, musulmonos, le, va, a, estar, esperando, delante, de, la, puerta, de, su, negocio, url, \"]  \n",
       "4  [@user, callate, come, sobra, ,, m√°s, zorra, son, las, tuyas]                                                                                                                                                                                                                                                                                                                       \n",
       "5  [te, quiero, hacer, mi, reina, √°rabe, bomboncitocaramel]                                                                                                                                                                                                                                                                                                                            \n",
       "6  [@user, c√°llate, perra, jajajajajaja]                                                                                                                                                                                                                                                                                                                                               \n",
       "7  [\", en, \", \", la, reina, del, sur, \", \", de, @user, ,, el, personaje, del, \", \", g√ºero, \", \", d√°vila, tambien, lleva, un, registro, en, cuaderno, los, detalles, de, todos, los, vuelos, realizados, transportando, droga, ., esto, le, cuesta, finalmente, su, vida, ., url, \"]                                                                                                    \n",
       "8  [@user, vieja, zorra, imb√©cil, y, mentirosa, ,, que, nos, cree, unos, solemnes, cojudos, ., se√±or, lenin, ,, por, favor, dignifique, al, ecuador, ,, pobres, ,, pero, no, en, la, cloaca, robolucionaria, !, !]                                                                                                                                                                     \n",
       "9  [@user, tu, eres, un, hijo, de, puta, pervertido, y, pedofilo, ,, una, lacra, que, se, debe, exterminar, ,, basura, de, mierda, ,, no, mereces, vivir]                                                                                                                                                                                                                              "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 0\n",
    "df = pd.DataFrame([(x, x2) for x, x2 in zip(X_dev, X_tokens)])\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 05:06:51,774 INFO: 16 batches, avg len: 26.3\n",
      "2019-01-20 05:06:54,985 INFO: 16 batches, avg len: 26.3\n",
      "2019-01-20 05:06:58,218 INFO: 16 batches, avg len: 26.3\n",
      "2019-01-20 05:07:01,436 INFO: 16 batches, avg len: 26.3\n",
      "2019-01-20 05:07:13,666 INFO: 141 batches, avg len: 25.9\n",
      "2019-01-20 05:07:17,865 INFO: Finished 1000 sentences.\n",
      "2019-01-20 05:07:21,900 INFO: Finished 2000 sentences.\n",
      "2019-01-20 05:07:25,822 INFO: Finished 3000 sentences.\n",
      "2019-01-20 05:07:29,794 INFO: Finished 4000 sentences.\n",
      "2019-01-20 05:07:41,691 INFO: 141 batches, avg len: 25.9\n",
      "2019-01-20 05:07:46,039 INFO: Finished 1000 sentences.\n",
      "2019-01-20 05:07:50,187 INFO: Finished 2000 sentences.\n",
      "2019-01-20 05:07:53,622 INFO: Finished 3000 sentences.\n",
      "2019-01-20 05:07:57,323 INFO: Finished 4000 sentences.\n",
      "2019-01-20 05:08:09,526 INFO: 141 batches, avg len: 25.9\n",
      "2019-01-20 05:08:13,922 INFO: Finished 1000 sentences.\n",
      "2019-01-20 05:08:18,041 INFO: Finished 2000 sentences.\n",
      "2019-01-20 05:08:21,994 INFO: Finished 3000 sentences.\n",
      "2019-01-20 05:08:25,507 INFO: Finished 4000 sentences.\n",
      "2019-01-20 05:08:37,343 INFO: 141 batches, avg len: 25.9\n",
      "2019-01-20 05:08:41,815 INFO: Finished 1000 sentences.\n",
      "2019-01-20 05:08:45,654 INFO: Finished 2000 sentences.\n",
      "2019-01-20 05:08:49,420 INFO: Finished 3000 sentences.\n",
      "2019-01-20 05:08:53,552 INFO: Finished 4000 sentences.\n"
     ]
    }
   ],
   "source": [
    "X_dev_vecs = {}\n",
    "for i in [0, 1, 2, -1]:\n",
    "    X_dev_vecs[i] = e.sents2elmo(X_dev_tokens, output_layer=i)\n",
    "X_train_vecs = {}\n",
    "for i in [0, 1, 2, -1]:\n",
    "    X_train_vecs[i] = e.sents2elmo(X_train_tokens, output_layer=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'train_es_elmo_{}'\n",
    "for i in [0, 1, 2, -1]:\n",
    "    with open(filename.format(i), 'wb') as f:\n",
    "        pickle.dump(X_train_vecs[i], f)\n",
    "\n",
    "filename = 'dev_es_elmo_{}'\n",
    "for i in [0, 1, 2, -1]:\n",
    "    with open(filename.format(i), 'wb') as f:\n",
    "        pickle.dump(X_dev_vecs[i], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hate.settings import corpora\n",
    "train = corpora['train_es']\n",
    "X_train = list(train.X())\n",
    "y_train = list(train.y())\n",
    "dev = corpora['dev_es']\n",
    "X_dev = list(dev.X())\n",
    "y_dev = list(dev.y())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:736: FutureWarning: Possible nested set at position 8\n",
      "  re.IGNORECASE | re.VERBOSE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:2025: FutureWarning: Possible nested set at position 152\n",
      "  re.VERBOSE | re.IGNORECASE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:2048: FutureWarning: Possible nested set at position 409\n",
      "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:2060: FutureWarning: Possible nested set at position 192\n",
      "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy\t0.85\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       278\n",
      "           1       0.82      0.84      0.83       222\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       500\n",
      "   macro avg       0.85      0.85      0.85       500\n",
      "weighted avg       0.85      0.85      0.85       500\n",
      "\n",
      "[[237  41]\n",
      " [ 35 187]]\n"
     ]
    }
   ],
   "source": [
    "from hate.classifier import HateClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "filename = '/users/jsanchez/francolq/hatEval/tass2018/SENTIMENT_UBAv2_50_2.bin'\n",
    "clf = HateClassifier(\n",
    "    lang='es',\n",
    "    bow=True,\n",
    "    bow_params={\n",
    "        'binary': True,\n",
    "        'ngram_range': (1, 2),\n",
    "    },\n",
    "    boc=True,\n",
    "    boc_params={\n",
    "        'analyzer': 'char',\n",
    "        'binary': True,\n",
    "        'ngram_range': (1, 5),\n",
    "    },\n",
    "    #emb='fasttext',\n",
    "    emb='wfasttext',\n",
    "    emb_params={\n",
    "        'file': filename,\n",
    "        # 'binarize': True,\n",
    "    },\n",
    "    clf='maxent'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "clf.eval(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:736: FutureWarning: Possible nested set at position 8\n",
      "  re.IGNORECASE | re.VERBOSE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:2025: FutureWarning: Possible nested set at position 152\n",
      "  re.VERBOSE | re.IGNORECASE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:2048: FutureWarning: Possible nested set at position 409\n",
      "  UrlMatch_re = re.compile(UrlMatch_expression, re.VERBOSE | re.IGNORECASE)\n",
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/treetaggerwrapper.py:2060: FutureWarning: Possible nested set at position 192\n",
      "  EmailMatch_re = re.compile(EmailMatch_expression, re.VERBOSE | re.IGNORECASE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elmo in mode train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elmo in mode test\n",
      "accuracy\t0.81\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83       278\n",
      "           1       0.78      0.82      0.80       222\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       500\n",
      "   macro avg       0.81      0.81      0.81       500\n",
      "weighted avg       0.82      0.81      0.81       500\n",
      "\n",
      "[[226  52]\n",
      " [ 41 181]]\n"
     ]
    }
   ],
   "source": [
    "from hate.classifier import HateClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "filename = '/users/jsanchez/francolq/hatEval/tass2018/SENTIMENT_UBAv2_50_2.bin'\n",
    "clf = HateClassifier(\n",
    "    lang='es',\n",
    "    bow=True,\n",
    "    bow_params={\n",
    "        'binary': True,\n",
    "        'ngram_range': (1, 2),\n",
    "    },\n",
    "    boc=True,\n",
    "    boc_params={\n",
    "        'analyzer': 'char',\n",
    "        'binary': True,\n",
    "        'ngram_range': (1, 5),\n",
    "    },\n",
    "    #emb='fasttext',\n",
    "    emb='elmo',\n",
    "    emb_params={\n",
    "        'train_file': 'train_es_elmo_2',\n",
    "        'test_file': 'dev_es_elmo_2',\n",
    "        'tokenizer': None,\n",
    "        'dim': 100,\n",
    "    },\n",
    "    clf='maxent'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "clf.eval(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elmo in mode train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/jsanchez/.virtualenvs/pln/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elmo in mode test\n",
      "accuracy\t0.84\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.86       278\n",
      "           1       0.81      0.85      0.83       222\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       500\n",
      "   macro avg       0.84      0.84      0.84       500\n",
      "weighted avg       0.84      0.84      0.84       500\n",
      "\n",
      "[[233  45]\n",
      " [ 34 188]]\n"
     ]
    }
   ],
   "source": [
    "from hate.classifier import HateClassifier\n",
    "\n",
    "# Logistic Regression\n",
    "filename = '/users/jsanchez/francolq/hatEval/tass2018/SENTIMENT_UBAv2_50_2.bin'\n",
    "clf = HateClassifier(\n",
    "    lang='es',\n",
    "    bow=True,\n",
    "    bow_params={\n",
    "        'binary': True,\n",
    "        'ngram_range': (1, 2),\n",
    "    },\n",
    "    boc=True,\n",
    "    boc_params={\n",
    "        'analyzer': 'char',\n",
    "        'binary': True,\n",
    "        'ngram_range': (1, 5),\n",
    "    },\n",
    "    emb=['wfasttext', 'elmo'],\n",
    "    emb_params=\n",
    "    [{\n",
    "        'file': filename,\n",
    "        # 'binarize': True,\n",
    "    },\n",
    "    {\n",
    "        'train_file': 'train_es_elmo_-1',\n",
    "        'test_file': 'dev_es_elmo_-1',\n",
    "        'tokenizer': None,\n",
    "        'dim': 100,\n",
    "    }],\n",
    "    clf='maxent'\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "clf.eval(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = clf.vect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bow_vect',\n",
       "  TfidfVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
       "          dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 2), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=<hate.tokenizer.Tokenizer object at 0x7fd7ae529470>,\n",
       "          use_idf=True, vocabulary=None)),\n",
       " ('boc_vect',\n",
       "  TfidfVectorizer(analyzer='char', binary=True, decode_error='strict',\n",
       "          dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 5), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "          stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "          token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "          vocabulary=None)),\n",
       " ('wfasttext_vect',\n",
       "  WeightedSentenceVectorizer(a=None, binarize=None, file=None, normalize=None,\n",
       "                tokenizer=None)),\n",
       " ('elmo_vect',\n",
       "  CachedElmoVectorizer(test_file=None, tokenizer=None, train_file=None))]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.transformer_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
