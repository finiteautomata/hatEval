{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles\n",
    "\n",
    "En esta notebook vamos a cargar el modelo que mejor anduvo en la CV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancias de entrenamiento: 9000\n",
      "Instancias de desarrollo: 1000\n",
      "Instancias de test: 2971\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import torch\n",
    "\n",
    "random_seed = 10101119\n",
    "\n",
    "torch.manual_seed(2*random_seed)\n",
    "np.random.seed(3*random_seed)\n",
    "tf.random.set_random_seed(random_seed+1)\n",
    "random.seed(random_seed/2 + 1)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "df_dev = pd.read_table(\"../../../data/en/dev_en.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "df_train = pd.read_table(\"../../../data/en/train_en.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "df_test = pd.read_table(\"../../../data/en/reference_en.tsv\", header=None, \n",
    "                        names=[\"text\", \"HS\", \"TR\", \"AG\"], quoting=csv.QUOTE_NONE)\n",
    "\n",
    "\n",
    "X_train, y_train = df_train[\"text\"], df_train[\"HS\"]\n",
    "X_dev, y_dev = df_dev[\"text\"], df_dev[\"HS\"]\n",
    "X_test, y_test = df_test[\"text\"], df_test[\"HS\"]\n",
    "\n",
    "print(\"Instancias de entrenamiento: {}\".format(len(df_train)))\n",
    "print(\"Instancias de desarrollo: {}\".format(len(df_dev)))\n",
    "print(\"Instancias de test: {}\".format(len(df_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hate.nn.preprocessing import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokens_train = [tokenizer.tokenize(t) for t in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos tokenize sobre el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 366., 1747., 1987., 2059., 1170.,  584.,  601.,  373.,   95.,\n",
       "          18.]),\n",
       " array([ 0.,  7., 14., 21., 28., 35., 42., 49., 56., 63., 70.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(t) for t in tokens_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 10:19:00,409 INFO: char embedding size: 4939\n",
      "2019-02-21 10:19:01,187 INFO: word embedding size: 167642\n",
      "2019-02-21 10:19:10,438 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(167642, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(4939, 50, padding_idx=4936)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from elmoformanylangs import Embedder\n",
    "\n",
    "e = Embedder(\"../../../models/elmo/en/\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from hate.nn import CharModel, ElmoModel, BowModel, MergeModel\n",
    "\n",
    "def create_model(params, embedder):\n",
    "    params = params.copy()\n",
    "\n",
    "    dropout = params.pop('dropout')\n",
    "    recursive_class = params.pop('recursive_class')\n",
    "    dense_last_layer = params.pop('dense_last_layer')\n",
    "    char_model = CharModel(\n",
    "        vocab_size=params.pop('char__vocab_size'),\n",
    "        max_charlen=params.pop('char__max_charlen'),\n",
    "        embedding_dim=params.pop('char__embedding_dim'),\n",
    "        tokenize_args={\n",
    "            \"stem\": params.pop('char__stem'),\n",
    "            \"alpha_only\": params.pop('char__alpha_only'),\n",
    "        },\n",
    "        filters=params.pop('char__filters'),\n",
    "        recursive_units=params.pop('char__lstm_units'),\n",
    "        kernel_size=params.pop('char__kernel_size'),\n",
    "        pooling_size=params.pop('char__pooling_size'),\n",
    "        dense_units=dense_last_layer,\n",
    "        recursive_class=recursive_class, dropout=dropout\n",
    "    )\n",
    "    elmo_model = ElmoModel(\n",
    "        max_len=55, embedder=embedder,\n",
    "        lstm_units=params.pop('elmo__lstm_units'),\n",
    "        tokenize_args={'deaccent': params.pop('elmo__deaccent')},\n",
    "        dense_units=dense_last_layer,\n",
    "        recursive_class=recursive_class, dropout=dropout\n",
    "    )\n",
    "    bow_model = BowModel(\n",
    "        num_words=params.pop('bow__num_words'),\n",
    "        dense_units=[512, dense_last_layer], dropout=dropout,\n",
    "        tokenize_args = {\"alpha_only\": True, \"language\": \"english\"}\n",
    "    )\n",
    "    merge_model = MergeModel([char_model, elmo_model, bow_model])\n",
    "    optimizer_args = {\n",
    "        \"lr\": params.pop('lr'),\n",
    "        \"decay\": params.pop('decay')\n",
    "    }\n",
    "    merge_model.compile(loss='binary_crossentropy',\n",
    "              optimizer=Adam(**optimizer_args),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    print(params)\n",
    "    assert(len(params) == 0)\n",
    "\n",
    "    return merge_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos los hiperpar치metros 칩ptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"../../../models/model_selection.pkl\", \"rb\") as f:\n",
    "    model_selection = pickle.load(f)\n",
    "    \n",
    "df = pd.DataFrame(model_selection)\n",
    "df = df.sort_values(\"val_acc\", ascending=False)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recursive_class': keras.layers.cudnn_recurrent.CuDNNLSTM,\n",
       " 'lr': 0.002,\n",
       " 'elmo__lstm_units': 128,\n",
       " 'elmo__deaccent': False,\n",
       " 'dropout': [0.8, 0.55],\n",
       " 'dense_last_layer': 64,\n",
       " 'decay': 0.01,\n",
       " 'char__vocab_size': 150,\n",
       " 'char__stem': False,\n",
       " 'char__pooling_size': 4,\n",
       " 'char__max_charlen': 200,\n",
       " 'char__kernel_size': 5,\n",
       " 'char__filters': 128,\n",
       " 'char__embedding_dim': 64,\n",
       " 'char__alpha_only': False,\n",
       " 'bow__num_words': 2000,\n",
       " 'char__lstm_units': 128}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = df.iloc[0][\"params\"]\n",
    "\n",
    "params[\"lr\"] = 0.002\n",
    "params[\"dropout\"] = [0.80, 0.55]\n",
    "params[\"char__embedding_dim\"] = 64\n",
    "params[\"char__lstm_units\"] = 128\n",
    "params[\"dense_last_layer\"] = 64\n",
    "params[\"char__vocab_size\"] = 150\n",
    "params[\"char__filters\"] = 128\n",
    "params[\"char__kernel_size\"] = 5\n",
    "params[\"bow__num_words\"] = 2000\n",
    "params[\"elmo__lstm_units\"] = 128\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Char_Input (InputLayer)         (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 200, 64)      9600        Char_Input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 200, 128)     41088       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 50, 128)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Elmo_Input (InputLayer)         (None, 55, 1024)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "BoW_Input (InputLayer)          (None, 2000)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 256)          264192      max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 256)          1181696     Elmo_Input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 512)          1024512     BoW_Input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           16448       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_elmo (Dense)              (None, 64)           16448       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           32832       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64)           0           dense_elmo[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 192)          0           dropout_2[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            193         concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,587,009\n",
      "Trainable params: 2,587,009\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "model = create_model(params, e)\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 10:19:45,503 INFO: 282 batches, avg len: 57.0\n",
      "2019-02-21 10:19:50,976 INFO: Finished 1000 sentences.\n",
      "2019-02-21 10:19:55,879 INFO: Finished 2000 sentences.\n",
      "2019-02-21 10:20:00,811 INFO: Finished 3000 sentences.\n",
      "2019-02-21 10:20:05,730 INFO: Finished 4000 sentences.\n",
      "2019-02-21 10:20:10,824 INFO: Finished 5000 sentences.\n",
      "2019-02-21 10:20:15,759 INFO: Finished 6000 sentences.\n",
      "2019-02-21 10:20:20,843 INFO: Finished 7000 sentences.\n",
      "2019-02-21 10:20:25,790 INFO: Finished 8000 sentences.\n",
      "2019-02-21 10:20:30,749 INFO: Finished 9000 sentences.\n",
      "2019-02-21 10:20:37,686 INFO: 32 batches, avg len: 57.0\n",
      "2019-02-21 10:20:42,468 INFO: Finished 1000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 10:20:43,832 WARNING: Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/300\n",
      "9000/9000 [==============================] - 11s 1ms/step - loss: 0.6123 - acc: 0.6594 - val_loss: 0.5513 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.71800, saving model to /tmp/en_ensemble_17.h5\n",
      "Epoch 2/300\n",
      "9000/9000 [==============================] - 9s 948us/step - loss: 0.4777 - acc: 0.7807 - val_loss: 0.5384 - val_acc: 0.7310\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.71800 to 0.73100, saving model to /tmp/en_ensemble_17.h5\n",
      "Epoch 3/300\n",
      "9000/9000 [==============================] - 9s 950us/step - loss: 0.4342 - acc: 0.8020 - val_loss: 0.5400 - val_acc: 0.7370\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.73100 to 0.73700, saving model to /tmp/en_ensemble_17.h5\n",
      "Epoch 4/300\n",
      "9000/9000 [==============================] - 9s 946us/step - loss: 0.3955 - acc: 0.8264 - val_loss: 0.5361 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.73700 to 0.73900, saving model to /tmp/en_ensemble_17.h5\n",
      "Epoch 5/300\n",
      "9000/9000 [==============================] - 9s 958us/step - loss: 0.3779 - acc: 0.8354 - val_loss: 0.5436 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.73900\n",
      "Epoch 6/300\n",
      "9000/9000 [==============================] - 9s 961us/step - loss: 0.3666 - acc: 0.8432 - val_loss: 0.5412 - val_acc: 0.7400\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.73900 to 0.74000, saving model to /tmp/en_ensemble_17.h5\n",
      "Epoch 7/300\n",
      "9000/9000 [==============================] - 9s 955us/step - loss: 0.3454 - acc: 0.8522 - val_loss: 0.5458 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.74000 to 0.74900, saving model to /tmp/en_ensemble_17.h5\n",
      "Epoch 8/300\n",
      "9000/9000 [==============================] - 9s 961us/step - loss: 0.3321 - acc: 0.8568 - val_loss: 0.5492 - val_acc: 0.7480\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.74900\n",
      "Epoch 9/300\n",
      "9000/9000 [==============================] - 9s 958us/step - loss: 0.3262 - acc: 0.8631 - val_loss: 0.5509 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.74900 to 0.75000, saving model to /tmp/en_ensemble_17.h5\n",
      "Epoch 10/300\n",
      "9000/9000 [==============================] - 9s 961us/step - loss: 0.3146 - acc: 0.8711 - val_loss: 0.5564 - val_acc: 0.7480\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.75000\n",
      "Epoch 11/300\n",
      "9000/9000 [==============================] - 9s 956us/step - loss: 0.3057 - acc: 0.8708 - val_loss: 0.5668 - val_acc: 0.7420\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.75000\n",
      "Epoch 12/300\n",
      "9000/9000 [==============================] - 9s 945us/step - loss: 0.2904 - acc: 0.8760 - val_loss: 0.5731 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.75000\n",
      "Epoch 13/300\n",
      "9000/9000 [==============================] - 9s 956us/step - loss: 0.2888 - acc: 0.8811 - val_loss: 0.5687 - val_acc: 0.7500\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.75000\n",
      "Epoch 14/300\n",
      "9000/9000 [==============================] - 9s 963us/step - loss: 0.2809 - acc: 0.8832 - val_loss: 0.5705 - val_acc: 0.7510\n",
      "\n",
      "Epoch 00014: val_acc improved from 0.75000 to 0.75100, saving model to /tmp/en_ensemble_17.h5\n",
      "Epoch 15/300\n",
      "9000/9000 [==============================] - 8s 943us/step - loss: 0.2789 - acc: 0.8864 - val_loss: 0.5760 - val_acc: 0.7480\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.75100\n",
      "Epoch 16/300\n",
      "9000/9000 [==============================] - 9s 952us/step - loss: 0.2669 - acc: 0.8889 - val_loss: 0.5812 - val_acc: 0.7420\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.75100\n",
      "Epoch 17/300\n",
      "9000/9000 [==============================] - 9s 948us/step - loss: 0.2633 - acc: 0.8937 - val_loss: 0.5849 - val_acc: 0.7450\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.75100\n",
      "Epoch 18/300\n",
      "9000/9000 [==============================] - 9s 951us/step - loss: 0.2606 - acc: 0.8943 - val_loss: 0.5880 - val_acc: 0.7460\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.75100\n",
      "Epoch 19/300\n",
      "9000/9000 [==============================] - 9s 966us/step - loss: 0.2504 - acc: 0.8973 - val_loss: 0.5947 - val_acc: 0.7440\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.75100\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint('/tmp/en_ensemble_17.h5', save_best_only=True, monitor='val_acc', verbose=1)\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=15)\n",
    "history = model.fit(X_train, y_train, callbacks=[checkpointer, early_stopper],\n",
    "          validation_data=(X_dev, y_dev), epochs=300, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 10:35:51,661 INFO: 32 batches, avg len: 57.0\n",
      "2019-02-21 10:35:56,394 INFO: Finished 1000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 402us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 10:36:00,042 INFO: 32 batches, avg len: 57.0\n",
      "2019-02-21 10:36:04,768 INFO: Finished 1000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss           : 0.5708\n",
      "Accuracy       : 0.7480\n",
      "Precision(1)   : 0.6966\n",
      "Precision(1)   : 0.7892\n",
      "Precision(avg) : 0.7429\n",
      "\n",
      "Recall(1)      : 0.7260\n",
      "Recall(0)      : 0.7644\n",
      "Recall(avg)    : 0.7452\n",
      "\n",
      "F1(1)          : 0.7110\n",
      "F1(0)          : 0.7766\n",
      "F1(avg)        : 0.7438\n",
      "\n",
      "\n",
      "Evaluaci칩n sobre test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 10:36:13,354 INFO: 93 batches, avg len: 57.0\n",
      "2019-02-21 10:36:18,133 INFO: Finished 1000 sentences.\n",
      "2019-02-21 10:36:22,769 INFO: Finished 2000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2971/2971 [==============================] - 1s 427us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 10:36:37,547 INFO: 93 batches, avg len: 57.0\n",
      "2019-02-21 10:36:42,335 INFO: Finished 1000 sentences.\n",
      "2019-02-21 10:36:47,005 INFO: Finished 2000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss           : 1.7859\n",
      "Accuracy       : 0.5059\n",
      "Precision(1)   : 0.4578\n",
      "Precision(1)   : 0.8039\n",
      "Precision(avg) : 0.6308\n",
      "\n",
      "Recall(1)      : 0.9353\n",
      "Recall(0)      : 0.1931\n",
      "Recall(avg)    : 0.5642\n",
      "\n",
      "F1(1)          : 0.6147\n",
      "F1(0)          : 0.3114\n",
      "F1(avg)        : 0.4631\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "model.load_weights(checkpointer.filepath)\n",
    "model.preprocess_fit(X_train)\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)\n",
    "\n",
    "print(\"\\n\\nEvaluaci칩n sobre test\")\n",
    "print_evaluation(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 19:50:26,265 INFO: 94 batches, avg len: 57.0\n",
      "2019-01-20 19:50:31,359 INFO: Finished 1000 sentences.\n",
      "2019-01-20 19:50:36,542 INFO: Finished 2000 sentences.\n",
      "2019-01-20 19:50:41,721 INFO: Finished 3000 sentences.\n",
      "2019-01-20 19:50:47,136 INFO: 32 batches, avg len: 57.0\n",
      "2019-01-20 19:50:52,196 INFO: Finished 1000 sentences.\n"
     ]
    }
   ],
   "source": [
    "df_test[\"preds\"] = (model.predict(df_test[\"text\"]) >= 0.5).astype(int)\n",
    "df_dev[\"preds\"] = (model.predict(df_dev[\"text\"]) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'en_a.tsv': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm en_a.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('en_a.tsv', 'w') as f:\n",
    "    for i, row in df_test.iterrows():\n",
    "        f.write('{}\\t{}\\n'.format(i, row[\"preds\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp en_a.tsv ../../../submissions/17_en_ensemble.tsv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"en_a.tsv.zip\", 'w') as f:\n",
    "    f.write('en_a.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
