{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElMO\n",
    "\n",
    "Probemos Elmo sólo en inglés a ver qué da..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instancias de entrenamiento: 9000\n",
      "Instancias de desarrollo: 1000\n",
      "Instancias de test: 2971\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import torch\n",
    "\n",
    "random_seed = 10101119\n",
    "\n",
    "torch.manual_seed(2*random_seed)\n",
    "np.random.seed(3*random_seed)\n",
    "tf.random.set_random_seed(random_seed+1)\n",
    "random.seed(random_seed/2 + 1)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "df_dev = pd.read_table(\"../../../data/en/dev_en.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "df_train = pd.read_table(\"../../../data/en/train_en.tsv\", index_col=\"id\", quoting=csv.QUOTE_NONE)\n",
    "df_test = pd.read_table(\"../../../data/en/reference_en.tsv\", header=None, \n",
    "                        names=[\"text\", \"HS\", \"TR\", \"AG\"], quoting=csv.QUOTE_NONE)\n",
    "\n",
    "\n",
    "X_train, y_train = df_train[\"text\"], df_train[\"HS\"]\n",
    "X_dev, y_dev = df_dev[\"text\"], df_dev[\"HS\"]\n",
    "X_test, y_test = df_test[\"text\"], df_test[\"HS\"]\n",
    "\n",
    "print(\"Instancias de entrenamiento: {}\".format(len(df_train)))\n",
    "print(\"Instancias de desarrollo: {}\".format(len(df_dev)))\n",
    "print(\"Instancias de test: {}\".format(len(df_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hate.nn.preprocessing import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokens_train = [tokenizer.tokenize(t) for t in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos tokenize sobre el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 366., 1747., 1987., 2059., 1170.,  584.,  601.,  373.,   95.,\n",
       "          18.]),\n",
       " array([ 0.,  7., 14., 21., 28., 35., 42., 49., 56., 63., 70.]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAD8CAYAAACRkhiPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFBRJREFUeJzt3X+MXfV55/H3Z0nCtqQtpkyR6x87JHVSQdQ4MCJU+SFatmCgCqSqUlAV3CyqExWkIEWqTCst2VRIdLdJtmi7VE7xAlIWQkMIVqAlDptt1NXyYyAuGAjFECNsGduFNHRLhWp49o/7nXAzjO3x3Ou5dzjvl3Q15zzn3HOeGV3r4/M959yTqkKS1E3/ZtQNSJJGxxCQpA4zBCSpwwwBSeowQ0CSOswQkKQOMwQkqcMMAUnqMENAkjrsLaNu4HBOPPHEmpycHHUbkrRkPPTQQ/9QVRPzWXfsQ2BycpLp6elRtyFJS0aSZ+e7rsNBktRhhoAkdZghIEkdZghIUocZApLUYYaAJHWYISBJHWYISFKHGQKS1GFjf8ewlobJjXeNbN87r71gZPuWljqPBCSpww4bAklWJfl2kseTPJbk061+QpKtSZ5qP5e1epJcl2RHkkeSnNa3rfVt/aeSrD96v5YkaT7mcyRwAPhMVZ0CnAlcnuQUYCNwb1WtAe5t8wDnAWvaawNwPfRCA7gaeD9wBnD1THBIkkbjsCFQVXuq6uE2/U/AE8AK4ELgprbaTcBFbfpC4ObquQ84Psly4Fxga1W9WFU/ALYC64b620iSjsgRnRNIMgm8D7gfOKmq9rRFzwMntekVwHN9b9vVagerS5JGZN4hkOTtwO3AlVX1Uv+yqiqghtVUkg1JppNM79+/f1iblSTNMq9LRJO8lV4AfLmqvtbKe5Msr6o9bbhnX6vvBlb1vX1lq+0GzppV/99z7a+qNgGbAKampoYWLl0wyks1JS0987k6KMANwBNV9YW+RVuAmSt81gN39tUvbVcJnQn8sA0b3QOck2RZOyF8TqtJkkZkPkcCHwA+DjyaZFur/QFwLXBbksuAZ4GPtWV3A+cDO4CXgU8AVNWLSf4IeLCt97mqenEov4UkaUEOGwJV9bdADrL47DnWL+Dyg2xrM7D5SBqUJB093jEsSR1mCEhShxkCktRhhoAkdZghIEkdZghIUocZApLUYYaAJHWYISBJHWYISFKHGQKS1GGGgCR1mCEgSR1mCEhShxkCktRhhoAkddh8Hi+5Ocm+JNv7al9Jsq29ds48cSzJZJJ/6Vv2533vOT3Jo0l2JLmuPbZSkjRC83m85I3AfwNunilU1W/NTCf5PPDDvvWfrqq1c2zneuB3gfvpPYJyHfBXR96yJGlYDnskUFXfAeZ8FnD73/zHgFsOtY0ky4Gfrqr72uMnbwYuOvJ2JUnDNOg5gQ8Be6vqqb7ayUm+m+Rvknyo1VYAu/rW2dVqkqQRms9w0KFcwo8fBewBVlfVC0lOB76e5NQj3WiSDcAGgNWrVw/Y4uKb3HjXqFuQpHlZ8JFAkrcAvwF8ZaZWVa9U1Qtt+iHgaeBdwG5gZd/bV7banKpqU1VNVdXUxMTEQluUJB3GIMNB/x74XlX9aJgnyUSSY9r0O4A1wDNVtQd4KcmZ7TzCpcCdA+xbkjQE87lE9Bbg/wLvTrIryWVt0cW88YTwh4FH2iWjXwU+VVUzJ5V/D/gLYAe9IwSvDJKkETvsOYGquuQg9d+Zo3Y7cPtB1p8G3nOE/UmSjiLvGJakDjMEJKnDDAFJ6jBDQJI6zBCQpA4zBCSpwwwBSeowQ0CSOswQkKQOMwQkqcMMAUnqMENAkjrMEJCkDjMEJKnDDAFJ6jBDQJI6bD5PFtucZF+S7X21zybZnWRbe53ft+yqJDuSPJnk3L76ulbbkWTj8H8VSdKRms+RwI3AujnqX6yqte11N0CSU+g9dvLU9p7/nuSY9tzhPwPOA04BLmnrSpJGaD6Pl/xOksl5bu9C4NaqegX4fpIdwBlt2Y6qegYgya1t3cePuGNJ0tAMck7giiSPtOGiZa22Aniub51drXawuiRphBYaAtcD7wTWAnuAzw+tIyDJhiTTSab3798/zE1LkvosKASqam9VvVpVrwFf4vUhn93Aqr5VV7baweoH2/6mqpqqqqmJiYmFtChJmocFhUCS5X2zHwVmrhzaAlyc5NgkJwNrgAeAB4E1SU5O8jZ6J4+3LLxtSdIwHPbEcJJbgLOAE5PsAq4GzkqyFihgJ/BJgKp6LMlt9E74HgAur6pX23auAO4BjgE2V9VjQ/9tJElHZD5XB10yR/mGQ6x/DXDNHPW7gbuPqDtJ0lHlHcOS1GGGgCR1mCEgSR1mCEhShxkCktRhhoAkdZghIEkdZghIUocZApLUYYaAJHWYISBJHWYISFKHGQKS1GGGgCR1mCEgSR1mCEhShx02BJJsTrIvyfa+2n9J8r0kjyS5I8nxrT6Z5F+SbGuvP+97z+lJHk2yI8l1SXJ0fiVJ0nzN50jgRmDdrNpW4D1V9UvA3wNX9S17uqrWtten+urXA79L77nDa+bYpiRpkR02BKrqO8CLs2rfrKoDbfY+YOWhttEeTP/TVXVfVRVwM3DRwlqWJA3LMM4J/Afgr/rmT07y3SR/k+RDrbYC2NW3zq5WkySN0GEfNH8oSf4QOAB8uZX2AKur6oUkpwNfT3LqAra7AdgAsHr16kFalCQdwoKPBJL8DvDrwG+3IR6q6pWqeqFNPwQ8DbwL2M2PDxmtbLU5VdWmqpqqqqmJiYmFtihJOowFhUCSdcDvAx+pqpf76hNJjmnT76B3AviZqtoDvJTkzHZV0KXAnQN3L0kayGGHg5LcApwFnJhkF3A1vauBjgW2tis972tXAn0Y+FySfwVeAz5VVTMnlX+P3pVGP0HvHEL/eQRJ0ggcNgSq6pI5yjccZN3bgdsPsmwaeM8RdSdJOqq8Y1iSOswQkKQOMwQkqcMGuk9AGgeTG+8ayX53XnvBSPYrDZNHApLUYYaAJHWYISBJHWYISFKHGQKS1GGGgCR1mCEgSR1mCEhShxkCktRhhoAkdZghIEkdZghIUocZApLUYfMKgSSbk+xLsr2vdkKSrUmeaj+XtXqSXJdkR5JHkpzW9571bf2nkqwf/q8jSToS8z0SuBFYN6u2Ebi3qtYA97Z5gPPoPWB+DbABuB56oUHv+cTvB84Arp4JDknSaMwrBKrqO8CLs8oXAje16ZuAi/rqN1fPfcDxSZYD5wJbq+rFqvoBsJU3BoskaRENck7gpKra06afB05q0yuA5/rW29VqB6u/QZINSaaTTO/fv3+AFiVJhzKUE8NVVUANY1tte5uqaqqqpiYmJoa1WUnSLIOEwN42zEP7ua/VdwOr+tZb2WoHq0uSRmSQENgCzFzhsx64s69+abtK6Ezgh23Y6B7gnCTL2gnhc1pNkjQi83rQfJJbgLOAE5PsoneVz7XAbUkuA54FPtZWvxs4H9gBvAx8AqCqXkzyR8CDbb3PVdXsk82SpEU0rxCoqksOsujsOdYt4PKDbGczsHne3UmSjirvGJakDjMEJKnDDAFJ6jBDQJI6zBCQpA4zBCSpwwwBSeowQ0CSOswQkKQOMwQkqcMMAUnqMENAkjrMEJCkDjMEJKnDDAFJ6jBDQJI6bMEhkOTdSbb1vV5KcmWSzybZ3Vc/v+89VyXZkeTJJOcO51eQJC3UvJ4sNpeqehJYC5DkGHoPjb+D3uMkv1hVf9K/fpJTgIuBU4GfB76V5F1V9epCe5AkDWZYw0FnA09X1bOHWOdC4NaqeqWqvk/vGcRnDGn/kqQFGFYIXAzc0jd/RZJHkmxOsqzVVgDP9a2zq9XeIMmGJNNJpvfv3z+kFiVJsw0cAkneBnwE+MtWuh54J72hoj3A5490m1W1qaqmqmpqYmJi0BYlSQcxjCOB84CHq2ovQFXtrapXq+o14Eu8PuSzG1jV976VrSZJGpFhhMAl9A0FJVnet+yjwPY2vQW4OMmxSU4G1gAPDGH/kqQFWvDVQQBJjgN+DfhkX/k/J1kLFLBzZllVPZbkNuBx4ABwuVcGSdJoDRQCVfXPwM/Oqn38EOtfA1wzyD4lScPjHcOS1GGGgCR1mCEgSR1mCEhShxkCktRhhoAkdZghIEkdZghIUocZApLUYQPdMSxp8U1uvGtk+9557QUj27eODo8EJKnDPBKQFmiU/yOXhsUjAUnqMENAkjrMEJCkDjMEJKnDhvGg+Z1JHk2yLcl0q52QZGuSp9rPZa2eJNcl2ZHkkSSnDbp/SdLCDetI4Feqam1VTbX5jcC9VbUGuLfNQ++h9GvaawNw/ZD2L0lagKM1HHQhcFObvgm4qK9+c/XcBxw/68H0kqRFNIwQKOCbSR5KsqHVTqqqPW36eeCkNr0CeK7vvbtaTZI0AsO4WeyDVbU7yc8BW5N8r39hVVWSOpINtjDZALB69eohtChJmsvARwJVtbv93AfcAZwB7J0Z5mk/97XVdwOr+t6+stVmb3NTVU1V1dTExMSgLUqSDmKgEEhyXJKfmpkGzgG2A1uA9W219cCdbXoLcGm7SuhM4Id9w0aSpEU26HDQScAdSWa29T+r6q+TPAjcluQy4FngY239u4HzgR3Ay8AnBty/JGkAA4VAVT0DvHeO+gvA2XPUC7h8kH1KkobHO4YlqcMMAUnqMENAkjrMEJCkDjMEJKnDDAFJ6jBDQJI6zAfNS5q3yY13jWS/O6+9YCT77YI3dQiM6gMrSUuFw0GS1GGGgCR1mCEgSR1mCEhShxkCktRhhoAkdZghIEkdtuAQSLIqybeTPJ7ksSSfbvXPJtmdZFt7nd/3nquS7EjyZJJzh/ELSJIWbpCbxQ4An6mqh9tzhh9KsrUt+2JV/Un/yklOAS4GTgV+HvhWkndV1asD9CBJGsCCjwSqak9VPdym/wl4AlhxiLdcCNxaVa9U1ffpPWf4jIXuX5I0uKGcE0gyCbwPuL+VrkjySJLNSZa12grgub637eLQoSFJOsoGDoEkbwduB66sqpeA64F3AmuBPcDnF7DNDUmmk0zv379/0BYlSQcxUAgkeSu9APhyVX0NoKr2VtWrVfUa8CVeH/LZDazqe/vKVnuDqtpUVVNVNTUxMTFIi5KkQxjk6qAANwBPVNUX+urL+1b7KLC9TW8BLk5ybJKTgTXAAwvdvyRpcINcHfQB4OPAo0m2tdofAJckWQsUsBP4JEBVPZbkNuBxelcWXe6VQZI0WgsOgar6WyBzLLr7EO+5BrhmofuUJA2XdwxLUocZApLUYYaAJHWYISBJHWYISFKHGQKS1GGGgCR1mCEgSR1mCEhShxkCktRhg3x3kCQtismNd41s3zuvvWBk+14MHglIUocZApLUYYaAJHWYISBJHWYISFKHLXoIJFmX5MkkO5JsXOz9S5Jet6ghkOQY4M+A84BT6D2K8pTF7EGS9LrFvk/gDGBHVT0DkORW4EJ6zx2WpLEzqnsUFuv+hMUeDloBPNc3v6vVJEkjMJZ3DCfZAGxos/8vyZML3NSJwD8Mp6ujbin1Ckur36XUKyytfpdSr7CE+s0fD9Trv5vviosdAruBVX3zK1vtx1TVJmDToDtLMl1VU4NuZzEspV5hafW7lHqFpdXvUuoVlla/i9XrYg8HPQisSXJykrcBFwNbFrkHSVKzqEcCVXUgyRXAPcAxwOaqemwxe5AkvW7RzwlU1d3A3Yu0u4GHlBbRUuoVlla/S6lXWFr9LqVeYWn1uyi9pqoWYz+SpDHk10ZIUoe9KUNg3L+aIsnmJPuSbO+rnZBka5Kn2s9lo+xxRpJVSb6d5PEkjyX5dKuPa7//NskDSf6u9fufWv3kJPe3z8RX2oUJYyHJMUm+m+QbbX6ce92Z5NEk25JMt9q4fhaOT/LVJN9L8kSSXx7jXt/d/qYzr5eSXLkY/b7pQmCJfDXFjcC6WbWNwL1VtQa4t82PgwPAZ6rqFOBM4PL29xzXfl8BfrWq3gusBdYlORP4Y+CLVfULwA+Ay0bY42yfBp7omx/nXgF+parW9l2+OK6fhT8F/rqqfhF4L72/8Vj2WlVPtr/pWuB04GXgDhaj36p6U72AXwbu6Zu/Crhq1H3N0ecksL1v/klgeZteDjw56h4P0vedwK8thX6BnwQeBt5P76abt8z1GRlxjyvbP+5fBb4BZFx7bf3sBE6cVRu7zwLwM8D3aec9x7nXOXo/B/g/i9Xvm+5IgKX71RQnVdWeNv08cNIom5lLkkngfcD9jHG/bXhlG7AP2Ao8DfxjVR1oq4zTZ+K/Ar8PvNbmf5bx7RWggG8meajd2Q/j+Vk4GdgP/I821PYXSY5jPHud7WLgljZ91Pt9M4bAkle92B+ry7aSvB24Hbiyql7qXzZu/VbVq9U7rF5J70sLf3HELc0pya8D+6rqoVH3cgQ+WFWn0RtuvTzJh/sXjtFn4S3AacD1VfU+4J+ZNZQyRr3+SDv/8xHgL2cvO1r9vhlDYF5fTTGG9iZZDtB+7htxPz+S5K30AuDLVfW1Vh7bfmdU1T8C36Y3pHJ8kpn7YsblM/EB4CNJdgK30hsS+lPGs1cAqmp3+7mP3pj1GYznZ2EXsKuq7m/zX6UXCuPYa7/zgIeram+bP+r9vhlDYKl+NcUWYH2bXk9v7H3kkgS4AXiiqr7Qt2hc+51Icnyb/gl65y+eoBcGv9lWG4t+q+qqqlpZVZP0Pqf/q6p+mzHsFSDJcUl+amaa3tj1dsbws1BVzwPPJXl3K51N7yvrx67XWS7h9aEgWIx+R30S5CidWDkf+Ht6Y8F/OOp+5ujvFmAP8K/0/sdyGb2x4HuBp4BvASeMus/W6wfpHYI+Amxrr/PHuN9fAr7b+t0O/MdWfwfwALCD3qH2saPudVbfZwHfGOdeW19/116PzfzbGuPPwlpgun0Wvg4sG9deW7/HAS8AP9NXO+r9esewJHXYm3E4SJI0T4aAJHWYISBJHWYISFKHGQKS1GGGgCR1mCEgSR1mCEhSh/1/A8+Ar6jKokMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist([len(t) for t in tokens_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 11:04:27,157 INFO: char embedding size: 4939\n",
      "2019-02-21 11:04:27,971 INFO: word embedding size: 167642\n",
      "2019-02-21 11:04:36,824 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(167642, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(4939, 50, padding_idx=4936)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "from elmoformanylangs import Embedder\n",
    "\n",
    "embedder = Embedder(\"../../../models/elmo/en/\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import CuDNNLSTM\n",
    "from hate.nn import CharModel, ElmoModel, BowModel, MergeModel\n",
    "\n",
    "tokenize_args = {\n",
    "    'deaccent': False, \n",
    "    'language': 'english', \n",
    "    'preserve_case': False,\n",
    "}\n",
    "\n",
    "elmo_model = ElmoModel(\n",
    "    max_len=55, embedder=embedder,\n",
    "    lstm_units=256,\n",
    "    tokenize_args=tokenize_args,\n",
    "    dense_units=128,\n",
    "    recursive_class=CuDNNLSTM, dropout=[0.80, 0.50]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carguemos los hiperparámetros óptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Elmo_Input (InputLayer)      (None, 55, 1024)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               2625536   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_elmo (Dense)           (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,691,329\n",
      "Trainable params: 2,691,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "model = elmo_model\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "    optimizer=Adam(lr=0.0005, decay=0.01),\n",
    "    metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 11:05:05,077 INFO: 282 batches, avg len: 57.0\n",
      "2019-02-21 11:05:10,637 INFO: Finished 1000 sentences.\n",
      "2019-02-21 11:05:15,410 INFO: Finished 2000 sentences.\n",
      "2019-02-21 11:05:20,174 INFO: Finished 3000 sentences.\n",
      "2019-02-21 11:05:24,966 INFO: Finished 4000 sentences.\n",
      "2019-02-21 11:05:29,894 INFO: Finished 5000 sentences.\n",
      "2019-02-21 11:05:34,700 INFO: Finished 6000 sentences.\n",
      "2019-02-21 11:05:39,623 INFO: Finished 7000 sentences.\n",
      "2019-02-21 11:05:44,453 INFO: Finished 8000 sentences.\n",
      "2019-02-21 11:05:49,271 INFO: Finished 9000 sentences.\n",
      "2019-02-21 11:05:52,786 INFO: 32 batches, avg len: 57.0\n",
      "2019-02-21 11:05:57,598 INFO: Finished 1000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 11:05:58,082 WARNING: Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/300\n",
      "9000/9000 [==============================] - 8s 840us/step - loss: 0.6880 - acc: 0.5796 - val_loss: 0.6445 - val_acc: 0.6370\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.63700, saving model to /tmp/en_elmo.h5\n",
      "Epoch 2/300\n",
      "9000/9000 [==============================] - 6s 635us/step - loss: 0.6083 - acc: 0.6618 - val_loss: 0.6058 - val_acc: 0.6850\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.63700 to 0.68500, saving model to /tmp/en_elmo.h5\n",
      "Epoch 3/300\n",
      "9000/9000 [==============================] - 6s 634us/step - loss: 0.5813 - acc: 0.6996 - val_loss: 0.6195 - val_acc: 0.6340\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.68500\n",
      "Epoch 4/300\n",
      "9000/9000 [==============================] - 6s 633us/step - loss: 0.5623 - acc: 0.7148 - val_loss: 0.5942 - val_acc: 0.6730\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.68500\n",
      "Epoch 5/300\n",
      "9000/9000 [==============================] - 6s 635us/step - loss: 0.5500 - acc: 0.7270 - val_loss: 0.5855 - val_acc: 0.6720\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.68500\n",
      "Epoch 6/300\n",
      "9000/9000 [==============================] - 6s 635us/step - loss: 0.5395 - acc: 0.7304 - val_loss: 0.5819 - val_acc: 0.6890\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.68500 to 0.68900, saving model to /tmp/en_elmo.h5\n",
      "Epoch 7/300\n",
      "9000/9000 [==============================] - 6s 636us/step - loss: 0.5368 - acc: 0.7331 - val_loss: 0.5823 - val_acc: 0.6830\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.68900\n",
      "Epoch 8/300\n",
      "9000/9000 [==============================] - 6s 638us/step - loss: 0.5303 - acc: 0.7369 - val_loss: 0.5772 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.68900\n",
      "Epoch 9/300\n",
      "9000/9000 [==============================] - 6s 636us/step - loss: 0.5189 - acc: 0.7460 - val_loss: 0.5770 - val_acc: 0.6780\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.68900\n",
      "Epoch 10/300\n",
      "9000/9000 [==============================] - 6s 632us/step - loss: 0.5137 - acc: 0.7493 - val_loss: 0.5734 - val_acc: 0.6940\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.68900 to 0.69400, saving model to /tmp/en_elmo.h5\n",
      "Epoch 11/300\n",
      "9000/9000 [==============================] - 6s 638us/step - loss: 0.5121 - acc: 0.7466 - val_loss: 0.5765 - val_acc: 0.6740\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.69400\n",
      "Epoch 12/300\n",
      "9000/9000 [==============================] - 6s 633us/step - loss: 0.5072 - acc: 0.7553 - val_loss: 0.5714 - val_acc: 0.7010\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.69400 to 0.70100, saving model to /tmp/en_elmo.h5\n",
      "Epoch 13/300\n",
      "9000/9000 [==============================] - 6s 636us/step - loss: 0.5025 - acc: 0.7523 - val_loss: 0.5695 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.70100\n",
      "Epoch 14/300\n",
      "9000/9000 [==============================] - 6s 635us/step - loss: 0.4977 - acc: 0.7610 - val_loss: 0.5684 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.70100\n",
      "Epoch 15/300\n",
      "9000/9000 [==============================] - 6s 636us/step - loss: 0.4968 - acc: 0.7608 - val_loss: 0.5714 - val_acc: 0.6840\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.70100\n",
      "Epoch 16/300\n",
      "9000/9000 [==============================] - 6s 639us/step - loss: 0.4936 - acc: 0.7651 - val_loss: 0.5722 - val_acc: 0.6980\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.70100\n",
      "Epoch 17/300\n",
      "9000/9000 [==============================] - 6s 639us/step - loss: 0.4882 - acc: 0.7629 - val_loss: 0.5735 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.70100\n",
      "Epoch 18/300\n",
      "9000/9000 [==============================] - 6s 635us/step - loss: 0.4869 - acc: 0.7702 - val_loss: 0.5723 - val_acc: 0.7040\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.70100 to 0.70400, saving model to /tmp/en_elmo.h5\n",
      "Epoch 19/300\n",
      "9000/9000 [==============================] - 6s 633us/step - loss: 0.4830 - acc: 0.7682 - val_loss: 0.5676 - val_acc: 0.6930\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.70400\n",
      "Epoch 20/300\n",
      "9000/9000 [==============================] - 6s 633us/step - loss: 0.4759 - acc: 0.7724 - val_loss: 0.5715 - val_acc: 0.6980\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.70400\n",
      "Epoch 21/300\n",
      "9000/9000 [==============================] - 6s 634us/step - loss: 0.4794 - acc: 0.7703 - val_loss: 0.5709 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.70400\n",
      "Epoch 22/300\n",
      "9000/9000 [==============================] - 6s 633us/step - loss: 0.4748 - acc: 0.7726 - val_loss: 0.5683 - val_acc: 0.6910\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.70400\n",
      "Epoch 23/300\n",
      "9000/9000 [==============================] - 6s 634us/step - loss: 0.4740 - acc: 0.7722 - val_loss: 0.5691 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.70400\n",
      "Epoch 24/300\n",
      "9000/9000 [==============================] - 6s 639us/step - loss: 0.4743 - acc: 0.7707 - val_loss: 0.5678 - val_acc: 0.6890\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.70400\n",
      "Epoch 25/300\n",
      "9000/9000 [==============================] - 6s 634us/step - loss: 0.4727 - acc: 0.7743 - val_loss: 0.5737 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.70400\n",
      "Epoch 26/300\n",
      "9000/9000 [==============================] - 6s 636us/step - loss: 0.4691 - acc: 0.7754 - val_loss: 0.5685 - val_acc: 0.6890\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.70400\n",
      "Epoch 27/300\n",
      "9000/9000 [==============================] - 6s 634us/step - loss: 0.4648 - acc: 0.7796 - val_loss: 0.5709 - val_acc: 0.6960\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.70400\n",
      "Epoch 28/300\n",
      "9000/9000 [==============================] - 6s 635us/step - loss: 0.4610 - acc: 0.7780 - val_loss: 0.5771 - val_acc: 0.7030\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.70400\n",
      "Epoch 29/300\n",
      "9000/9000 [==============================] - 6s 634us/step - loss: 0.4608 - acc: 0.7854 - val_loss: 0.5756 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.70400\n",
      "Epoch 30/300\n",
      "9000/9000 [==============================] - 6s 635us/step - loss: 0.4597 - acc: 0.7814 - val_loss: 0.5710 - val_acc: 0.6940\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.70400\n",
      "Epoch 31/300\n",
      "9000/9000 [==============================] - 6s 637us/step - loss: 0.4556 - acc: 0.7848 - val_loss: 0.5727 - val_acc: 0.6940\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.70400\n",
      "Epoch 32/300\n",
      "9000/9000 [==============================] - 6s 638us/step - loss: 0.4552 - acc: 0.7883 - val_loss: 0.5704 - val_acc: 0.6860\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.70400\n",
      "Epoch 33/300\n",
      "9000/9000 [==============================] - 6s 638us/step - loss: 0.4552 - acc: 0.7870 - val_loss: 0.5740 - val_acc: 0.6980\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.70400\n",
      "Epoch 34/300\n",
      "9000/9000 [==============================] - 6s 639us/step - loss: 0.4480 - acc: 0.7836 - val_loss: 0.5728 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.70400\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "checkpointer = ModelCheckpoint('/tmp/en_elmo.h5', save_best_only=True, monitor='val_acc', verbose=1)\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=15)\n",
    "history = model.fit(X_train, y_train, callbacks=[checkpointer, early_stopper],\n",
    "          validation_data=(X_dev, y_dev), epochs=300, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 11:09:18,037 INFO: 32 batches, avg len: 57.0\n",
      "2019-02-21 11:09:22,950 INFO: Finished 1000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 269us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 11:09:25,941 INFO: 32 batches, avg len: 57.0\n",
      "2019-02-21 11:09:30,883 INFO: Finished 1000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss           : 0.5719\n",
      "Accuracy       : 0.7050\n",
      "Precision(1)   : 0.6585\n",
      "Precision(1)   : 0.7339\n",
      "Precision(avg) : 0.6962\n",
      "\n",
      "Recall(1)      : 0.6323\n",
      "Recall(0)      : 0.7557\n",
      "Recall(avg)    : 0.6940\n",
      "\n",
      "F1(1)          : 0.6452\n",
      "F1(0)          : 0.7446\n",
      "F1(avg)        : 0.6949\n",
      "\n",
      "\n",
      "Evaluación sobre test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 11:09:38,680 INFO: 93 batches, avg len: 57.0\n",
      "2019-02-21 11:09:43,766 INFO: Finished 1000 sentences.\n",
      "2019-02-21 11:09:48,747 INFO: Finished 2000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2971/2971 [==============================] - 1s 248us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-02-21 11:10:02,092 INFO: 93 batches, avg len: 57.0\n",
      "2019-02-21 11:10:06,968 INFO: Finished 1000 sentences.\n",
      "2019-02-21 11:10:11,678 INFO: Finished 2000 sentences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss           : 0.7359\n",
      "Accuracy       : 0.5079\n",
      "Precision(1)   : 0.4546\n",
      "Precision(1)   : 0.7364\n",
      "Precision(avg) : 0.5955\n",
      "\n",
      "Recall(1)      : 0.8914\n",
      "Recall(0)      : 0.2211\n",
      "Recall(avg)    : 0.5562\n",
      "\n",
      "F1(1)          : 0.6021\n",
      "F1(0)          : 0.3400\n",
      "F1(avg)        : 0.4711\n"
     ]
    }
   ],
   "source": [
    "from hate.utils import print_evaluation\n",
    "\n",
    "model.load_weights(checkpointer.filepath)\n",
    "model.preprocess_fit(X_train)\n",
    "\n",
    "print_evaluation(model, X_dev, y_dev)\n",
    "\n",
    "print(\"\\n\\nEvaluación sobre test\")\n",
    "print_evaluation(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-01-20 19:50:26,265 INFO: 94 batches, avg len: 57.0\n",
      "2019-01-20 19:50:31,359 INFO: Finished 1000 sentences.\n",
      "2019-01-20 19:50:36,542 INFO: Finished 2000 sentences.\n",
      "2019-01-20 19:50:41,721 INFO: Finished 3000 sentences.\n",
      "2019-01-20 19:50:47,136 INFO: 32 batches, avg len: 57.0\n",
      "2019-01-20 19:50:52,196 INFO: Finished 1000 sentences.\n"
     ]
    }
   ],
   "source": [
    "df_test[\"preds\"] = (model.predict(df_test[\"text\"]) >= 0.5).astype(int)\n",
    "df_dev[\"preds\"] = (model.predict(df_dev[\"text\"]) >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'en_a.tsv': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!rm en_a.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('en_a.tsv', 'w') as f:\n",
    "    for i, row in df_test.iterrows():\n",
    "        f.write('{}\\t{}\\n'.format(i, row[\"preds\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp en_a.tsv ../../../submissions/17_en_ensemble.tsv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"en_a.tsv.zip\", 'w') as f:\n",
    "    f.write('en_a.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
